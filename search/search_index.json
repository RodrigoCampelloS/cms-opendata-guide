{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"CMS Open Data Guide \u00b6 Warning This page is under construction Welcome to the guide for CMS open data. This guide is brought to you by the CMS open data group, on a best-effort basis. All software and instructions are provided \"as is\", without warranty of any kind. This is ongoing work and we appreciate your feedback and/or your help building this guide. How to use this site \u00b6 There are three main tabs to help you navigate the site. It starts with the Computing Tools most likely needed to deal with CMS open data. Then, there is a little review of CMSSW , which is the software used by CMS. Finally the Analysis section guides you through the different steps (in the most general order) that you need to follow for performing a particle physics analysis with CMS open data. The site's philosophy \u00b6 This site is thought as a navigation aid. The CMS Collaboration has built an extensive amount of documentation over the years. However, given the nature of our rapidly evolving research activities, this documentation is usually scattered around, which makes it difficult to navigate. The main goal of this guide, therefore, is to facilitate the usage of CMS open/legacy data by providing a structured set of instructions that agglutinate those pieces of information already available in other sites. In this sense, we do not pretend to copy every little piece of information and/or code, but to help you get to it and find your way around it. For CMS open data the three main sources of documentation/information are: The CMS public Twiki pages . Particularly the workbook and the software guide Note When accessing the CMS twiki pages we will usually point you to the most recent page. However, historical Twiki documentation, i.e., earlier revision of the pages, may provide more accurate information for open data that is already a few years old. One can access this historical archive by going to the bottom of any Twiki page, clicking on History and exploring the revisions closer to the open data release year. The CERN CMS Open Portal pages. This portal is not exactly meant to archive documentation. It is mainly a repository for our open data. However, it does host important information that is not so easy to find. This guide will point you to the right pages. The CMSSW code . Although less conventional, exploring the CMSSW code could be a really good source of information. For instance, having hundreds of trigger bits, if the information from a specific module used in a specific trigger (with which data was taken) was needed, it would be impossible to document that explicitly in some guide. Instead, one can explore the code and easily find out the needed information. We will try to show you how it is done. How to get help \u00b6 The best way to get additional help is to visit our open data forum . How to contribute or contact us \u00b6 Please follow these instructions if you would like to contribute. If you find bugs or have suggestions or recommendations to improve this guide, please fill out an issue or contact us .","title":"Home"},{"location":"#cms-open-data-guide","text":"Warning This page is under construction Welcome to the guide for CMS open data. This guide is brought to you by the CMS open data group, on a best-effort basis. All software and instructions are provided \"as is\", without warranty of any kind. This is ongoing work and we appreciate your feedback and/or your help building this guide.","title":"CMS Open Data Guide"},{"location":"#how-to-use-this-site","text":"There are three main tabs to help you navigate the site. It starts with the Computing Tools most likely needed to deal with CMS open data. Then, there is a little review of CMSSW , which is the software used by CMS. Finally the Analysis section guides you through the different steps (in the most general order) that you need to follow for performing a particle physics analysis with CMS open data.","title":"How to use this site"},{"location":"#the-sites-philosophy","text":"This site is thought as a navigation aid. The CMS Collaboration has built an extensive amount of documentation over the years. However, given the nature of our rapidly evolving research activities, this documentation is usually scattered around, which makes it difficult to navigate. The main goal of this guide, therefore, is to facilitate the usage of CMS open/legacy data by providing a structured set of instructions that agglutinate those pieces of information already available in other sites. In this sense, we do not pretend to copy every little piece of information and/or code, but to help you get to it and find your way around it. For CMS open data the three main sources of documentation/information are: The CMS public Twiki pages . Particularly the workbook and the software guide Note When accessing the CMS twiki pages we will usually point you to the most recent page. However, historical Twiki documentation, i.e., earlier revision of the pages, may provide more accurate information for open data that is already a few years old. One can access this historical archive by going to the bottom of any Twiki page, clicking on History and exploring the revisions closer to the open data release year. The CERN CMS Open Portal pages. This portal is not exactly meant to archive documentation. It is mainly a repository for our open data. However, it does host important information that is not so easy to find. This guide will point you to the right pages. The CMSSW code . Although less conventional, exploring the CMSSW code could be a really good source of information. For instance, having hundreds of trigger bits, if the information from a specific module used in a specific trigger (with which data was taken) was needed, it would be impossible to document that explicitly in some guide. Instead, one can explore the code and easily find out the needed information. We will try to show you how it is done.","title":"The site's philosophy"},{"location":"#how-to-get-help","text":"The best way to get additional help is to visit our open data forum .","title":"How to get help"},{"location":"#how-to-contribute-or-contact-us","text":"Please follow these instructions if you would like to contribute. If you find bugs or have suggestions or recommendations to improve this guide, please fill out an issue or contact us .","title":"How to contribute or contact us"},{"location":"about/","text":"About \u00b6 This is the guide for CMS open data. All CMS instructional material is made available under the Creative Commons Attribution license . This guide is brought to you by the CMS open data group, on a best-effort basis. All software and instructions are provided \"as is\", without warranty of any kind. This is ongoing work and we appreciate your feedback and/or your help building this guide. Contributors \u00b6 Matt Bellis Edgar Carrera Kati Lassila-Perini Tibor \u0160imko Marco Vidal Garc\u00eda Audrius Mecionis Allan Jales Contact \u00b6 Please contact us here .","title":"About"},{"location":"about/#about","text":"This is the guide for CMS open data. All CMS instructional material is made available under the Creative Commons Attribution license . This guide is brought to you by the CMS open data group, on a best-effort basis. All software and instructions are provided \"as is\", without warranty of any kind. This is ongoing work and we appreciate your feedback and/or your help building this guide.","title":"About"},{"location":"about/#contributors","text":"Matt Bellis Edgar Carrera Kati Lassila-Perini Tibor \u0160imko Marco Vidal Garc\u00eda Audrius Mecionis Allan Jales","title":"Contributors"},{"location":"about/#contact","text":"Please contact us here .","title":"Contact"},{"location":"faq/","text":"FAQ \u00b6 Warning This page is under construction Frequently Asked Questions and other problems and issues that have come up. Possible subsections below High-level questions \u00b6 Why would I choose VirtualBox over docker? Why would I choose docker over VirtualBox? \u00b6 Great question! Anyone? Docker \u00b6 Docker downloads container but never launches environment \u00b6 This is an issue with newer OSs on your local laptop/desktop running older OSs in the container. For example, suppose you are following the Running CMS analysis code using Docker tutorial. If you run docker run --name opendata -it cmsopendata/cmssw_5_3_32 /bin/bash and the container downloads but you don't find yourself in the CMSSW_5_3_32 environment, then... Data \u00b6 CMSSW \u00b6","title":"FAQ"},{"location":"faq/#faq","text":"Warning This page is under construction Frequently Asked Questions and other problems and issues that have come up. Possible subsections below","title":"FAQ"},{"location":"faq/#high-level-questions","text":"","title":"High-level questions"},{"location":"faq/#why-would-i-choose-virtualbox-over-docker-why-would-i-choose-docker-over-virtualbox","text":"Great question! Anyone?","title":"Why would I choose VirtualBox over docker? Why would I choose docker over VirtualBox?"},{"location":"faq/#docker","text":"","title":"Docker"},{"location":"faq/#docker-downloads-container-but-never-launches-environment","text":"This is an issue with newer OSs on your local laptop/desktop running older OSs in the container. For example, suppose you are following the Running CMS analysis code using Docker tutorial. If you run docker run --name opendata -it cmsopendata/cmssw_5_3_32 /bin/bash and the container downloads but you don't find yourself in the CMSSW_5_3_32 environment, then...","title":"Docker downloads container but never launches environment"},{"location":"faq/#data","text":"","title":"Data"},{"location":"faq/#cmssw","text":"","title":"CMSSW"},{"location":"analysis/backgrounds/qcdestimation/","text":"QCD Estimation \u00b6 Warning This page is under construction","title":"QCD Estimation"},{"location":"analysis/backgrounds/qcdestimation/#qcd-estimation","text":"Warning This page is under construction","title":"QCD Estimation"},{"location":"analysis/backgrounds/techniques/","text":"Techniques \u00b6 Warning This page is under construction","title":"Techniques"},{"location":"analysis/backgrounds/techniques/#techniques","text":"Warning This page is under construction","title":"Techniques"},{"location":"analysis/datasim/collisiondata/","text":"Collision Data \u00b6 Warning This page is under construction The CMS collision data is organized in primary datasets (PD). All CMS open data primary datasets can be found with this search . The dataset name consists of three parts separated by \"/\", e.g.: /TauPlusX/Run2011A-12Oct2013-v1/AOD The first part indicates the primary dataset contents ( TauPlusX ), the second part is the data-taking era ( Run2011A ) and reprocessing ( 12Oct2013 ), and the last one indicates the data format ( AOD ). Dataset contents \u00b6 The primary dataset definition is centered around physics objects (SingleMu, Jet, Tau etc). Events triggered by High Level Triggers (HLT) with a similar physics contents or use are mostly directed in the same PD. This guide gives an overview of the CMS trigger system. Besides requirements on the physics content, the organisation of the primary datasets has to satisfy constraints related to the data processing and handling, such as the average event rate approximately uniform across the different PDs, and the event rate more than 10 Hz and less than 200 Hz. (relevant?) Each CMS collision dataset comes with a brief description of the contents, and the full listing of all possible HLT trigger streams included in the dataset. The instructions how to find the exact definitions and parameters of the HLT trigger definitions can be found in Guide to the CMS Trigger System under \" HLT Trigger Path definitions \". Since a given event can pass more than one HLT path, it can be included in more than one primary dataset. There's an overall overlap between the PDs of around 25-35% during Run1 and it must be taken into account when combining events from different datasets in an analysis. Data taking and reprocessing \u00b6 One year of data taking is divided in several \"eras\" indicated as RunA, RunB, etc. According to the CMS data policy, 50% of data is published after the embargo period, completed with the full release within 10 years. Currently available are Run2010A and Run2010B Run2011A Run2012B and Run2012C The data are reprocessed several times, and it is the last complete reprocessing available at the time of the release which is made public. Data format \u00b6 The data format in use for Run1 data is Analysis Object Data (AOD). A brief description of data formats can be found in the introductory About CMS under \" Primary and simulated datasets \". Else (FIXME) \u00b6 To consider: mention json files for validated runs/LS mention condition data and GT Integrated luminosity here or in a separate chapter? Refs G. Franzoni: Dataset definition for CMS operations and physics analyses CR2014_311.pdf","title":"Collision Data"},{"location":"analysis/datasim/collisiondata/#collision-data","text":"Warning This page is under construction The CMS collision data is organized in primary datasets (PD). All CMS open data primary datasets can be found with this search . The dataset name consists of three parts separated by \"/\", e.g.: /TauPlusX/Run2011A-12Oct2013-v1/AOD The first part indicates the primary dataset contents ( TauPlusX ), the second part is the data-taking era ( Run2011A ) and reprocessing ( 12Oct2013 ), and the last one indicates the data format ( AOD ).","title":"Collision Data"},{"location":"analysis/datasim/collisiondata/#dataset-contents","text":"The primary dataset definition is centered around physics objects (SingleMu, Jet, Tau etc). Events triggered by High Level Triggers (HLT) with a similar physics contents or use are mostly directed in the same PD. This guide gives an overview of the CMS trigger system. Besides requirements on the physics content, the organisation of the primary datasets has to satisfy constraints related to the data processing and handling, such as the average event rate approximately uniform across the different PDs, and the event rate more than 10 Hz and less than 200 Hz. (relevant?) Each CMS collision dataset comes with a brief description of the contents, and the full listing of all possible HLT trigger streams included in the dataset. The instructions how to find the exact definitions and parameters of the HLT trigger definitions can be found in Guide to the CMS Trigger System under \" HLT Trigger Path definitions \". Since a given event can pass more than one HLT path, it can be included in more than one primary dataset. There's an overall overlap between the PDs of around 25-35% during Run1 and it must be taken into account when combining events from different datasets in an analysis.","title":"Dataset contents"},{"location":"analysis/datasim/collisiondata/#data-taking-and-reprocessing","text":"One year of data taking is divided in several \"eras\" indicated as RunA, RunB, etc. According to the CMS data policy, 50% of data is published after the embargo period, completed with the full release within 10 years. Currently available are Run2010A and Run2010B Run2011A Run2012B and Run2012C The data are reprocessed several times, and it is the last complete reprocessing available at the time of the release which is made public.","title":"Data taking and reprocessing"},{"location":"analysis/datasim/collisiondata/#data-format","text":"The data format in use for Run1 data is Analysis Object Data (AOD). A brief description of data formats can be found in the introductory About CMS under \" Primary and simulated datasets \".","title":"Data format"},{"location":"analysis/datasim/collisiondata/#else-fixme","text":"To consider: mention json files for validated runs/LS mention condition data and GT Integrated luminosity here or in a separate chapter? Refs G. Franzoni: Dataset definition for CMS operations and physics analyses CR2014_311.pdf","title":"Else (FIXME)"},{"location":"analysis/datasim/eventgeneration/","text":"Event Generation \u00b6 Warning This page is under construction Physical event generation and detector simulation are the first steps in producing Monte Carlo samples suitable for physical analysis. Here we will teach you how to use the CMS datasets in the CERN Open Data Portal and the CMSSW machinery for the generation of events in simple steps: Generation and Simulation: To simulate beam collisions. Triggers: To simulate the effect of the detectors and electronics. Reconstruction: For the reconstruction of the events in the collisions. What you will find here: Virtual machines Dataset name System details Configuration files cmsDriver Generation from Matrix Element (ME) generators LHE Simulation High Level Trigger (HLT) Reconstruction Generation from general-purpose generators Generation and Simulation High Level Trigger (HLT) Reconstruction Example for event generation with 2011 CMSSW machinery Example for event generation with 2012 CMSSW machinery Virtual machines \u00b6 A specific CMS virtual machine includes the ROOT framework and CMSSW. Follow these instructions to configure a CERN virtual machine on your computer to be used with the 2011 and 2012 CMS open data. Dataset name \u00b6 When exploring a simulated dataset on the CERN Open Data Portal , the first thing you will see is the name of the dataset. CMS uses the following naming convention : PROCESS_RANGETYPE-RANGELOWtoRANGEHIGH_FILTER_TUNE_COMMENT_COMENERGY-GENERATOR Take as an example the name of record 12201 : QCD_Pt-15to3000_TuneZ2star_Flat_8TeV_pythia6 System details \u00b6 In the record of each dataset, you can find the recommended global tag and release for analysis (CMSSW is the data analysis library). A global tag stores additional data that is required by the reconstruction and analysis software. Take as an example section System details of record 12201 : Recommended global tag for analysis: START53_V27 Recommended release for analysis: CMSSW_5_3_32 Configuration files \u00b6 The CMS software framework uses a software bus model, where data is stored in the event which is passed to a series of modules. A single executable, cmsRun , is used, and the modules are loaded at runtime. A configuration file defines which modules are loaded, in which order they are run, and with which configurable parameters they are run. You can find the configuration files for the generation of events for each dataset in its respective record within the CERN Open Data Portal . Check, for example, the section How were these data generated? of record 12201 . cmsDriver \u00b6 The cmsDriver is a tool to create production-solid configuration files from minimal command line options. Its code implementation, the cmsDriver.py script, is part of the CMSSW software. A summary of the cmsDriver.py script's options with a detailed message about each one can be visualized by getting the help: cmsDriver.py --help Generation from Matrix Element (ME) generators \u00b6 Generator-level datasets can be produced using a Matrix Element (ME) generator (e.g., Powheg , MadGraph5_aMCatNLO , Alpgen ) to deliver the event at the parton level and then a general-purpose generator to hadronise the event. Here we will reproduce the steps in the generation of record 1352 . Guided by the system details specified in the dataset, you should start by setting up your run time environment: cmsrel CMSSW_5_3_32 cd CMSSW_5_3_32/src/ cmsenv We will create a package according to our dataset: mkdir MyPackage cd MyPackage mkedanlzr MySim LHE \u00b6 The Les Houches Event file format ( LHE ) is an agreement between Monte Carlo event generators and theorists to define Matrix Element level event listings in a common language. The LHE input file that store process and event information can be one generated by you or you can look for examples in /eos/cms/store/lhe/ . Here we will use a file with events generated for record 1352 : cmsDriver.py step1 --filein lhe:10270 --fileout file:LHE.root --mc --eventcontent LHE --datatier GEN --conditions START53_LV6A1::All --step NONE --python_filename LHE.py --no_exec --customise Configuration/DataProcessing/Utils.addMonitoring -n 3 Run the CMSSW executable: cmsRun LHE.py Simulation \u00b6 The next step is to generate fully hadronised events. We need to use the appropriate configuration file for this purpose. Take as an example the file in Step SIM for the simulation of record 1352 . The configuration file is in this link . We add this file to our local area: curl http://uaf-10.t2.ucsd.edu/~phchang/analysis/generator/genproductions/python/SevenTeV/Hadronizer_TuneZ2_7TeV_generic_LHE_pythia_tauola_cff.py -o MySim/python/mysim.py Compile everything: scram b Execute the cmsDriver command as: cmsDriver.py MyPackage/MySim/python/mysim.py --filein file:LHE.root --fileout file:sim.root --mc --eventcontent RAWSIM --customise SimG4Core/Application/reproc2011_2012_cff.customiseG4,Configuration/DataProcessing/Utils.addMonitoring --datatier GEN-SIM --conditions START53_LV6A1::All --beamspot Realistic7TeV2011CollisionV2 --step GEN,SIM --datamix NODATAMIXER --python_filename sim.py --no_exec -n 3 Run the CMSSW executable: cmsRun sim.py High Level Trigger (HLT) \u00b6 It is a crucial part of the CMS data flow since it is the HLT algorithms and filters which will decide whether an event should be kept for an offline analysis: any offline analysis depends on the outcome of HLT. Execute the cmsDriver command as: cmsDriver.py step1 --filein file:sim.root --fileout file:hlt.root --mc --eventcontent RAWSIM --runsScenarioForMC Run2012_AB_C_D_oneRunPerEra --datatier GEN-RAW --conditions START53_LV6A1::All --step DIGI,L1,DIGI2RAW,HLT:2011 --python_filename hlt.py --no_exec --customise Configuration/DataProcessing/Utils.addMonitoring -n 3 Now, run the CMSSW executable: cmsRun hlt.py Reconstruction \u00b6 The algorithms that make up the CMS event reconstruction software build physics objects (e.g., muons, electrons, jets) from the raw data recorded by the detector. All events collected by the CMS trigger system are reconstructed by the CMS prompt reconstruction system soon after being collected. Execute the cmsDriver command as: cmsDriver.py step2 --filein file:hlt.root --fileout file:reco.root --mc --eventcontent AODSIM,DQM --datatier AODSIM,DQM --conditions START53_LV6A1::All --step RAW2DIGI,L1Reco,RECO,VALIDATION:validation_prod,DQM:DQMOfflinePOGMC --python_filename reco.py --no_exec --customise Configuration/DataProcessing/Utils.addMonitoring -n 3 Now, run the CMSSW executable: cmsRun reco.py You can start ROOT and type TBrowser t to explore the files that were created. Generation from general-purpose generators \u00b6 Generator-level datasets can be produced using a general-purpose generator (e.g., Pythia , Herwig , Tauola ) to simulate the event and the hadronisation. Here we will reproduce the steps in the generation of record 12201 . Guided by the system details specified in the dataset, you should start by setting up your run time environment: cmsrel CMSSW_5_3_32 cd CMSSW_5_3_32/src/ cmsenv We will create a package according to our dataset: mkdir MyPackage cd MyPackage mkedanlzr MyGen Generation and Simulation \u00b6 We need to use the appropriate configuration file. Take as an example the file in Step SIM for the generation and simulation of record 12201 . The configuration file is in this link . We add this file to our local area: curl https://raw.githubusercontent.com/cms-sw/genproductions/master/python/EightTeV/QCD_Pt/QCD_Pt_15to3000_TuneZ2star_Flat_8TeV_pythia6_cff.py -o MyGen/python/mygen.py Compile everything: scram b Execute the cmsDriver command as: cmsDriver.py MyPackage/MyGen/python/mygen.py --fileout file:gen.root --mc --eventcontent RAWSIM --pileup NoPileUp --customise Configuration/StandardSequences/SimWithCastor_cff.customise,Configuration/DataProcessing/Utils.addMonitoring --datatier GEN-SIM --conditions START50_V13::All --beamspot Realistic8TeVCollision --step GEN,SIM --datamix NODATAMIXER --python_filename gen.py --no_exec -n 3 Run the CMSSW executable: cmsRun gen.py High Level Trigger (HLT) \u00b6 Execute the cmsDriver command as: cmsDriver.py step1 --filein file:gen.root --fileout file:hlt.root --pileup_input dbs:/MinBias_TuneZ2star_8TeV-pythia6/Summer12-START50_V13-v3/GEN-SIM --mc --eventcontent RAWSIM --runsScenarioForMC Run2012_AB_C_D_oneRunPerEra --pileup fromDB --datatier GEN-SIM-RAW --conditions START53_V7N::All --step DIGI,L1,DIGI2RAW,HLT:7E33v2 --python_filename hlt.py --no_exec --customise Configuration/DataProcessing/Utils.addMonitoring -n 3 In section How were these data generated? of the record, you can find the pile-up dataset. Additionally, you can manually add ROOT files to the hlt.py file for the pile-up configuration by looking at the list of ROOT files that were used in the Step HLT configuration file of the record you are studying. This involves, for instance, opening file hlt.py and replacing the line process.mix.input.fileNames = cms.untracked.vstring([]) with process.mix.input.fileNames = cms.untracked.vstring([ 'root://eospublic.cern.ch//eos/opendata/cms/MonteCarlo2012/Summer12/MinBias_TuneZ2star_8TeV-pythia6/GEN-SIM/START50_V13-v3/0000/005825F1-F260-E111-BD97-003048C692DA.root', 'root://eospublic.cern.ch//eos/opendata/cms/MonteCarlo2012/Summer12/MinBias_TuneZ2star_8TeV-pythia6/GEN-SIM/START50_V13-v3/0000/003EEBD4-8061-E111-9A23-003048D437F2.root', 'root://eospublic.cern.ch//eos/opendata/cms/MonteCarlo2012/Summer12/MinBias_TuneZ2star_8TeV-pythia6/GEN-SIM/START50_V13-v3/0000/0005E496-3661-E111-B31E-003048F0E426.root']) Now, run the CMSSW executable: cmsRun hlt.py Reconstruction \u00b6 Execute the cmsDriver command as: cmsDriver.py step2 --filein file:hlt.root --fileout file:reco.root --mc --eventcontent AODSIM,DQM --datatier AODSIM,DQM --conditions START53_V7N::All --step RAW2DIGI,L1Reco,RECO,VALIDATION:validation_prod,DQM:DQMOfflinePOGMC --python_filename reco.py --no_exec --customise Configuration/DataProcessing/Utils.addMonitoring -n 3 Now, run the CMSSW executable: cmsRun reco.py You can start ROOT and type TBrowser t to explore the files that were created. Example for event generation with 2011 CMSSW machinery \u00b6 In this example , you will learn how to generate 2011 MC Drell-Yan events from scratch. A Drell-Yan process occurs when a quark and an antiquark annihilate, creating a virtual photon or Z boson, which then decays into a pair of oppositely charged leptons. Example for event generation with 2012 CMSSW machinery \u00b6 In this example , you will learn how to generate 2012 MC QCD events, which involve the strong interaction between quarks and gluons. Additionally, you will know what are the steps to extract the tracking information of these events.","title":"Event Generation"},{"location":"analysis/datasim/eventgeneration/#event-generation","text":"Warning This page is under construction Physical event generation and detector simulation are the first steps in producing Monte Carlo samples suitable for physical analysis. Here we will teach you how to use the CMS datasets in the CERN Open Data Portal and the CMSSW machinery for the generation of events in simple steps: Generation and Simulation: To simulate beam collisions. Triggers: To simulate the effect of the detectors and electronics. Reconstruction: For the reconstruction of the events in the collisions. What you will find here: Virtual machines Dataset name System details Configuration files cmsDriver Generation from Matrix Element (ME) generators LHE Simulation High Level Trigger (HLT) Reconstruction Generation from general-purpose generators Generation and Simulation High Level Trigger (HLT) Reconstruction Example for event generation with 2011 CMSSW machinery Example for event generation with 2012 CMSSW machinery","title":"Event Generation"},{"location":"analysis/datasim/eventgeneration/#virtual-machines","text":"A specific CMS virtual machine includes the ROOT framework and CMSSW. Follow these instructions to configure a CERN virtual machine on your computer to be used with the 2011 and 2012 CMS open data.","title":"Virtual machines"},{"location":"analysis/datasim/eventgeneration/#dataset-name","text":"When exploring a simulated dataset on the CERN Open Data Portal , the first thing you will see is the name of the dataset. CMS uses the following naming convention : PROCESS_RANGETYPE-RANGELOWtoRANGEHIGH_FILTER_TUNE_COMMENT_COMENERGY-GENERATOR Take as an example the name of record 12201 : QCD_Pt-15to3000_TuneZ2star_Flat_8TeV_pythia6","title":"Dataset name"},{"location":"analysis/datasim/eventgeneration/#system-details","text":"In the record of each dataset, you can find the recommended global tag and release for analysis (CMSSW is the data analysis library). A global tag stores additional data that is required by the reconstruction and analysis software. Take as an example section System details of record 12201 : Recommended global tag for analysis: START53_V27 Recommended release for analysis: CMSSW_5_3_32","title":"System details"},{"location":"analysis/datasim/eventgeneration/#configuration-files","text":"The CMS software framework uses a software bus model, where data is stored in the event which is passed to a series of modules. A single executable, cmsRun , is used, and the modules are loaded at runtime. A configuration file defines which modules are loaded, in which order they are run, and with which configurable parameters they are run. You can find the configuration files for the generation of events for each dataset in its respective record within the CERN Open Data Portal . Check, for example, the section How were these data generated? of record 12201 .","title":"Configuration files"},{"location":"analysis/datasim/eventgeneration/#cmsdriver","text":"The cmsDriver is a tool to create production-solid configuration files from minimal command line options. Its code implementation, the cmsDriver.py script, is part of the CMSSW software. A summary of the cmsDriver.py script's options with a detailed message about each one can be visualized by getting the help: cmsDriver.py --help","title":"cmsDriver"},{"location":"analysis/datasim/eventgeneration/#generation-from-matrix-element-me-generators","text":"Generator-level datasets can be produced using a Matrix Element (ME) generator (e.g., Powheg , MadGraph5_aMCatNLO , Alpgen ) to deliver the event at the parton level and then a general-purpose generator to hadronise the event. Here we will reproduce the steps in the generation of record 1352 . Guided by the system details specified in the dataset, you should start by setting up your run time environment: cmsrel CMSSW_5_3_32 cd CMSSW_5_3_32/src/ cmsenv We will create a package according to our dataset: mkdir MyPackage cd MyPackage mkedanlzr MySim","title":"Generation from Matrix Element (ME) generators"},{"location":"analysis/datasim/eventgeneration/#lhe","text":"The Les Houches Event file format ( LHE ) is an agreement between Monte Carlo event generators and theorists to define Matrix Element level event listings in a common language. The LHE input file that store process and event information can be one generated by you or you can look for examples in /eos/cms/store/lhe/ . Here we will use a file with events generated for record 1352 : cmsDriver.py step1 --filein lhe:10270 --fileout file:LHE.root --mc --eventcontent LHE --datatier GEN --conditions START53_LV6A1::All --step NONE --python_filename LHE.py --no_exec --customise Configuration/DataProcessing/Utils.addMonitoring -n 3 Run the CMSSW executable: cmsRun LHE.py","title":"LHE"},{"location":"analysis/datasim/eventgeneration/#simulation","text":"The next step is to generate fully hadronised events. We need to use the appropriate configuration file for this purpose. Take as an example the file in Step SIM for the simulation of record 1352 . The configuration file is in this link . We add this file to our local area: curl http://uaf-10.t2.ucsd.edu/~phchang/analysis/generator/genproductions/python/SevenTeV/Hadronizer_TuneZ2_7TeV_generic_LHE_pythia_tauola_cff.py -o MySim/python/mysim.py Compile everything: scram b Execute the cmsDriver command as: cmsDriver.py MyPackage/MySim/python/mysim.py --filein file:LHE.root --fileout file:sim.root --mc --eventcontent RAWSIM --customise SimG4Core/Application/reproc2011_2012_cff.customiseG4,Configuration/DataProcessing/Utils.addMonitoring --datatier GEN-SIM --conditions START53_LV6A1::All --beamspot Realistic7TeV2011CollisionV2 --step GEN,SIM --datamix NODATAMIXER --python_filename sim.py --no_exec -n 3 Run the CMSSW executable: cmsRun sim.py","title":"Simulation"},{"location":"analysis/datasim/eventgeneration/#high-level-trigger-hlt","text":"It is a crucial part of the CMS data flow since it is the HLT algorithms and filters which will decide whether an event should be kept for an offline analysis: any offline analysis depends on the outcome of HLT. Execute the cmsDriver command as: cmsDriver.py step1 --filein file:sim.root --fileout file:hlt.root --mc --eventcontent RAWSIM --runsScenarioForMC Run2012_AB_C_D_oneRunPerEra --datatier GEN-RAW --conditions START53_LV6A1::All --step DIGI,L1,DIGI2RAW,HLT:2011 --python_filename hlt.py --no_exec --customise Configuration/DataProcessing/Utils.addMonitoring -n 3 Now, run the CMSSW executable: cmsRun hlt.py","title":"High Level Trigger (HLT)"},{"location":"analysis/datasim/eventgeneration/#reconstruction","text":"The algorithms that make up the CMS event reconstruction software build physics objects (e.g., muons, electrons, jets) from the raw data recorded by the detector. All events collected by the CMS trigger system are reconstructed by the CMS prompt reconstruction system soon after being collected. Execute the cmsDriver command as: cmsDriver.py step2 --filein file:hlt.root --fileout file:reco.root --mc --eventcontent AODSIM,DQM --datatier AODSIM,DQM --conditions START53_LV6A1::All --step RAW2DIGI,L1Reco,RECO,VALIDATION:validation_prod,DQM:DQMOfflinePOGMC --python_filename reco.py --no_exec --customise Configuration/DataProcessing/Utils.addMonitoring -n 3 Now, run the CMSSW executable: cmsRun reco.py You can start ROOT and type TBrowser t to explore the files that were created.","title":"Reconstruction"},{"location":"analysis/datasim/eventgeneration/#generation-from-general-purpose-generators","text":"Generator-level datasets can be produced using a general-purpose generator (e.g., Pythia , Herwig , Tauola ) to simulate the event and the hadronisation. Here we will reproduce the steps in the generation of record 12201 . Guided by the system details specified in the dataset, you should start by setting up your run time environment: cmsrel CMSSW_5_3_32 cd CMSSW_5_3_32/src/ cmsenv We will create a package according to our dataset: mkdir MyPackage cd MyPackage mkedanlzr MyGen","title":"Generation from general-purpose generators"},{"location":"analysis/datasim/eventgeneration/#generation-and-simulation","text":"We need to use the appropriate configuration file. Take as an example the file in Step SIM for the generation and simulation of record 12201 . The configuration file is in this link . We add this file to our local area: curl https://raw.githubusercontent.com/cms-sw/genproductions/master/python/EightTeV/QCD_Pt/QCD_Pt_15to3000_TuneZ2star_Flat_8TeV_pythia6_cff.py -o MyGen/python/mygen.py Compile everything: scram b Execute the cmsDriver command as: cmsDriver.py MyPackage/MyGen/python/mygen.py --fileout file:gen.root --mc --eventcontent RAWSIM --pileup NoPileUp --customise Configuration/StandardSequences/SimWithCastor_cff.customise,Configuration/DataProcessing/Utils.addMonitoring --datatier GEN-SIM --conditions START50_V13::All --beamspot Realistic8TeVCollision --step GEN,SIM --datamix NODATAMIXER --python_filename gen.py --no_exec -n 3 Run the CMSSW executable: cmsRun gen.py","title":"Generation and Simulation"},{"location":"analysis/datasim/eventgeneration/#high-level-trigger-hlt_1","text":"Execute the cmsDriver command as: cmsDriver.py step1 --filein file:gen.root --fileout file:hlt.root --pileup_input dbs:/MinBias_TuneZ2star_8TeV-pythia6/Summer12-START50_V13-v3/GEN-SIM --mc --eventcontent RAWSIM --runsScenarioForMC Run2012_AB_C_D_oneRunPerEra --pileup fromDB --datatier GEN-SIM-RAW --conditions START53_V7N::All --step DIGI,L1,DIGI2RAW,HLT:7E33v2 --python_filename hlt.py --no_exec --customise Configuration/DataProcessing/Utils.addMonitoring -n 3 In section How were these data generated? of the record, you can find the pile-up dataset. Additionally, you can manually add ROOT files to the hlt.py file for the pile-up configuration by looking at the list of ROOT files that were used in the Step HLT configuration file of the record you are studying. This involves, for instance, opening file hlt.py and replacing the line process.mix.input.fileNames = cms.untracked.vstring([]) with process.mix.input.fileNames = cms.untracked.vstring([ 'root://eospublic.cern.ch//eos/opendata/cms/MonteCarlo2012/Summer12/MinBias_TuneZ2star_8TeV-pythia6/GEN-SIM/START50_V13-v3/0000/005825F1-F260-E111-BD97-003048C692DA.root', 'root://eospublic.cern.ch//eos/opendata/cms/MonteCarlo2012/Summer12/MinBias_TuneZ2star_8TeV-pythia6/GEN-SIM/START50_V13-v3/0000/003EEBD4-8061-E111-9A23-003048D437F2.root', 'root://eospublic.cern.ch//eos/opendata/cms/MonteCarlo2012/Summer12/MinBias_TuneZ2star_8TeV-pythia6/GEN-SIM/START50_V13-v3/0000/0005E496-3661-E111-B31E-003048F0E426.root']) Now, run the CMSSW executable: cmsRun hlt.py","title":"High Level Trigger (HLT)"},{"location":"analysis/datasim/eventgeneration/#reconstruction_1","text":"Execute the cmsDriver command as: cmsDriver.py step2 --filein file:hlt.root --fileout file:reco.root --mc --eventcontent AODSIM,DQM --datatier AODSIM,DQM --conditions START53_V7N::All --step RAW2DIGI,L1Reco,RECO,VALIDATION:validation_prod,DQM:DQMOfflinePOGMC --python_filename reco.py --no_exec --customise Configuration/DataProcessing/Utils.addMonitoring -n 3 Now, run the CMSSW executable: cmsRun reco.py You can start ROOT and type TBrowser t to explore the files that were created.","title":"Reconstruction"},{"location":"analysis/datasim/eventgeneration/#example-for-event-generation-with-2011-cmssw-machinery","text":"In this example , you will learn how to generate 2011 MC Drell-Yan events from scratch. A Drell-Yan process occurs when a quark and an antiquark annihilate, creating a virtual photon or Z boson, which then decays into a pair of oppositely charged leptons.","title":"Example for event generation with 2011 CMSSW machinery"},{"location":"analysis/datasim/eventgeneration/#example-for-event-generation-with-2012-cmssw-machinery","text":"In this example , you will learn how to generate 2012 MC QCD events, which involve the strong interaction between quarks and gluons. Additionally, you will know what are the steps to extract the tracking information of these events.","title":"Example for event generation with 2012 CMSSW machinery"},{"location":"analysis/datasim/mcsimulations/","text":"Monte Carlo Simulations \u00b6 Warning This page is under construction A set of simulated data (Monte Carlo - MC) corresponding to the collision data is made available. All directly available MC datasets can be found with this search . Furthermore, large amount of MC, thought to be of less frequent use, is available on demand and included in search results if \" include on-demand datasets \" option is selected. MC dataset are searchable by categories , which can be found under \"Filter by category\" on the left bar of the search page. The dataset name consists of three parts separated by / e.g.: /DYToMuMu_M-15To50_Tune4C_8TeV-pythia8/Summer12_DR53X-PU_S10_START53_V19-v1/AODSIM The first part indicates the simulated physics process ( DYToMuMu ), some of the production parameters ( M-15To50_Tune4C ), collision energy ( 8TeV ), and the event generator used in the processing chain. CMS simulated datasets names gives more details in the naming. The second part is the production campaign ( Summer12_DR53X ), pile-up profile ( PU_S10 ) and processing conditions ( START53_V19 ), and the last one indicates the data format ( AODSIM ). Dataset contents \u00b6 The dataset naming reflects the contents of the dataset, and the actual generator parameters with which the dataset contents have been defined can be found as explained under \" Finding the generator parameters \" in the CMS Monte Carlo production overview . Processing \u00b6 CMS Monte Carlo production overview briefly describes the steps in the MC production chain. Data format \u00b6 The data format in use for Run1 MC data is Analysis Object Data (AODSIM). A brief description of data formats can be found in the introductory About CMS under \" Primary and simulated datasets \".","title":"MC Simulations"},{"location":"analysis/datasim/mcsimulations/#monte-carlo-simulations","text":"Warning This page is under construction A set of simulated data (Monte Carlo - MC) corresponding to the collision data is made available. All directly available MC datasets can be found with this search . Furthermore, large amount of MC, thought to be of less frequent use, is available on demand and included in search results if \" include on-demand datasets \" option is selected. MC dataset are searchable by categories , which can be found under \"Filter by category\" on the left bar of the search page. The dataset name consists of three parts separated by / e.g.: /DYToMuMu_M-15To50_Tune4C_8TeV-pythia8/Summer12_DR53X-PU_S10_START53_V19-v1/AODSIM The first part indicates the simulated physics process ( DYToMuMu ), some of the production parameters ( M-15To50_Tune4C ), collision energy ( 8TeV ), and the event generator used in the processing chain. CMS simulated datasets names gives more details in the naming. The second part is the production campaign ( Summer12_DR53X ), pile-up profile ( PU_S10 ) and processing conditions ( START53_V19 ), and the last one indicates the data format ( AODSIM ).","title":"Monte Carlo Simulations"},{"location":"analysis/datasim/mcsimulations/#dataset-contents","text":"The dataset naming reflects the contents of the dataset, and the actual generator parameters with which the dataset contents have been defined can be found as explained under \" Finding the generator parameters \" in the CMS Monte Carlo production overview .","title":"Dataset contents"},{"location":"analysis/datasim/mcsimulations/#processing","text":"CMS Monte Carlo production overview briefly describes the steps in the MC production chain.","title":"Processing"},{"location":"analysis/datasim/mcsimulations/#data-format","text":"The data format in use for Run1 MC data is Analysis Object Data (AODSIM). A brief description of data formats can be found in the introductory About CMS under \" Primary and simulated datasets \".","title":"Data format"},{"location":"analysis/interpretation/limits/","text":"Upper-limit calculations \u00b6 Warning This page is under construction","title":"Upper-limit Calculations"},{"location":"analysis/interpretation/limits/#upper-limit-calculations","text":"Warning This page is under construction","title":"Upper-limit calculations"},{"location":"analysis/interpretation/stats/","text":"Statistics \u00b6 Warning This page is under construction","title":"Statistics"},{"location":"analysis/interpretation/stats/#statistics","text":"Warning This page is under construction","title":"Statistics"},{"location":"analysis/luminosity/lumi/","text":"Luminosity \u00b6 Warning This page is under construction","title":"Luminosity"},{"location":"analysis/luminosity/lumi/#luminosity","text":"Warning This page is under construction","title":"Luminosity"},{"location":"analysis/selection/objectid/","text":"Object ID \u00b6 Warning This page is under construction","title":"Physics Objects ID"},{"location":"analysis/selection/objectid/#object-id","text":"Warning This page is under construction","title":"Object ID"},{"location":"analysis/selection/objects/","text":"Physics Objects \u00b6 Warning This page is under construction Description \u00b6 The CMS is a giant detector that acts like a camera that \"photographs\" particle collisions, allowing us to interpret their nature. Certainly we cannot directly observe all the particles created in the collisions because some of them decay very quickly or simply do not interact with our detector. However, we can infer their presence. If they decay to other stable particles and interact with the apparatus, they leave signals in the CMS subdetectors. These signals are used to reconstruct the decay products or infer their presence; we call these physics objects . These objects could be electrons, muons, jets, missing energy, etc., but also lower level objects like tracks. For the current releases of open data, we store them in ROOT files following the EDM data model in AOD format. In the CERN Open Portal site one can find a more detailed description of these physical objects and a list of them corresponding to 2010 and 2011/2012 releases of open data. DataFormats \u00b6 As one can see in those guides, these physical objects are usually stored in specific collections . For instance, muons are most commonly obtained from the reco::Muon collection. The AOD Data Format Table gives a good description of the different collections (or data formats) for the AOD tier. Unfortunately, the links for the containers column got broken after CMSSW was moved to Github. Those links would have pointed us to the corresponding CMSSW C++ classes associated with those containers. This is important because one needs to know which CMSSW class matches a given collection of objects to include the headers of those classes in the header of your analyzer code. But let that not let us down. Fortunately, the names of the collections containers actually match the name of its associated CMSSW classes. These classes (data format classes) live under the DataFormats directory in CMSSW. If we browse through, we find the MuonReco package. In its interface area we find the DataFormats/MuonReco/interface/Muon.h class header, which is the one we would need to incorporate in our analyzer. This is corroborated by this Muon Analysis Twiki section . Remember When accessing a specific piece of code in the CMSSW github repository, and want to explore its methods, variables, etc., make sure you select the right git branch. E.g., CMSSW_5_3_X for 2011/2012 open data. In addition to this base class, sometimes it is necessary to invoke other auxiliary classes. For instance, DataFormats/MuonReco/interface/MuonFwd.h , which can be found in the same interface area. So, in the context of this example, in order to support muons information, at the top of your EDAnalyzer you should include the following lines: //classes to extract Muon information #include \"DataFormats/MuonReco/interface/Muon.h\" #include \"DataFormats/MuonReco/interface/MuonFwd.h\" Access methods \u00b6 In the Event methods for data access section of the Getting Data From an Event Twiki page, one can find a complete description of the different methods available for Event data access. Remember When accessing the CMS twiki pages we will usually point you to the most recent page. However, historical Twiki documentation, i.e., earlier revision of the pages, may provide more accurate information for open data that is already a few years old. One can access this historical archive by going to the bottom of any Twiki page, clicking on History and exploring the revisions closer to the open data release year. As indicated in that page, all Event data access methods use the edm::Handle<T> , where T is the C++ type of the requested object, to hold the result of an access. As an example, during Run 1, the recommended method was the getByLabel one. This method needed an InputTag . This can also be extracted from the AOD Data Format Table . The first column indicate the InputTag: Therefore, in the context of this muon example, in the analyze method of your EDAnalyzer you should include the following lines: Handle < reco :: MuonCollection > mymuons ; iEvent . getByLabel ( \"muons\" , mymuons ); If you required cosmic muons, for some reason, you would need instead: Handle < reco :: MuonCollection > mymuons ; iEvent . getByLabel ( \"muonsFromCosmics\" , mymuons ); From configuration \u00b6 Alternatively, it would be also possible to retrieve the InputTag name from configuration . In that case, in your configuration file you would need something like: process . demo = cms . EDAnalyzer ( 'MuonAnalyzer' , InputCollection = cms . InputTag ( \"muons\" ) ) In this case, you would need to declare the appropriate input tag in your EDAnalyzer class: //declare the input tag for MuonCollection edm :: InputTag muonInput ; Extract it from the ParameterSet in the constructor MuonAnalyzer :: MuonAnalyzer ( const edm :: ParameterSet & iConfig ) { //now do what ever initialization is needed muonInput = iConfig . getParameter < edm :: InputTag > ( \"InputCollection\" ); } and use in the analyze routine: Handle < reco :: MuonCollection > mymuons ; iEvent . getByLabel ( muonInput , mymuons ); Additional information for accessing CMS physics objects \u00b6 In Chapter 7 of the CMS Workbook one can find Analysis pages that provide additional information, which can be useful to check on top of the general strategy for accessing objects that was discussed above.","title":"Physics Objects"},{"location":"analysis/selection/objects/#physics-objects","text":"Warning This page is under construction","title":"Physics Objects"},{"location":"analysis/selection/objects/#description","text":"The CMS is a giant detector that acts like a camera that \"photographs\" particle collisions, allowing us to interpret their nature. Certainly we cannot directly observe all the particles created in the collisions because some of them decay very quickly or simply do not interact with our detector. However, we can infer their presence. If they decay to other stable particles and interact with the apparatus, they leave signals in the CMS subdetectors. These signals are used to reconstruct the decay products or infer their presence; we call these physics objects . These objects could be electrons, muons, jets, missing energy, etc., but also lower level objects like tracks. For the current releases of open data, we store them in ROOT files following the EDM data model in AOD format. In the CERN Open Portal site one can find a more detailed description of these physical objects and a list of them corresponding to 2010 and 2011/2012 releases of open data.","title":"Description"},{"location":"analysis/selection/objects/#dataformats","text":"As one can see in those guides, these physical objects are usually stored in specific collections . For instance, muons are most commonly obtained from the reco::Muon collection. The AOD Data Format Table gives a good description of the different collections (or data formats) for the AOD tier. Unfortunately, the links for the containers column got broken after CMSSW was moved to Github. Those links would have pointed us to the corresponding CMSSW C++ classes associated with those containers. This is important because one needs to know which CMSSW class matches a given collection of objects to include the headers of those classes in the header of your analyzer code. But let that not let us down. Fortunately, the names of the collections containers actually match the name of its associated CMSSW classes. These classes (data format classes) live under the DataFormats directory in CMSSW. If we browse through, we find the MuonReco package. In its interface area we find the DataFormats/MuonReco/interface/Muon.h class header, which is the one we would need to incorporate in our analyzer. This is corroborated by this Muon Analysis Twiki section . Remember When accessing a specific piece of code in the CMSSW github repository, and want to explore its methods, variables, etc., make sure you select the right git branch. E.g., CMSSW_5_3_X for 2011/2012 open data. In addition to this base class, sometimes it is necessary to invoke other auxiliary classes. For instance, DataFormats/MuonReco/interface/MuonFwd.h , which can be found in the same interface area. So, in the context of this example, in order to support muons information, at the top of your EDAnalyzer you should include the following lines: //classes to extract Muon information #include \"DataFormats/MuonReco/interface/Muon.h\" #include \"DataFormats/MuonReco/interface/MuonFwd.h\"","title":"DataFormats"},{"location":"analysis/selection/objects/#access-methods","text":"In the Event methods for data access section of the Getting Data From an Event Twiki page, one can find a complete description of the different methods available for Event data access. Remember When accessing the CMS twiki pages we will usually point you to the most recent page. However, historical Twiki documentation, i.e., earlier revision of the pages, may provide more accurate information for open data that is already a few years old. One can access this historical archive by going to the bottom of any Twiki page, clicking on History and exploring the revisions closer to the open data release year. As indicated in that page, all Event data access methods use the edm::Handle<T> , where T is the C++ type of the requested object, to hold the result of an access. As an example, during Run 1, the recommended method was the getByLabel one. This method needed an InputTag . This can also be extracted from the AOD Data Format Table . The first column indicate the InputTag: Therefore, in the context of this muon example, in the analyze method of your EDAnalyzer you should include the following lines: Handle < reco :: MuonCollection > mymuons ; iEvent . getByLabel ( \"muons\" , mymuons ); If you required cosmic muons, for some reason, you would need instead: Handle < reco :: MuonCollection > mymuons ; iEvent . getByLabel ( \"muonsFromCosmics\" , mymuons );","title":"Access methods"},{"location":"analysis/selection/objects/#from-configuration","text":"Alternatively, it would be also possible to retrieve the InputTag name from configuration . In that case, in your configuration file you would need something like: process . demo = cms . EDAnalyzer ( 'MuonAnalyzer' , InputCollection = cms . InputTag ( \"muons\" ) ) In this case, you would need to declare the appropriate input tag in your EDAnalyzer class: //declare the input tag for MuonCollection edm :: InputTag muonInput ; Extract it from the ParameterSet in the constructor MuonAnalyzer :: MuonAnalyzer ( const edm :: ParameterSet & iConfig ) { //now do what ever initialization is needed muonInput = iConfig . getParameter < edm :: InputTag > ( \"InputCollection\" ); } and use in the analyze routine: Handle < reco :: MuonCollection > mymuons ; iEvent . getByLabel ( muonInput , mymuons );","title":"From configuration"},{"location":"analysis/selection/objects/#additional-information-for-accessing-cms-physics-objects","text":"In Chapter 7 of the CMS Workbook one can find Analysis pages that provide additional information, which can be useful to check on top of the general strategy for accessing objects that was discussed above.","title":"Additional information for accessing CMS physics objects"},{"location":"analysis/selection/triggers/","text":"Triggers \u00b6 Warning This page is under construction","title":"Triggers"},{"location":"analysis/selection/triggers/#triggers","text":"Warning This page is under construction","title":"Triggers"},{"location":"analysis/selection/idefficiencystudy/efficiencytool/","text":"Efficiency Tools \u00b6 For CMS efficiency using tag and probe, we developed two codes separatelly for each method presented: Sideband Subtraction method and Fitting method. Both codes can be found in this link: Efficiency tools . Both codes are explained in details in next sections splitted in Sideband Subtraction Reference Guide (SB) and Fitting Method Reference Guide (Fit) . Note In the guide we use function(...) in title when a function has arguments. Function with no arguments are written function() without \"...\". Workshop tutorial \u00b6 Besides the references guide, there is a tutorial included in this guide that was used as a material for a workshop for theoretical physics.","title":"Efficiency Tool"},{"location":"analysis/selection/idefficiencystudy/efficiencytool/#efficiency-tools","text":"For CMS efficiency using tag and probe, we developed two codes separatelly for each method presented: Sideband Subtraction method and Fitting method. Both codes can be found in this link: Efficiency tools . Both codes are explained in details in next sections splitted in Sideband Subtraction Reference Guide (SB) and Fitting Method Reference Guide (Fit) . Note In the guide we use function(...) in title when a function has arguments. Function with no arguments are written function() without \"...\".","title":"Efficiency Tools"},{"location":"analysis/selection/idefficiencystudy/efficiencytool/#workshop-tutorial","text":"Besides the references guide, there is a tutorial included in this guide that was used as a material for a workshop for theoretical physics.","title":"Workshop tutorial"},{"location":"analysis/selection/idefficiencystudy/signalextraction/","text":"Signal Extraction \u00b6 Detector reconstruction efficiencies are calculated using signal muons, that is, only true candidates decaying to dimuons. This is achieved in this study by extracting signal from the data by the usage of some methods. Here it is presented two: sideband subtraction and fitting. Sideband subtraction method \u00b6 The sideband subtraction method involves choosing sideband and signal regions in invariant mass distribution for each tag+probe pair. The signal region is selected by finding the ressonance position and defining a region around it. While the signal region contains both signal and background, the sideband region is chosen such as to have only background, with a distance from signal region. A example of those regions selection can be seen below for the J/psi ressonance. For each event category (i.e. Pass and All), and for a given variable of interest (e.g., the probe pT), two distributions are obtained, one for each region (Signal and Sideband). In order to obtain the variable distribution for the signal only, we proceed by subtracting the Background distribution (Sideband region) from the Signal+Background one (Signal region): Where the normalization \u03b1 factor quantifies the quantity of background present in the signal region: And for the uncertainty: Applying those equations we get histograms like this: Solid blue line (Total) = particles in signal region; Dashed blue line (Background) = particles in sideband regions; Solid magenta line (signal) = signal histogram subtracted. Fitting method \u00b6 In this method, the signal is extracted not by histogram manipulation but by likelihood fitting. The procedure is applied after splitting the data in sub-samples, corresponding to bins of the kinematic variable of interest of the probe objects. As such, the efficiency will be measured as a function of that variable. Each sub-sample contains signal and background events; the signal is accessed by fitting the invariant mass spectra The fit for each bin allows to statistically discriminate between signal and background. In particular, the fit yields the number of signal events. The efficiency is finally obtained by simply forming the ratio of the signal yield from the fit to the passing category by the signal yield from the fit of the inclusive all category. This approach is illustrated below.","title":"Signal extraction"},{"location":"analysis/selection/idefficiencystudy/signalextraction/#signal-extraction","text":"Detector reconstruction efficiencies are calculated using signal muons, that is, only true candidates decaying to dimuons. This is achieved in this study by extracting signal from the data by the usage of some methods. Here it is presented two: sideband subtraction and fitting.","title":"Signal Extraction"},{"location":"analysis/selection/idefficiencystudy/signalextraction/#sideband-subtraction-method","text":"The sideband subtraction method involves choosing sideband and signal regions in invariant mass distribution for each tag+probe pair. The signal region is selected by finding the ressonance position and defining a region around it. While the signal region contains both signal and background, the sideband region is chosen such as to have only background, with a distance from signal region. A example of those regions selection can be seen below for the J/psi ressonance. For each event category (i.e. Pass and All), and for a given variable of interest (e.g., the probe pT), two distributions are obtained, one for each region (Signal and Sideband). In order to obtain the variable distribution for the signal only, we proceed by subtracting the Background distribution (Sideband region) from the Signal+Background one (Signal region): Where the normalization \u03b1 factor quantifies the quantity of background present in the signal region: And for the uncertainty: Applying those equations we get histograms like this: Solid blue line (Total) = particles in signal region; Dashed blue line (Background) = particles in sideband regions; Solid magenta line (signal) = signal histogram subtracted.","title":"Sideband subtraction method"},{"location":"analysis/selection/idefficiencystudy/signalextraction/#fitting-method","text":"In this method, the signal is extracted not by histogram manipulation but by likelihood fitting. The procedure is applied after splitting the data in sub-samples, corresponding to bins of the kinematic variable of interest of the probe objects. As such, the efficiency will be measured as a function of that variable. Each sub-sample contains signal and background events; the signal is accessed by fitting the invariant mass spectra The fit for each bin allows to statistically discriminate between signal and background. In particular, the fit yields the number of signal events. The efficiency is finally obtained by simply forming the ratio of the signal yield from the fit to the passing category by the signal yield from the fit of the inclusive all category. This approach is illustrated below.","title":"Fitting method"},{"location":"analysis/selection/idefficiencystudy/tagandprobe/","text":"Tag and Probe \u00b6 The Tag and Probe method is an experimental procedure commonly used in particle physics that allows to measure a process\u2019 efficiency directly from data. The procedure provides an unbiased sample of probe objects that can be then used to measure the efficiency of a particular selection criteria. Tag and Probe method \u00b6 This method is a data-driven technique and it is based on decays of known ressonances in pair of particles. The decaying muons are labeled according to the following criteria: Tag muon : well identified, triggered muon (tight selection criteria). Probe muon : unbiased set of muon candidates (very loose selection criteria), either passing or failing the criteria for which the eciency is to be measured. Tag muon are employed to trigger the presence of a resonance decay while probe muons, paired to tag muons, will be used for getting efficiency due its' unbiased characteristic. CMS Efficiency \u00b6 The efficiency will be given by the fraction of probe muons that pass a given criteria (in this case, the Muon ID which is explained below): The denominator corresponds to the number of resonance candidates (tag+probe pairs) reconstructed in the dataset. The numerator corresponds to the subset for which the probe passes the criteria. CMS Muon identification and reconstruction \u00b6 In the standard CMS reconstruction for proton-proton collisions, tracks are first reconstructed independently in the inner tracker and in the muon system. Based on these objects, three reconstruction approaches are used: Tracker Muon reconstruction: all tracker tracks with pT > 0.5 GeV/c and total momentum p > 2.5 GeV/c are considered as possible muon candidates, and are extrapolated to the muon system taking into account the magnetic field; Standalone Muon reconstruction: all tracks of the segments reconstructed in the muon chambers (performed using segments and hits from Drift Tubes in the barrel region, Cathode Strip Chambers and Resistive Plates Chambers in the endcaps) are used to generate \u201cseeds\u201d consisting of position and direction vectors and an estimate of the muon transverse momentum; Global Muon reconstruction: starts from a Standalone reconstructed muon track and extrapolates its trajectory from the innermost muon station through the coil and both calorimeters to the outer tracker surface. These are illustrated below: Note You can find more details concerning CMS Muon Identification and reconstruction in this paper JINST 7 (2012) P10002 .","title":"Tag and Probe"},{"location":"analysis/selection/idefficiencystudy/tagandprobe/#tag-and-probe","text":"The Tag and Probe method is an experimental procedure commonly used in particle physics that allows to measure a process\u2019 efficiency directly from data. The procedure provides an unbiased sample of probe objects that can be then used to measure the efficiency of a particular selection criteria.","title":"Tag and Probe"},{"location":"analysis/selection/idefficiencystudy/tagandprobe/#tag-and-probe-method","text":"This method is a data-driven technique and it is based on decays of known ressonances in pair of particles. The decaying muons are labeled according to the following criteria: Tag muon : well identified, triggered muon (tight selection criteria). Probe muon : unbiased set of muon candidates (very loose selection criteria), either passing or failing the criteria for which the eciency is to be measured. Tag muon are employed to trigger the presence of a resonance decay while probe muons, paired to tag muons, will be used for getting efficiency due its' unbiased characteristic.","title":"Tag and Probe method"},{"location":"analysis/selection/idefficiencystudy/tagandprobe/#cms-efficiency","text":"The efficiency will be given by the fraction of probe muons that pass a given criteria (in this case, the Muon ID which is explained below): The denominator corresponds to the number of resonance candidates (tag+probe pairs) reconstructed in the dataset. The numerator corresponds to the subset for which the probe passes the criteria.","title":"CMS Efficiency"},{"location":"analysis/selection/idefficiencystudy/tagandprobe/#cms-muon-identification-and-reconstruction","text":"In the standard CMS reconstruction for proton-proton collisions, tracks are first reconstructed independently in the inner tracker and in the muon system. Based on these objects, three reconstruction approaches are used: Tracker Muon reconstruction: all tracker tracks with pT > 0.5 GeV/c and total momentum p > 2.5 GeV/c are considered as possible muon candidates, and are extrapolated to the muon system taking into account the magnetic field; Standalone Muon reconstruction: all tracks of the segments reconstructed in the muon chambers (performed using segments and hits from Drift Tubes in the barrel region, Cathode Strip Chambers and Resistive Plates Chambers in the endcaps) are used to generate \u201cseeds\u201d consisting of position and direction vectors and an estimate of the muon transverse momentum; Global Muon reconstruction: starts from a Standalone reconstructed muon track and extrapolates its trajectory from the innermost muon station through the coil and both calorimeters to the outer tracker surface. These are illustrated below: Note You can find more details concerning CMS Muon Identification and reconstruction in this paper JINST 7 (2012) P10002 .","title":"CMS Muon identification and reconstruction"},{"location":"analysis/selection/idefficiencystudy/fittingreferenceguide/mainfunctions/","text":"Main Functions \u00b6 get_conditions(...) \u00b6 string * get_conditions ( int bin_n , double * bins , string quantity ) Outputs conditions that specifie the cuts to be applied to the dataset. doFit(...) \u00b6 double * doFit ( string condition , string MuonID_str , bool save = TRUE ) // RETURNS ARRAY WITH [yield_all, yield_pass, err_all, err_pass] Function that handles the fitting. Has as an input a string condition that specifies the cut to be applied to the dataset (The location to the .root is set inside the function). string MuonID_str specifies the Muon ID that we want to study. McYield(...) \u00b6 double * McYield ( string condition ) Returns number yield of Monte Carlo data (data is only signal). make_hist(...) \u00b6 TH1F * make_hist ( string name , double ** values , int qnt , int bin_n , Double_t * binning , bool IsDataMc , bool DRAW = FALSE ) Generates TH1F * histograms direclty from values which stores doFit 's outputs. qnt specifies if the histogram stores data from All muons or from Probe muons. get_efficiency(...) \u00b6 TEfficiency * get_efficiency ( TH1F * ALL , TH1F * PASS ) Function used to calculate the efficiency. change_bin(...) \u00b6 void change_bin ( string condition , string hist_file = \"Histograms_Run2011.root\" ) Once the Macro Efficiency.C finishes running, sometimes we are left with poor fit results (sometimes the results are terrible on a specific bin!). This functions allows changes on a specific bin. It is recommended to change the initial conditions of the fitting parameters, on the doFit function. Auxiliary Functions \u00b6 get_TTree_from_ntupple(...) \u00b6 void get_TTree_from_ntupple () This function merges two seperate TTree files into one.","title":"Main Functions"},{"location":"analysis/selection/idefficiencystudy/fittingreferenceguide/mainfunctions/#main-functions","text":"","title":"Main Functions"},{"location":"analysis/selection/idefficiencystudy/fittingreferenceguide/mainfunctions/#get_conditions","text":"string * get_conditions ( int bin_n , double * bins , string quantity ) Outputs conditions that specifie the cuts to be applied to the dataset.","title":"get_conditions(...)"},{"location":"analysis/selection/idefficiencystudy/fittingreferenceguide/mainfunctions/#dofit","text":"double * doFit ( string condition , string MuonID_str , bool save = TRUE ) // RETURNS ARRAY WITH [yield_all, yield_pass, err_all, err_pass] Function that handles the fitting. Has as an input a string condition that specifies the cut to be applied to the dataset (The location to the .root is set inside the function). string MuonID_str specifies the Muon ID that we want to study.","title":"doFit(...)"},{"location":"analysis/selection/idefficiencystudy/fittingreferenceguide/mainfunctions/#mcyield","text":"double * McYield ( string condition ) Returns number yield of Monte Carlo data (data is only signal).","title":"McYield(...)"},{"location":"analysis/selection/idefficiencystudy/fittingreferenceguide/mainfunctions/#make_hist","text":"TH1F * make_hist ( string name , double ** values , int qnt , int bin_n , Double_t * binning , bool IsDataMc , bool DRAW = FALSE ) Generates TH1F * histograms direclty from values which stores doFit 's outputs. qnt specifies if the histogram stores data from All muons or from Probe muons.","title":"make_hist(...)"},{"location":"analysis/selection/idefficiencystudy/fittingreferenceguide/mainfunctions/#get_efficiency","text":"TEfficiency * get_efficiency ( TH1F * ALL , TH1F * PASS ) Function used to calculate the efficiency.","title":"get_efficiency(...)"},{"location":"analysis/selection/idefficiencystudy/fittingreferenceguide/mainfunctions/#change_bin","text":"void change_bin ( string condition , string hist_file = \"Histograms_Run2011.root\" ) Once the Macro Efficiency.C finishes running, sometimes we are left with poor fit results (sometimes the results are terrible on a specific bin!). This functions allows changes on a specific bin. It is recommended to change the initial conditions of the fitting parameters, on the doFit function.","title":"change_bin(...)"},{"location":"analysis/selection/idefficiencystudy/fittingreferenceguide/mainfunctions/#auxiliary-functions","text":"","title":"Auxiliary Functions"},{"location":"analysis/selection/idefficiencystudy/fittingreferenceguide/mainfunctions/#get_ttree_from_ntupple","text":"void get_TTree_from_ntupple () This function merges two seperate TTree files into one.","title":"get_TTree_from_ntupple(...)"},{"location":"analysis/selection/idefficiencystudy/fittingreferenceguide/readme/","text":"Calculating Efficiencies using Tag & Probe \u00b6 Setup \u00b6 This project was developed using ROOT , made available by CERN and the following Datasets: * [1] Run2011AMuOnia_mergeNtuple.root * [2] JPsiToMuMu_mergeMCNtuple.root From these two datasets, a .root file was generated for each MuonId (i.e Standalone , Tracker or Global ) using the get_root.C and then stored on the \\Data folder, following the respective hierarchy. Fitting Method \u00b6 The fitting method consists in dividing the quantity we want to use to calculate the efficiency into a certain amout of bins and then fitting the invariant mass of the muons (All and Passing) on the specified region. To compute the efficiency we simply divide the yield from the fit of the Passing muons by the yield of the fit of All the muons. The following image tries to illustrate this idea. WorkFlow \u00b6 Efficiency.C is given as an example of how to use the fitting method to calculate an efficiency. It follows as such: 1. The user has to manually define the bins in which the quantity being studied (i.e. pT, Eta, Phi) will be divided; 2. Generate conditions (that divide the dataset into the defined binned intervals) using get_conditions ; 3. Create a loop that fits the invariant mass for each bin using doFit when the dataset consists of real data and McYield for the Monte Carlo dataset. Running \u00b6 On this repository, do: root -l -b -q Efficiency.C Output \u00b6 Output images are stored in the /result folder.","title":"Read me"},{"location":"analysis/selection/idefficiencystudy/fittingreferenceguide/readme/#calculating-efficiencies-using-tag-probe","text":"","title":"Calculating Efficiencies using Tag &amp; Probe"},{"location":"analysis/selection/idefficiencystudy/fittingreferenceguide/readme/#setup","text":"This project was developed using ROOT , made available by CERN and the following Datasets: * [1] Run2011AMuOnia_mergeNtuple.root * [2] JPsiToMuMu_mergeMCNtuple.root From these two datasets, a .root file was generated for each MuonId (i.e Standalone , Tracker or Global ) using the get_root.C and then stored on the \\Data folder, following the respective hierarchy.","title":"Setup"},{"location":"analysis/selection/idefficiencystudy/fittingreferenceguide/readme/#fitting-method","text":"The fitting method consists in dividing the quantity we want to use to calculate the efficiency into a certain amout of bins and then fitting the invariant mass of the muons (All and Passing) on the specified region. To compute the efficiency we simply divide the yield from the fit of the Passing muons by the yield of the fit of All the muons. The following image tries to illustrate this idea.","title":"Fitting Method"},{"location":"analysis/selection/idefficiencystudy/fittingreferenceguide/readme/#workflow","text":"Efficiency.C is given as an example of how to use the fitting method to calculate an efficiency. It follows as such: 1. The user has to manually define the bins in which the quantity being studied (i.e. pT, Eta, Phi) will be divided; 2. Generate conditions (that divide the dataset into the defined binned intervals) using get_conditions ; 3. Create a loop that fits the invariant mass for each bin using doFit when the dataset consists of real data and McYield for the Monte Carlo dataset.","title":"WorkFlow"},{"location":"analysis/selection/idefficiencystudy/fittingreferenceguide/readme/#running","text":"On this repository, do: root -l -b -q Efficiency.C","title":"Running"},{"location":"analysis/selection/idefficiencystudy/fittingreferenceguide/readme/#output","text":"Output images are stored in the /result folder.","title":"Output"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/FitFunctions/","text":"class FitFunctions \u00b6 This class hold all fit functions for histograms. class FitFunctions::Primary \u00b6 This class is holding primary fit functions for histograms. Content list \u00b6 double Gaus(...) double Pol1(...) double Exp(...) double CrystalBall(...) Functions details \u00b6 Gaus(...) \u00b6 static double Gaus ( double * x , double * par ) Parameters: par = [ height , position , sigma ] Pol1(...) \u00b6 static double Pol1 ( double * x , double * par ) Parameters: par = [ b , a ] Pol3(...) \u00b6 static double Pol3 ( double * x , double * par ) Parameters: par = [ d , c , b , a ] Exp(...) \u00b6 static double Exp ( double * x , double * par ) Parameters: par = [ height , width ] CrystalBall(...) \u00b6 static double CrystalBall ( double * x , double * par ) Parameters: par = [ alpha , n , mean , sigma , yield ] class FitFunctions::Merged \u00b6 This class holds merged fit functions for histograms. Content list \u00b6 double Jpsi::Signal_InvariantMass() double Jpsi::Background_InvariantMass() double Jpsi::InvariantMass() double Upsilon::Signal_InvariantMass() double Upsilon::Background_InvariantMass() double Upsilon::InvariantMass() Functions details \u00b6 Jpsi::Signal_InvariantMass(...) \u00b6 static double Signal_InvariantMass ( double * x , double * par ) Form: Gaus + CrystalBall Parameters: par = [ height , position , sigma , alpha , n , mean , sigma , yield ] Jpsi::Background_InvariantMass(...) \u00b6 static double Background_InvariantMass ( double * x , double * par ) Form: Exp Parameters: par = [ b , a ] Jpsi::InvariantMass(...) \u00b6 static double Signal_InvariantMass ( double * x , double * par ) + Background_InvariantMass ( double * x , double * par ) Form: Gaus + CrystalBall + Exp Parameters: par = [ height1 , position1 , sigma1 , alpha2 , n2 , mean2 , sigma2 , yield2 , b , a ] Upsilon::Signal_InvariantMass(...) \u00b6 static double Signal_InvariantMass ( double * x , double * par ) Form: CrystalBall + Gaus + Gaus Parameters: par = [ alpha1 , n1 , mean1 , sigma1 , yield1 , height2 , position2 , sigma2 , height3 , position3 , sigma3 ] Upsilon::Background_InvariantMass(...) \u00b6 static double Background_InvariantMass ( double * x , double * par ) Form: Pol3 Parameters: par = [ d , c , b , a ] Upsilon::InvariantMass(...) \u00b6 static double Signal_InvariantMass ( double * x , double * par ) + Background_InvariantMass ( double * x , double * par ) Form: CrystalBall + Gaus + Gaus + Pol3 Parameters: par = [ alpha1 , n1 , mean1 , sigma1 , yield1 , height2 , position2 , sigma2 , height3 , position3 , sigma3 , d , c , b , a ]","title":"FitFunction class"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/FitFunctions/#class-fitfunctions","text":"This class hold all fit functions for histograms.","title":"class FitFunctions"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/FitFunctions/#class-fitfunctionsprimary","text":"This class is holding primary fit functions for histograms.","title":"class FitFunctions::Primary"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/FitFunctions/#content-list","text":"double Gaus(...) double Pol1(...) double Exp(...) double CrystalBall(...)","title":"Content list"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/FitFunctions/#functions-details","text":"","title":"Functions details"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/FitFunctions/#gaus","text":"static double Gaus ( double * x , double * par ) Parameters: par = [ height , position , sigma ]","title":"Gaus(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/FitFunctions/#pol1","text":"static double Pol1 ( double * x , double * par ) Parameters: par = [ b , a ]","title":"Pol1(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/FitFunctions/#pol3","text":"static double Pol3 ( double * x , double * par ) Parameters: par = [ d , c , b , a ]","title":"Pol3(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/FitFunctions/#exp","text":"static double Exp ( double * x , double * par ) Parameters: par = [ height , width ]","title":"Exp(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/FitFunctions/#crystalball","text":"static double CrystalBall ( double * x , double * par ) Parameters: par = [ alpha , n , mean , sigma , yield ]","title":"CrystalBall(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/FitFunctions/#class-fitfunctionsmerged","text":"This class holds merged fit functions for histograms.","title":"class FitFunctions::Merged"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/FitFunctions/#content-list_1","text":"double Jpsi::Signal_InvariantMass() double Jpsi::Background_InvariantMass() double Jpsi::InvariantMass() double Upsilon::Signal_InvariantMass() double Upsilon::Background_InvariantMass() double Upsilon::InvariantMass()","title":"Content list"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/FitFunctions/#functions-details_1","text":"","title":"Functions details"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/FitFunctions/#jpsisignal_invariantmass","text":"static double Signal_InvariantMass ( double * x , double * par ) Form: Gaus + CrystalBall Parameters: par = [ height , position , sigma , alpha , n , mean , sigma , yield ]","title":"Jpsi::Signal_InvariantMass(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/FitFunctions/#jpsibackground_invariantmass","text":"static double Background_InvariantMass ( double * x , double * par ) Form: Exp Parameters: par = [ b , a ]","title":"Jpsi::Background_InvariantMass(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/FitFunctions/#jpsiinvariantmass","text":"static double Signal_InvariantMass ( double * x , double * par ) + Background_InvariantMass ( double * x , double * par ) Form: Gaus + CrystalBall + Exp Parameters: par = [ height1 , position1 , sigma1 , alpha2 , n2 , mean2 , sigma2 , yield2 , b , a ]","title":"Jpsi::InvariantMass(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/FitFunctions/#upsilonsignal_invariantmass","text":"static double Signal_InvariantMass ( double * x , double * par ) Form: CrystalBall + Gaus + Gaus Parameters: par = [ alpha1 , n1 , mean1 , sigma1 , yield1 , height2 , position2 , sigma2 , height3 , position3 , sigma3 ]","title":"Upsilon::Signal_InvariantMass(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/FitFunctions/#upsilonbackground_invariantmass","text":"static double Background_InvariantMass ( double * x , double * par ) Form: Pol3 Parameters: par = [ d , c , b , a ]","title":"Upsilon::Background_InvariantMass(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/FitFunctions/#upsiloninvariantmass","text":"static double Signal_InvariantMass ( double * x , double * par ) + Background_InvariantMass ( double * x , double * par ) Form: CrystalBall + Gaus + Gaus + Pol3 Parameters: par = [ alpha1 , n1 , mean1 , sigma1 , yield1 , height2 , position2 , sigma2 , height3 , position3 , sigma3 , d , c , b , a ]","title":"Upsilon::InvariantMass(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/InvariantMass/","text":"class InvariantMass \u00b6 Holds MassValues struct . Constructor details \u00b6 InvariantMass ( const char *& resonance , const char *& particleName , const char *& canvasWatermark , const char *& directoryToSave , const char *& particleType ) : resonance ( resonance ), particleName ( particleName ), canvasWatermark ( canvasWatermark ), directoryToSave ( directoryToSave ), particleType ( particleType ) { if ( strcmp ( resonance , \"Jpsi\" ) == 0 ) { xMin = 2.9 ; xMax = 3.3 ; nBins = 160 ; } if ( strcmp ( resonance , \"Upsilon\" ) == 0 ) { xMin = 8.7 ; xMax = 11. ; nBins = 60 ; } if ( strcmp ( resonance , \"Upsilon1S\" ) == 0 ) { xMin = 8.7 ; xMax = 11. ; nBins = 60 ; } createMassHistogram ( Pass . hMass , \"Passing\" ); createMassHistogram ( All . hMass , \"All\" ); } Private variable details \u00b6 Summary Type Name const char*& resonance const char*& particleName const char*& canvasWatermark const char*& directoryToSave const char*& particleType All variables here are reference for public variables in mother class: Type class Private Functions details \u00b6 createMassHistogram(...) \u00b6 void createMassHistogram ( TH1D * & hMass , const char * PassingOrFailing ) Create invariant mass histogram with a specific title. The argument hMass is a pointer where the histogram shall be stored. drawCanvasQuarter(...) \u00b6 void drawCanvasQuarter ( TCanvas * & canvas , bool drawRegions , int quarter , MassValues * ObjMassValues , int color = kBlue ) Draw a quarter of whole canvas with invariant mass histogram pointed. Public variable details \u00b6 Summary Type Name Default value double xMin 0. double xMax 0. int nBins 0 int decimals 3 Constructed objects MassValues Pass Stores information about passing mass histograms. MassValues All Stores information about passing mass histograms. Public Functions details \u00b6 createMassCanvas(...) \u00b6 TCanvas * createMassCanvas ( bool drawRegions = false , bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for invariant mass (passing and all muons). defineMassHistogramNumbers() \u00b6 void defineMassHistogramNumbers ( int nBins , double xMin , double xMax , int decimals = 3 ) Redefine number parameters of mass histograms in Mass object. doFit() \u00b6 void doFit () Apply a fit over invariant mass in MassValues objects. fillMassHistograms(...) \u00b6 void fillMassHistograms ( double ** quantities , int ** types ) Automatically fill masses histograms. Needs to be called in a loop over all dataset. updateMassValuesAll() \u00b6 void updateMassValuesAll () After fill invariant mass histogram, you need to set signal regions and sideband regions. This function will set it for you. updateMassValuesAll(...) \u00b6 void updateMassValuesFor ( MassValues * ObjMassValues , bool isAll = false ) After fill invariant mass histograms, you need to set signal regions and sideband regions. This function will set it for you. writeMassHistogramsOnFile(...) \u00b6 void writeMassHistogramsOnFile ( bool writehPass , bool writehAll ) Write all mass canvas histograms in a root file. Just need to call this function and all mass histograms will be written.","title":"InvariantMass class"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/InvariantMass/#class-invariantmass","text":"Holds MassValues struct .","title":"class InvariantMass"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/InvariantMass/#constructor-details","text":"InvariantMass ( const char *& resonance , const char *& particleName , const char *& canvasWatermark , const char *& directoryToSave , const char *& particleType ) : resonance ( resonance ), particleName ( particleName ), canvasWatermark ( canvasWatermark ), directoryToSave ( directoryToSave ), particleType ( particleType ) { if ( strcmp ( resonance , \"Jpsi\" ) == 0 ) { xMin = 2.9 ; xMax = 3.3 ; nBins = 160 ; } if ( strcmp ( resonance , \"Upsilon\" ) == 0 ) { xMin = 8.7 ; xMax = 11. ; nBins = 60 ; } if ( strcmp ( resonance , \"Upsilon1S\" ) == 0 ) { xMin = 8.7 ; xMax = 11. ; nBins = 60 ; } createMassHistogram ( Pass . hMass , \"Passing\" ); createMassHistogram ( All . hMass , \"All\" ); }","title":"Constructor details"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/InvariantMass/#private-variable-details","text":"Summary Type Name const char*& resonance const char*& particleName const char*& canvasWatermark const char*& directoryToSave const char*& particleType All variables here are reference for public variables in mother class: Type class","title":"Private variable details"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/InvariantMass/#private-functions-details","text":"","title":"Private Functions details"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/InvariantMass/#createmasshistogram","text":"void createMassHistogram ( TH1D * & hMass , const char * PassingOrFailing ) Create invariant mass histogram with a specific title. The argument hMass is a pointer where the histogram shall be stored.","title":"createMassHistogram(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/InvariantMass/#drawcanvasquarter","text":"void drawCanvasQuarter ( TCanvas * & canvas , bool drawRegions , int quarter , MassValues * ObjMassValues , int color = kBlue ) Draw a quarter of whole canvas with invariant mass histogram pointed.","title":"drawCanvasQuarter(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/InvariantMass/#public-variable-details","text":"Summary Type Name Default value double xMin 0. double xMax 0. int nBins 0 int decimals 3 Constructed objects MassValues Pass Stores information about passing mass histograms. MassValues All Stores information about passing mass histograms.","title":"Public variable details"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/InvariantMass/#public-functions-details","text":"","title":"Public Functions details"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/InvariantMass/#createmasscanvas","text":"TCanvas * createMassCanvas ( bool drawRegions = false , bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for invariant mass (passing and all muons).","title":"createMassCanvas(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/InvariantMass/#definemasshistogramnumbers","text":"void defineMassHistogramNumbers ( int nBins , double xMin , double xMax , int decimals = 3 ) Redefine number parameters of mass histograms in Mass object.","title":"defineMassHistogramNumbers()"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/InvariantMass/#dofit","text":"void doFit () Apply a fit over invariant mass in MassValues objects.","title":"doFit()"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/InvariantMass/#fillmasshistograms","text":"void fillMassHistograms ( double ** quantities , int ** types ) Automatically fill masses histograms. Needs to be called in a loop over all dataset.","title":"fillMassHistograms(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/InvariantMass/#updatemassvaluesall","text":"void updateMassValuesAll () After fill invariant mass histogram, you need to set signal regions and sideband regions. This function will set it for you.","title":"updateMassValuesAll()"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/InvariantMass/#updatemassvaluesall_1","text":"void updateMassValuesFor ( MassValues * ObjMassValues , bool isAll = false ) After fill invariant mass histograms, you need to set signal regions and sideband regions. This function will set it for you.","title":"updateMassValuesAll(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/InvariantMass/#writemasshistogramsonfile","text":"void writeMassHistogramsOnFile ( bool writehPass , bool writehAll ) Write all mass canvas histograms in a root file. Just need to call this function and all mass histograms will be written.","title":"writeMassHistogramsOnFile(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/MassValues/","text":"struct MassValues \u00b6 Holds informations about passing or all particles fit. Public variable details \u00b6 Summary Type Name Default value TH1D* hMass NULL TF1* fitFunction NULL TF1* fitSignal NULL TF1* fitBackground NULL double sidebandRegion1_x1 0. double sidebandRegion1_x2 0. double signalRegion_x1 0. double signalRegion_x2 0. double sidebandRegion2_x1 0. double sidebandRegion2_x2 0. TFitResultPtr fitResult 0 Public Functions details \u00b6 createTBox(...) \u00b6 TBox * createTBox ( double Ymax , int index = 0 , double Ymin = 0. ) Return TBox of sideband or signal region. if index = -1 return TBox representing left sideband region. if index = 0 return TBox representing signal region. if index = 1 return TBox representing right sideband region. doFitJpsi() \u00b6 void doFitJpsi () Do fit for J/psi resonance. doFitUpsilon() \u00b6 void doFitUpsilon () Do fit for Upsilon resonance with 3 resonances peaks (1S, 2S, 3S). doFitUpsilon1S() \u00b6 void doFitUpsilon1S () Do fit for Upsilon (1S) resonance. isInSidebandRegion(...) \u00b6 bool isInSidebandRegion ( double InvariantMass ) Check if InvariantMass is in sideband region. isInSignalRegion(...) \u00b6 bool isInSignalRegion ( double InvariantMass ) Check if InvariantMass is in signal region. subtractionFactor() \u00b6 double subtractionFactor () Get the subtraction factor calculated by the ratio between yield of background particles in signal region by yield of background particles in sideband region. This yield is get by the integral of function stored in fitBackground variable.","title":"MassValues struct"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/MassValues/#struct-massvalues","text":"Holds informations about passing or all particles fit.","title":"struct MassValues"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/MassValues/#public-variable-details","text":"Summary Type Name Default value TH1D* hMass NULL TF1* fitFunction NULL TF1* fitSignal NULL TF1* fitBackground NULL double sidebandRegion1_x1 0. double sidebandRegion1_x2 0. double signalRegion_x1 0. double signalRegion_x2 0. double sidebandRegion2_x1 0. double sidebandRegion2_x2 0. TFitResultPtr fitResult 0","title":"Public variable details"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/MassValues/#public-functions-details","text":"","title":"Public Functions details"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/MassValues/#createtbox","text":"TBox * createTBox ( double Ymax , int index = 0 , double Ymin = 0. ) Return TBox of sideband or signal region. if index = -1 return TBox representing left sideband region. if index = 0 return TBox representing signal region. if index = 1 return TBox representing right sideband region.","title":"createTBox(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/MassValues/#dofitjpsi","text":"void doFitJpsi () Do fit for J/psi resonance.","title":"doFitJpsi()"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/MassValues/#dofitupsilon","text":"void doFitUpsilon () Do fit for Upsilon resonance with 3 resonances peaks (1S, 2S, 3S).","title":"doFitUpsilon()"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/MassValues/#dofitupsilon1s","text":"void doFitUpsilon1S () Do fit for Upsilon (1S) resonance.","title":"doFitUpsilon1S()"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/MassValues/#isinsidebandregion","text":"bool isInSidebandRegion ( double InvariantMass ) Check if InvariantMass is in sideband region.","title":"isInSidebandRegion(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/MassValues/#isinsignalregion","text":"bool isInSignalRegion ( double InvariantMass ) Check if InvariantMass is in signal region.","title":"isInSignalRegion(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/MassValues/#subtractionfactor","text":"double subtractionFactor () Get the subtraction factor calculated by the ratio between yield of background particles in signal region by yield of background particles in sideband region. This yield is get by the integral of function stored in fitBackground variable.","title":"subtractionFactor()"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/PassingFailing/","text":"class PassingFailing \u00b6 Holds histograms of passing and all particle quantities. Constructor details \u00b6 PassingFailing ( const char *& resonance , const char *& particleName , const char *& canvasWatermark , const char *& directoryToSave , const char *& particleType , InvariantMass & ObjMass , const char *& tagOrProbe , const char * passingOrFailing , const char *& quantityName , const char *& xAxisName , const char *& quantityUnit , const char *& extendedQuantityName , double & xMin , double & xMax , int & nBins , int & decimals ) : resonance ( resonance ), particleName ( particleName ), canvasWatermark ( canvasWatermark ), directoryToSave ( directoryToSave ), particleType ( particleType ), ObjMass ( ObjMass ), tagOrProbe ( tagOrProbe ), passingOrFailing ( passingOrFailing ), quantityName ( quantityName ), xAxisName ( xAxisName ), quantityUnit ( quantityUnit ), extendedQuantityName ( extendedQuantityName ), nBins ( nBins ), xMin ( xMin ), xMax ( xMax ), decimals ( decimals ) { createHistogram ( hSigBack , \"SigBack\" ); createHistogram ( hSig , \"Sig\" ); createHistogram ( hBack , \"Back\" ); } Private variable details \u00b6 Summary Type Name const char*& resonance const char*& particleName const char*& canvasWatermark const char*& directoryToSave const char*& particleType const char*& tagOrProbe InvariantMass& ObjMass const char*& tagOrProbe const char*& xAxisName const char*& quantityUnit const char*& extendedQuantityName double& xMin double& xMax int& nBins int& decimals All variables here are reference for public variables in mother class: PtEtaPhi class . Private Functions details \u00b6 createHistogram() \u00b6 void createHistogram () Create quantity histogram. fillAfter() \u00b6 string fillAfter ( string text , char fillWith , int targetLength ) Fill blank space of a string. It is used in consistencyDebugCout(). Public variable details \u00b6 Summary Type Name Default value const char* passingOrFailing NULL TH1D* hSigBack NULL TH1D* hSig NULL TH1D* hBack NULL Details const char* passingOrFailing Set if it is \"Passing\" or \"All\" object. TH1D* hSigBack Stores the histogram for particles in signal region. TH1D* hSig Stores the subtracted histogram. TH1D* hBack Stores the histogram for particles in sideband region. Public Functions details \u00b6 consistencyDebugCout() \u00b6 void consistencyDebugCout () Print on terminal the consistency check after subtractSigHistogram(). It is result for this equation: N total - (alpha * N background + N signal ) Where: alpha = yield of background particles signal region / yield of background particles sideband region createQuantitiesCanvas(...) \u00b6 TCanvas * createQuantitiesCanvas ( bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all quantities after subtractSigHistograms(). fillQuantitiesHistograms(...) \u00b6 void fillQuantitiesHistograms ( double & InvariantMass , int & isPassing ) Automatically fill all quantities histograms. Needs to be called in a loop over all dataset. normalizeHistograms() \u00b6 void normalizeHistograms () Normalize quantities histograms of variable bin after filling it. PassFailObj() \u00b6 MassValues * PassFailObj () Get the MassValue object of corresponding MassValue object. subtractSigHistogram() \u00b6 void subtractSigHistogram () Apply sideband subtraction over histograms. writeQuantitiesHistogramsOnFile(...) \u00b6 void writeQuantitiesHistogramsOnFile ( bool hSigBack , bool hSig , bool hBack ) Write quantity histograms in a root file. Just need to call this function and all quantities histograms will be written. It needs to be called after subtractSigHistograms().","title":"PassingFailing class"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/PassingFailing/#class-passingfailing","text":"Holds histograms of passing and all particle quantities.","title":"class PassingFailing"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/PassingFailing/#constructor-details","text":"PassingFailing ( const char *& resonance , const char *& particleName , const char *& canvasWatermark , const char *& directoryToSave , const char *& particleType , InvariantMass & ObjMass , const char *& tagOrProbe , const char * passingOrFailing , const char *& quantityName , const char *& xAxisName , const char *& quantityUnit , const char *& extendedQuantityName , double & xMin , double & xMax , int & nBins , int & decimals ) : resonance ( resonance ), particleName ( particleName ), canvasWatermark ( canvasWatermark ), directoryToSave ( directoryToSave ), particleType ( particleType ), ObjMass ( ObjMass ), tagOrProbe ( tagOrProbe ), passingOrFailing ( passingOrFailing ), quantityName ( quantityName ), xAxisName ( xAxisName ), quantityUnit ( quantityUnit ), extendedQuantityName ( extendedQuantityName ), nBins ( nBins ), xMin ( xMin ), xMax ( xMax ), decimals ( decimals ) { createHistogram ( hSigBack , \"SigBack\" ); createHistogram ( hSig , \"Sig\" ); createHistogram ( hBack , \"Back\" ); }","title":"Constructor details"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/PassingFailing/#private-variable-details","text":"Summary Type Name const char*& resonance const char*& particleName const char*& canvasWatermark const char*& directoryToSave const char*& particleType const char*& tagOrProbe InvariantMass& ObjMass const char*& tagOrProbe const char*& xAxisName const char*& quantityUnit const char*& extendedQuantityName double& xMin double& xMax int& nBins int& decimals All variables here are reference for public variables in mother class: PtEtaPhi class .","title":"Private variable details"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/PassingFailing/#private-functions-details","text":"","title":"Private Functions details"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/PassingFailing/#createhistogram","text":"void createHistogram () Create quantity histogram.","title":"createHistogram()"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/PassingFailing/#fillafter","text":"string fillAfter ( string text , char fillWith , int targetLength ) Fill blank space of a string. It is used in consistencyDebugCout().","title":"fillAfter()"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/PassingFailing/#public-variable-details","text":"Summary Type Name Default value const char* passingOrFailing NULL TH1D* hSigBack NULL TH1D* hSig NULL TH1D* hBack NULL Details const char* passingOrFailing Set if it is \"Passing\" or \"All\" object. TH1D* hSigBack Stores the histogram for particles in signal region. TH1D* hSig Stores the subtracted histogram. TH1D* hBack Stores the histogram for particles in sideband region.","title":"Public variable details"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/PassingFailing/#public-functions-details","text":"","title":"Public Functions details"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/PassingFailing/#consistencydebugcout","text":"void consistencyDebugCout () Print on terminal the consistency check after subtractSigHistogram(). It is result for this equation: N total - (alpha * N background + N signal ) Where: alpha = yield of background particles signal region / yield of background particles sideband region","title":"consistencyDebugCout()"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/PassingFailing/#createquantitiescanvas","text":"TCanvas * createQuantitiesCanvas ( bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all quantities after subtractSigHistograms().","title":"createQuantitiesCanvas(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/PassingFailing/#fillquantitieshistograms","text":"void fillQuantitiesHistograms ( double & InvariantMass , int & isPassing ) Automatically fill all quantities histograms. Needs to be called in a loop over all dataset.","title":"fillQuantitiesHistograms(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/PassingFailing/#normalizehistograms","text":"void normalizeHistograms () Normalize quantities histograms of variable bin after filling it.","title":"normalizeHistograms()"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/PassingFailing/#passfailobj","text":"MassValues * PassFailObj () Get the MassValue object of corresponding MassValue object.","title":"PassFailObj()"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/PassingFailing/#subtractsighistogram","text":"void subtractSigHistogram () Apply sideband subtraction over histograms.","title":"subtractSigHistogram()"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/PassingFailing/#writequantitieshistogramsonfile","text":"void writeQuantitiesHistogramsOnFile ( bool hSigBack , bool hSig , bool hBack ) Write quantity histograms in a root file. Just need to call this function and all quantities histograms will be written. It needs to be called after subtractSigHistograms().","title":"writeQuantitiesHistogramsOnFile(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/PtEtaPhi/","text":"class PtEtaPhi \u00b6 Holds PassingFailing class . Constructor details \u00b6 PtEtaPhi ( const char *& resonance , const char *& particleName , const char *& canvasWatermark , const char *& directoryToSave , const char *& particleType , InvariantMass & ObjMass , const char *& tagOrProbe , const char * quantityName , const char * xAxisName , const char * quantityUnit , const char * extendedQuantityName , int nBins , double xMin , double xMax , int decimals = 3 ) : resonance ( resonance ), particleName ( particleName ), canvasWatermark ( canvasWatermark ), directoryToSave ( directoryToSave ), particleType ( particleType ), ObjMass ( ObjMass ), tagOrProbe ( tagOrProbe ), quantityName ( quantityName ), xAxisName ( xAxisName ), quantityUnit ( quantityUnit ), extendedQuantityName ( extendedQuantityName ), nBins ( nBins ), xMin ( xMin ), xMax ( xMax ), decimals ( decimals ) {} Private variable details \u00b6 Summary Type Name const char*& resonance const char*& particleName const char*& canvasWatermark const char*& directoryToSave const char*& particleType const char*& tagOrProbe InvariantMass& ObjMass All variables here are reference for public variables in mother class: TagProbe class . Public variable details \u00b6 Summary Type Name Default value const char* tagOrProbe NULL const char* xAxisName NULL const char* quantityUnit NULL const char* extendedQuantityName NULL double xMin 0. double xMax 0. int nBins 0 int decimals 3 TEfficiency* pEff NULL Details const char* quantityName Stores the quantity name. E.g.: \"pT\". const char* extendedQuantityName Stores the extended quantity name. E.g.: \"Transversal Momentum\". const char* quantityUnit Stores the quantity unit. E.g.: \"GeV/c\". const char* xAxisName Stores the quantity name for histogram horizontal axis in LaTeX form. E.g.: \"p_{t}\". int nBins Stores the number of bins in histograms. int decimals = 3 Number of decimals showed in bin width on histogram vertical axis. double xMin Lower horizontal value of histogram. double xMax Higher horizontal value of histogram. TEfficiency* pEff Stores the efficiency plot. Constructed objects PassingFailing Pass Stores all informations about invariant masses, including fit and histograms. PassingFailing All Stores all informations about tag muons, incuding quantities histograms and efficiencies. Public Functions details \u00b6 consistencyDebugCout() \u00b6 void consistencyDebugCout () Print on terminal the consistency check after subtractSigHistograms(). createEfficiencyCanvas(...) \u00b6 void createEfficiencyCanvas ( bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all efficiencies calculated. It need to be called after createEfficiencyPlot(...). createEfficiencyPlot(...) \u00b6 TEfficiency * createEfficiencyPlot ( bool shouldWrite = false ) Create a TEfficiency object with calculated efficiency. It needs do be called after subtractSigHistograms(). createQuantitiesCanvas(...) \u00b6 TCanvas * createQuantitiesCanvas ( bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all quantities after subtractSigHistograms(). fillQuantitiesHistograms(...) \u00b6 void fillQuantitiesHistograms ( double & quantity , double & InvariantMass , int & isPassing ) Automatically fill all quantities histograms. Needs to be called in a loop over all dataset. normalizeHistograms() \u00b6 void normalizeHistograms () Normalize quantities histograms of variable bin after filling it. subtractSigHistograms() \u00b6 void subtractSigHistograms () Apply sideband subtraction over all histograms. writeQuantitiesHistogramsOnFile(...) \u00b6 void writeQuantitiesHistogramsOnFile ( bool hSigBack , bool hSig , bool hBack ) Write all quantities histograms in a root file. Just need to call this function and all quantities histograms will be written. It needs to be called after subtractSigHistograms().","title":"PtEtaPhi class"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/PtEtaPhi/#class-ptetaphi","text":"Holds PassingFailing class .","title":"class PtEtaPhi"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/PtEtaPhi/#constructor-details","text":"PtEtaPhi ( const char *& resonance , const char *& particleName , const char *& canvasWatermark , const char *& directoryToSave , const char *& particleType , InvariantMass & ObjMass , const char *& tagOrProbe , const char * quantityName , const char * xAxisName , const char * quantityUnit , const char * extendedQuantityName , int nBins , double xMin , double xMax , int decimals = 3 ) : resonance ( resonance ), particleName ( particleName ), canvasWatermark ( canvasWatermark ), directoryToSave ( directoryToSave ), particleType ( particleType ), ObjMass ( ObjMass ), tagOrProbe ( tagOrProbe ), quantityName ( quantityName ), xAxisName ( xAxisName ), quantityUnit ( quantityUnit ), extendedQuantityName ( extendedQuantityName ), nBins ( nBins ), xMin ( xMin ), xMax ( xMax ), decimals ( decimals ) {}","title":"Constructor details"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/PtEtaPhi/#private-variable-details","text":"Summary Type Name const char*& resonance const char*& particleName const char*& canvasWatermark const char*& directoryToSave const char*& particleType const char*& tagOrProbe InvariantMass& ObjMass All variables here are reference for public variables in mother class: TagProbe class .","title":"Private variable details"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/PtEtaPhi/#public-variable-details","text":"Summary Type Name Default value const char* tagOrProbe NULL const char* xAxisName NULL const char* quantityUnit NULL const char* extendedQuantityName NULL double xMin 0. double xMax 0. int nBins 0 int decimals 3 TEfficiency* pEff NULL Details const char* quantityName Stores the quantity name. E.g.: \"pT\". const char* extendedQuantityName Stores the extended quantity name. E.g.: \"Transversal Momentum\". const char* quantityUnit Stores the quantity unit. E.g.: \"GeV/c\". const char* xAxisName Stores the quantity name for histogram horizontal axis in LaTeX form. E.g.: \"p_{t}\". int nBins Stores the number of bins in histograms. int decimals = 3 Number of decimals showed in bin width on histogram vertical axis. double xMin Lower horizontal value of histogram. double xMax Higher horizontal value of histogram. TEfficiency* pEff Stores the efficiency plot. Constructed objects PassingFailing Pass Stores all informations about invariant masses, including fit and histograms. PassingFailing All Stores all informations about tag muons, incuding quantities histograms and efficiencies.","title":"Public variable details"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/PtEtaPhi/#public-functions-details","text":"","title":"Public Functions details"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/PtEtaPhi/#consistencydebugcout","text":"void consistencyDebugCout () Print on terminal the consistency check after subtractSigHistograms().","title":"consistencyDebugCout()"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/PtEtaPhi/#createefficiencycanvas","text":"void createEfficiencyCanvas ( bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all efficiencies calculated. It need to be called after createEfficiencyPlot(...).","title":"createEfficiencyCanvas(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/PtEtaPhi/#createefficiencyplot","text":"TEfficiency * createEfficiencyPlot ( bool shouldWrite = false ) Create a TEfficiency object with calculated efficiency. It needs do be called after subtractSigHistograms().","title":"createEfficiencyPlot(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/PtEtaPhi/#createquantitiescanvas","text":"TCanvas * createQuantitiesCanvas ( bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all quantities after subtractSigHistograms().","title":"createQuantitiesCanvas(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/PtEtaPhi/#fillquantitieshistograms","text":"void fillQuantitiesHistograms ( double & quantity , double & InvariantMass , int & isPassing ) Automatically fill all quantities histograms. Needs to be called in a loop over all dataset.","title":"fillQuantitiesHistograms(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/PtEtaPhi/#normalizehistograms","text":"void normalizeHistograms () Normalize quantities histograms of variable bin after filling it.","title":"normalizeHistograms()"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/PtEtaPhi/#subtractsighistograms","text":"void subtractSigHistograms () Apply sideband subtraction over all histograms.","title":"subtractSigHistograms()"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/PtEtaPhi/#writequantitieshistogramsonfile","text":"void writeQuantitiesHistogramsOnFile ( bool hSigBack , bool hSig , bool hBack ) Write all quantities histograms in a root file. Just need to call this function and all quantities histograms will be written. It needs to be called after subtractSigHistograms().","title":"writeQuantitiesHistogramsOnFile(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/SidebandSubtraction/","text":"class SidebandSubtraction \u00b6 Holds Type class . This is the mother class. Constructor details \u00b6 SidebandSubtraction () {} SidebandSubtraction ( const char * resonance ) : resonance ( resonance ) {} Public variable details \u00b6 Summary Type Name Default value const char* resonance \"Jpsi\" const char* particleName \"Muon\" const char* canvasWatermark \"#bf{CMS Open Data}\" const char* directoryToSave \"../result/\" bool doTracker true bool doStandalone true bool doGlobal true bool doTagMuon true bool doProbeMuon true Details const char* resonance = \"Jpsi\" Supports values \"Jpsi\" , \"Upsilon\" or \"Upsilon(1S)\" . const char* particleName = \"Muon\" Stores the particle name for titles. const char* canvasWatermark = \"#bf{CMS Open Data}\" Stores what watermark will be showed in plots. const char* directoryToSave = \"../result/\" Where all canvas will be stored. bool doTracker = true If it will compute Tracker muons efficiency. bool doStandalone = true If it will compute Standalone muons efficiency. bool doGlobal = true If it will compute Global muons efficiency. Constructed objects Type Tracker Stores all informations about Tracker muons. Type Standalone Stores all informations about Standalone muons. Type Global Stores all informations about Global muons. Public Functions details \u00b6 consistencyDebugCout() \u00b6 void consistencyDebugCout () Print on terminal the consistency check after subtractSigHistograms(). createEfficiencyCanvas(...) \u00b6 void createEfficiencyCanvas ( bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all efficiencies calculated. It need to be called after createEfficiencyPlot(...). createEfficiencyPlot(...) \u00b6 void createEfficiencyPlot ( bool shouldWrite = false ) Create a TEfficiency object with calculated efficiency. It needs do be called after subtractSigHistograms(). createMassCanvas(...) \u00b6 void createMassCanvas ( bool drawRegions = false , bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all invariant mass (passing and all muons). createQuantitiesCanvas(...) \u00b6 void createQuantitiesCanvas ( bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all quantities after subtractSigHistograms(). defineMassHistogramNumbers() \u00b6 void defineMassHistogramNumbers ( int nBins , double xMin , double xMax , int decimals = 3 ) Redefine number parameters of all mass histograms. doFit() \u00b6 void doFit () Apply a fit over all invariant mass stored. fillMassHistograms(...) \u00b6 void fillMassHistograms ( double ** quantities , int ** types ) Automatically fill all masses histograms. Needs to be called in a loop over all dataset. fillQuantitiesHistograms(...) \u00b6 void fillQuantitiesHistograms ( double ** quantities , int ** types ) Automatically fill all quantities histograms. Needs to be called in a loop over all dataset. normalizeHistograms() \u00b6 void normalizeHistograms () Normalize quantities histograms of variable bin after filling it. subtractSigHistograms() \u00b6 void subtractSigHistograms () Apply sideband subtraction over all histograms. updateMassValuesAll() \u00b6 void updateMassValuesAll () After fill invariant mass histograms, you need to set signal regions and sideband regions. This function will set it for you. writeMassHistogramsOnFile(...) \u00b6 void writeMassHistogramsOnFile ( bool writehPass , bool writehAll ) Write all mass canvas histograms in a root file. Just need to call this function and all mass histograms will be written. writeQuantitiesHistogramsOnFile(...) \u00b6 void writeQuantitiesHistogramsOnFile ( bool hSigBack , bool hSig , bool hBack ) Write all quantities histograms in a root file. Just need to call this function and all quantities histograms will be written. It needs to be called after subtractSigHistograms().","title":"SidebandSubtraction class"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/SidebandSubtraction/#class-sidebandsubtraction","text":"Holds Type class . This is the mother class.","title":"class SidebandSubtraction"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/SidebandSubtraction/#constructor-details","text":"SidebandSubtraction () {} SidebandSubtraction ( const char * resonance ) : resonance ( resonance ) {}","title":"Constructor details"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/SidebandSubtraction/#public-variable-details","text":"Summary Type Name Default value const char* resonance \"Jpsi\" const char* particleName \"Muon\" const char* canvasWatermark \"#bf{CMS Open Data}\" const char* directoryToSave \"../result/\" bool doTracker true bool doStandalone true bool doGlobal true bool doTagMuon true bool doProbeMuon true Details const char* resonance = \"Jpsi\" Supports values \"Jpsi\" , \"Upsilon\" or \"Upsilon(1S)\" . const char* particleName = \"Muon\" Stores the particle name for titles. const char* canvasWatermark = \"#bf{CMS Open Data}\" Stores what watermark will be showed in plots. const char* directoryToSave = \"../result/\" Where all canvas will be stored. bool doTracker = true If it will compute Tracker muons efficiency. bool doStandalone = true If it will compute Standalone muons efficiency. bool doGlobal = true If it will compute Global muons efficiency. Constructed objects Type Tracker Stores all informations about Tracker muons. Type Standalone Stores all informations about Standalone muons. Type Global Stores all informations about Global muons.","title":"Public variable details"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/SidebandSubtraction/#public-functions-details","text":"","title":"Public Functions details"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/SidebandSubtraction/#consistencydebugcout","text":"void consistencyDebugCout () Print on terminal the consistency check after subtractSigHistograms().","title":"consistencyDebugCout()"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/SidebandSubtraction/#createefficiencycanvas","text":"void createEfficiencyCanvas ( bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all efficiencies calculated. It need to be called after createEfficiencyPlot(...).","title":"createEfficiencyCanvas(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/SidebandSubtraction/#createefficiencyplot","text":"void createEfficiencyPlot ( bool shouldWrite = false ) Create a TEfficiency object with calculated efficiency. It needs do be called after subtractSigHistograms().","title":"createEfficiencyPlot(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/SidebandSubtraction/#createmasscanvas","text":"void createMassCanvas ( bool drawRegions = false , bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all invariant mass (passing and all muons).","title":"createMassCanvas(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/SidebandSubtraction/#createquantitiescanvas","text":"void createQuantitiesCanvas ( bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all quantities after subtractSigHistograms().","title":"createQuantitiesCanvas(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/SidebandSubtraction/#definemasshistogramnumbers","text":"void defineMassHistogramNumbers ( int nBins , double xMin , double xMax , int decimals = 3 ) Redefine number parameters of all mass histograms.","title":"defineMassHistogramNumbers()"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/SidebandSubtraction/#dofit","text":"void doFit () Apply a fit over all invariant mass stored.","title":"doFit()"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/SidebandSubtraction/#fillmasshistograms","text":"void fillMassHistograms ( double ** quantities , int ** types ) Automatically fill all masses histograms. Needs to be called in a loop over all dataset.","title":"fillMassHistograms(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/SidebandSubtraction/#fillquantitieshistograms","text":"void fillQuantitiesHistograms ( double ** quantities , int ** types ) Automatically fill all quantities histograms. Needs to be called in a loop over all dataset.","title":"fillQuantitiesHistograms(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/SidebandSubtraction/#normalizehistograms","text":"void normalizeHistograms () Normalize quantities histograms of variable bin after filling it.","title":"normalizeHistograms()"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/SidebandSubtraction/#subtractsighistograms","text":"void subtractSigHistograms () Apply sideband subtraction over all histograms.","title":"subtractSigHistograms()"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/SidebandSubtraction/#updatemassvaluesall","text":"void updateMassValuesAll () After fill invariant mass histograms, you need to set signal regions and sideband regions. This function will set it for you.","title":"updateMassValuesAll()"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/SidebandSubtraction/#writemasshistogramsonfile","text":"void writeMassHistogramsOnFile ( bool writehPass , bool writehAll ) Write all mass canvas histograms in a root file. Just need to call this function and all mass histograms will be written.","title":"writeMassHistogramsOnFile(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/SidebandSubtraction/#writequantitieshistogramsonfile","text":"void writeQuantitiesHistogramsOnFile ( bool hSigBack , bool hSig , bool hBack ) Write all quantities histograms in a root file. Just need to call this function and all quantities histograms will be written. It needs to be called after subtractSigHistograms().","title":"writeQuantitiesHistogramsOnFile(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/TagProbe/","text":"class TagProbe \u00b6 Holds TagProbe class and InvariantMass class . Constructor details \u00b6 TagProbe ( const char *& resonance , const char *& particleName , const char *& canvasWatermark , const char *& directoryToSave , const char *& particleType , InvariantMass & ObjMass , const char * tagOrProbe ) : resonance ( resonance ), particleName ( particleName ), canvasWatermark ( canvasWatermark ), directoryToSave ( directoryToSave ), particleType ( particleType ), ObjMass ( ObjMass ), tagOrProbe ( tagOrProbe ) {} Private variable details \u00b6 Summary Type Name const char*& resonance const char*& particleName const char*& canvasWatermark const char*& directoryToSave const char*& particleType InvariantMass& ObjMass All variables here are reference for public variables in mother class: Type class Public variable details \u00b6 Summary Type Name Default value const char* tagOrProbe NULL Details const char* tagOrProbe = NULL Set if it is \"Tag\" or \"Probe\" object Constructed objects PtEtaPhi Pt Transversal momentum histograms. PtEtaPhi Eta Pseudorapidity histograms. PtEtaPhi Phi Azimutal angle histograms. Public Functions details \u00b6 consistencyDebugCout() \u00b6 void consistencyDebugCout () Print on terminal the consistency check after subtractSigHistograms(). createEfficiencyCanvas(...) \u00b6 void createEfficiencyCanvas ( bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all efficiencies calculated. It need to be called after createEfficiencyPlot(...). createEfficiencyPlot(...) \u00b6 void createEfficiencyPlot ( bool shouldWrite = false ) Create a TEfficiency object with calculated efficiency. It needs do be called after subtractSigHistograms(). createQuantitiesCanvas(...) \u00b6 void createQuantitiesCanvas ( bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all quantities after subtractSigHistograms(). fillQuantitiesHistograms(...) \u00b6 void fillQuantitiesHistograms ( double ** quantities , double & InvariantMass , int & isPassing ) Automatically fill all quantities histograms. Needs to be called in a loop over all dataset. normalizeHistograms() \u00b6 void normalizeHistograms () Normalize quantities histograms of variable bin after filling it. subtractSigHistograms() \u00b6 void subtractSigHistograms () Apply sideband subtraction over all histograms. writeQuantitiesHistogramsOnFile(...) \u00b6 void writeQuantitiesHistogramsOnFile ( bool hSigBack , bool hSig , bool hBack ) Write all quantities histograms in a root file. Just need to call this function and all quantities histograms will be written. It needs to be called after subtractSigHistograms().","title":"TagProbe class"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/TagProbe/#class-tagprobe","text":"Holds TagProbe class and InvariantMass class .","title":"class TagProbe"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/TagProbe/#constructor-details","text":"TagProbe ( const char *& resonance , const char *& particleName , const char *& canvasWatermark , const char *& directoryToSave , const char *& particleType , InvariantMass & ObjMass , const char * tagOrProbe ) : resonance ( resonance ), particleName ( particleName ), canvasWatermark ( canvasWatermark ), directoryToSave ( directoryToSave ), particleType ( particleType ), ObjMass ( ObjMass ), tagOrProbe ( tagOrProbe ) {}","title":"Constructor details"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/TagProbe/#private-variable-details","text":"Summary Type Name const char*& resonance const char*& particleName const char*& canvasWatermark const char*& directoryToSave const char*& particleType InvariantMass& ObjMass All variables here are reference for public variables in mother class: Type class","title":"Private variable details"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/TagProbe/#public-variable-details","text":"Summary Type Name Default value const char* tagOrProbe NULL Details const char* tagOrProbe = NULL Set if it is \"Tag\" or \"Probe\" object Constructed objects PtEtaPhi Pt Transversal momentum histograms. PtEtaPhi Eta Pseudorapidity histograms. PtEtaPhi Phi Azimutal angle histograms.","title":"Public variable details"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/TagProbe/#public-functions-details","text":"","title":"Public Functions details"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/TagProbe/#consistencydebugcout","text":"void consistencyDebugCout () Print on terminal the consistency check after subtractSigHistograms().","title":"consistencyDebugCout()"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/TagProbe/#createefficiencycanvas","text":"void createEfficiencyCanvas ( bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all efficiencies calculated. It need to be called after createEfficiencyPlot(...).","title":"createEfficiencyCanvas(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/TagProbe/#createefficiencyplot","text":"void createEfficiencyPlot ( bool shouldWrite = false ) Create a TEfficiency object with calculated efficiency. It needs do be called after subtractSigHistograms().","title":"createEfficiencyPlot(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/TagProbe/#createquantitiescanvas","text":"void createQuantitiesCanvas ( bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all quantities after subtractSigHistograms().","title":"createQuantitiesCanvas(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/TagProbe/#fillquantitieshistograms","text":"void fillQuantitiesHistograms ( double ** quantities , double & InvariantMass , int & isPassing ) Automatically fill all quantities histograms. Needs to be called in a loop over all dataset.","title":"fillQuantitiesHistograms(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/TagProbe/#normalizehistograms","text":"void normalizeHistograms () Normalize quantities histograms of variable bin after filling it.","title":"normalizeHistograms()"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/TagProbe/#subtractsighistograms","text":"void subtractSigHistograms () Apply sideband subtraction over all histograms.","title":"subtractSigHistograms()"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/TagProbe/#writequantitieshistogramsonfile","text":"void writeQuantitiesHistogramsOnFile ( bool hSigBack , bool hSig , bool hBack ) Write all quantities histograms in a root file. Just need to call this function and all quantities histograms will be written. It needs to be called after subtractSigHistograms().","title":"writeQuantitiesHistogramsOnFile(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/Type/","text":"class Type \u00b6 Holds TagProbe class and InvariantMass class . Constructor details \u00b6 Type ( const char *& resonance , const char *& particleName , bool & doTagMuon , bool & doProbeMuon , const char *& canvasWatermark , const char *& directoryToSave , const char * particleType ) : resonance ( resonance ), particleName ( particleName ), doTagMuon ( doTagMuon ), doProbeMuon ( doProbeMuon ), canvasWatermark ( canvasWatermark ), directoryToSave ( directoryToSave ), particleType ( particleType ) {} Private variable details \u00b6 Summary Type Name const char*& resonance const char*& particleName bool& doTagMuon bool& doProbeMuon const char*& canvasWatermark const char*& directoryToSave All variables here are reference for public variables in mother class: SidebandSubtraction class . Public variable details \u00b6 Summary Type Name Default value const char* particleType NULL Details const char* particleType = NULL Set the name of particle type. Constructed objects InvariantMass Mass Stores all informations about invariant masses, including fit and histograms. TagProbe Tag Stores all informations about tag muons, incuding quantities histograms and efficiencies. TagProbe Probe Stores all informations about probe muons, incuding quantities histograms and efficiencies. Public Functions details \u00b6 consistencyDebugCout() \u00b6 void consistencyDebugCout () Print on terminal the consistency check after subtractSigHistograms(). createEfficiencyCanvas(...) \u00b6 void createEfficiencyCanvas ( bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all efficiencies calculated. It need to be called after createEfficiencyPlot(...). createEfficiencyPlot(...) \u00b6 void createEfficiencyPlot ( bool shouldWrite = false ) Create a TEfficiency object with calculated efficiency. It needs do be called after subtractSigHistograms(). createMassCanvas(...) \u00b6 void createMassCanvas ( bool drawRegions = false , bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all invariant mass (passing and all muons). createQuantitiesCanvas(...) \u00b6 void createQuantitiesCanvas ( bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all quantities after subtractSigHistograms(). defineMassHistogramNumbers() \u00b6 void defineMassHistogramNumbers ( int nBins , double xMin , double xMax , int decimals = 3 ) Redefine number parameters of mass histograms in Mass object. doFit() \u00b6 void doFit () Apply a fit over invariant mass in Mass object. fillMassHistograms(...) \u00b6 void fillMassHistograms ( double & InvariantMass , int & isPassing ) Automatically fill all masses histograms. Needs to be called in a loop over all dataset. fillQuantitiesHistograms(...) \u00b6 void fillQuantitiesHistograms ( double ** quantities , int & isPassing ) Automatically fill all quantities histograms. Needs to be called in a loop over all dataset. normalizeHistograms() \u00b6 void normalizeHistograms () Normalize quantities histograms of variable bin after filling it. subtractSigHistograms() \u00b6 void subtractSigHistograms () Apply sideband subtraction over all histograms. updateMassValuesAll() \u00b6 void updateMassValuesAll () After fill invariant mass histograms, you need to set signal regions and sideband regions. This function will set it for you. writeMassHistogramsOnFile(...) \u00b6 void writeMassHistogramsOnFile ( bool writehPass , bool writehAll ) Write all mass canvas histograms in a root file. Just need to call this function and all mass histograms will be written. writeQuantitiesHistogramsOnFile(...) \u00b6 void writeQuantitiesHistogramsOnFile ( bool hSigBack , bool hSig , bool hBack ) Write all quantities histograms in a root file. Just need to call this function and all quantities histograms will be written. It needs to be called after subtractSigHistograms().","title":"Type class"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/Type/#class-type","text":"Holds TagProbe class and InvariantMass class .","title":"class Type"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/Type/#constructor-details","text":"Type ( const char *& resonance , const char *& particleName , bool & doTagMuon , bool & doProbeMuon , const char *& canvasWatermark , const char *& directoryToSave , const char * particleType ) : resonance ( resonance ), particleName ( particleName ), doTagMuon ( doTagMuon ), doProbeMuon ( doProbeMuon ), canvasWatermark ( canvasWatermark ), directoryToSave ( directoryToSave ), particleType ( particleType ) {}","title":"Constructor details"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/Type/#private-variable-details","text":"Summary Type Name const char*& resonance const char*& particleName bool& doTagMuon bool& doProbeMuon const char*& canvasWatermark const char*& directoryToSave All variables here are reference for public variables in mother class: SidebandSubtraction class .","title":"Private variable details"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/Type/#public-variable-details","text":"Summary Type Name Default value const char* particleType NULL Details const char* particleType = NULL Set the name of particle type. Constructed objects InvariantMass Mass Stores all informations about invariant masses, including fit and histograms. TagProbe Tag Stores all informations about tag muons, incuding quantities histograms and efficiencies. TagProbe Probe Stores all informations about probe muons, incuding quantities histograms and efficiencies.","title":"Public variable details"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/Type/#public-functions-details","text":"","title":"Public Functions details"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/Type/#consistencydebugcout","text":"void consistencyDebugCout () Print on terminal the consistency check after subtractSigHistograms().","title":"consistencyDebugCout()"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/Type/#createefficiencycanvas","text":"void createEfficiencyCanvas ( bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all efficiencies calculated. It need to be called after createEfficiencyPlot(...).","title":"createEfficiencyCanvas(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/Type/#createefficiencyplot","text":"void createEfficiencyPlot ( bool shouldWrite = false ) Create a TEfficiency object with calculated efficiency. It needs do be called after subtractSigHistograms().","title":"createEfficiencyPlot(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/Type/#createmasscanvas","text":"void createMassCanvas ( bool drawRegions = false , bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all invariant mass (passing and all muons).","title":"createMassCanvas(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/Type/#createquantitiescanvas","text":"void createQuantitiesCanvas ( bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all quantities after subtractSigHistograms().","title":"createQuantitiesCanvas(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/Type/#definemasshistogramnumbers","text":"void defineMassHistogramNumbers ( int nBins , double xMin , double xMax , int decimals = 3 ) Redefine number parameters of mass histograms in Mass object.","title":"defineMassHistogramNumbers()"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/Type/#dofit","text":"void doFit () Apply a fit over invariant mass in Mass object.","title":"doFit()"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/Type/#fillmasshistograms","text":"void fillMassHistograms ( double & InvariantMass , int & isPassing ) Automatically fill all masses histograms. Needs to be called in a loop over all dataset.","title":"fillMassHistograms(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/Type/#fillquantitieshistograms","text":"void fillQuantitiesHistograms ( double ** quantities , int & isPassing ) Automatically fill all quantities histograms. Needs to be called in a loop over all dataset.","title":"fillQuantitiesHistograms(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/Type/#normalizehistograms","text":"void normalizeHistograms () Normalize quantities histograms of variable bin after filling it.","title":"normalizeHistograms()"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/Type/#subtractsighistograms","text":"void subtractSigHistograms () Apply sideband subtraction over all histograms.","title":"subtractSigHistograms()"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/Type/#updatemassvaluesall","text":"void updateMassValuesAll () After fill invariant mass histograms, you need to set signal regions and sideband regions. This function will set it for you.","title":"updateMassValuesAll()"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/Type/#writemasshistogramsonfile","text":"void writeMassHistogramsOnFile ( bool writehPass , bool writehAll ) Write all mass canvas histograms in a root file. Just need to call this function and all mass histograms will be written.","title":"writeMassHistogramsOnFile(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/Type/#writequantitieshistogramsonfile","text":"void writeQuantitiesHistogramsOnFile ( bool hSigBack , bool hSig , bool hBack ) Write all quantities histograms in a root file. Just need to call this function and all quantities histograms will be written. It needs to be called after subtractSigHistograms().","title":"writeQuantitiesHistogramsOnFile(...)"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/macro/","text":"The Macro \u00b6 A macro is a code file create to be interpreted by a program. In this case, ROOT program will interpret it. The main code of this tool is in the file macro.ccp . In this section what compose this file is explained in details. About the code \u00b6 macro.cpp is a example how to use Sideband Subtraction to get reconstruction efficiencies for a Tag & Probe ntupple. It analyzes J/psi and Upsilon reconstruction efficiency for tracker , standalone and global muons. The file is encountered in folder main . Now, I going to talk about what this function do and how it does in the text below. Classes list \u00b6 There are some classes in Sideband Subtraction Tag And Probe project and they are distributed in these files with same name: Static functions : FitFunctions Primary Merged Jpsi Upsilon Classes and struct : SidebandSubtraction Type InvariantMass MassValues TagProbe PtEtaPhi PassingFailing This format shows what nested classes. Classes or structs below slided at right represents they are nested with the class above it. Sideband Subtraction code structure \u00b6 The diagram below represents the structure of objects in code. At left we have the structure of objects name. At right we have the correspondent class name of objects in these line. Also in Mass object we have: Notice that all objects in same line shares the same structure. Before macro.cpp \u00b6 There are some files in folder config aside of macro.ccp . The sections below explain about them. cuts.h \u00b6 This is it content: //This files holds some functions used in macro.cpp for particle selection //Return if is a accepted particle or no bool applyCuts ( double ** quantities , int ** types ) { //Assign variables for easy visualization double & ProbeMuon_Pt = * quantities [ 0 ]; double & ProbeMuon_Eta = * quantities [ 1 ]; double & ProbeMuon_Phi = * quantities [ 2 ]; double & TagMuon_Pt = * quantities [ 3 ]; double & TagMuon_Eta = * quantities [ 4 ]; double & TagMuon_Phi = * quantities [ 5 ]; double & InvariantMass = * quantities [ 6 ]; int & PassingProbeTrackingMuon = * types [ 0 ]; int & PassingProbeStandAloneMuon = * types [ 1 ]; int & PassingProbeGlobalMuon = * types [ 2 ]; //Apply cuts if ( TagMuon_Pt >= 7.0 && fabs ( TagMuon_Eta ) <= 2.4 ) return true ; return false ; } It stores the function applyCuts(), where return true for allowed pair of particles and false for not allowed. createHistogram.h \u00b6 This file is called in PassingFailing.cpp and set quantity histograms bins and create the hitogram. Its default content is shwon bellow: void createHistogram ( TH1D * & histo , const char * histoName ) { //Set parameters string hName = string ( particleType ) + string ( passingOrFailing ) + string ( tagOrProbe ) + string ( particleName ) + \"_\" + string ( quantityName ) + string ( histoName ); string hTitle = string ( passingOrFailing ) + \" in \" + string ( particleType ) + \" \" + string ( tagOrProbe ); string xAxisTitle = string ( xAxisName ); string yAxisTitleForm = \"Events\" ; //Add unit if has if ( strcmp ( quantityUnit , \"\" ) != 0 ) xAxisTitle += \" [\" + string ( quantityUnit ) + \"]\" ; //Change title is passing if ( strcmp ( passingOrFailing , \"Passing\" ) == 0 ) hTitle = string ( particleType ) + \" \" + string ( particleName ) + \" \" + string ( tagOrProbe ); if ( strcmp ( passingOrFailing , \"All\" ) == 0 ) hTitle = \"All \" + string ( particleName ) + \" \" + string ( tagOrProbe ); //Variable bin for pT if ( strcmp ( quantityName , \"Pt\" ) == 0 ) { double xbins [] = { 0. , 2.0 , 3.4 , 4.0 , 4.4 , 4.7 , 5.0 , 5.6 , 5.8 , 6.0 , 6.2 , 6.4 , 6.6 , 6.8 , 7.3 , 9.5 , 13.0 , 17.0 , 40. }; int nbins = sizeof ( xbins ) / sizeof ( * xbins ) - 1 ; histo = new TH1D ( hName . data (), hTitle . data (), nbins , xbins ); } //Variable bin for eta else if ( strcmp ( quantityName , \"Eta\" ) == 0 ) { double xbins [] = { -2.4 , -1.8 , -1.4 , -1.2 , -1.0 , -0.8 , -0.5 , -0.2 , 0 , 0.2 , 0.5 , 0.8 , 1.0 , 1.2 , 1.4 , 1.8 , 2.4 }; int nbins = sizeof ( xbins ) / sizeof ( * xbins ) - 1 ; histo = new TH1D ( hName . data (), hTitle . data (), nbins , xbins ); } //Bins for phi else { double xbins [] = { -3.0 , -1.8 , -1.6 , -1.2 , -1.0 , -0.7 , -0.4 , -0.2 , 0 , 0.2 , 0.4 , 0.7 , 1.0 , 1.2 , 1.6 , 1.8 , 3.0 }; int nbins = sizeof ( xbins ) / sizeof ( * xbins ) - 1 ; histo = new TH1D ( hName . data (), hTitle . data (), nbins , xbins ); } //Edit histogram axis histo -> GetYaxis () -> SetTitle ( Form ( yAxisTitleForm . data (), histo -> GetBinWidth ( 0 ))); histo -> GetXaxis () -> SetTitle ( xAxisTitle . data ()); } settings.cpp \u00b6 It stores many configurations used in macro.cpp : //List of files const char * files [] = { \"../data_histoall.root\" , \"../Run2011AMuOnia_mergeNtuple.root\" , \"../JPsiToMuMu_mergeMCNtuple.root\" , \"../Run2011A_MuOnia_Upsilon.root\" , \"../Upsilon1SToMuMu_MC_full.root\" }; const char * directoriesToSave [] = { \"../results/result/\" , \"../results/Jpsi_Run_2011/\" , \"../results/Jpsi_MC_2020_sbs/\" , \"../results/Upsilon_Run_2011/\" , \"../results/Upsilon_MC_2020_sbs/\" }; //MAIN OPTIONS //Which file of files (variable above) should use int useFile = 4 ; //Set the canvasW wtermark const char * canvasWatermark = \"#bf{CMS Open Data}\" ; //Path where is going to save results const char * directoryToSave = directoriesToSave [ useFile ]; //directoryToSave = \"../result/\"; //Should limit data? long long limitData = 0 ; //0 -> do not limit //Canvas drawing bool shouldDrawInvariantMassCanvas = true ; bool shouldDrawInvariantMassCanvasRegion = true ; bool shouldDrawQuantitiesCanvas = true ; bool shouldDrawEfficiencyCanvas = true ; //Muon id anlyse bool doTracker = true ; bool doStandalone = false ; bool doGlobal = false ; //Muon label anlyse bool doTagMuon = false ; bool doProbeMuon = true ; //ENDED MAIN OPTIONS And then there are more automatically set options: //Auto detect resonance due file index const char * resonance = \"Jpsi\" ; if ( useFile > 2 ) resonance = \"Upsilon\" ; if ( useFile == 4 ) resonance = \"Upsilon1S\" ; //Auto detect limit of data if ( limitData > 0 ) directoryToSave = \"../partial_result/\" ; //Compatibility adjusts on file read (for data_histoall ntupples) bool needsRetroCompatibility = false ; if ( useFile == 0 ) needsRetroCompatibility = true ; Code explained in parts \u00b6 macro.cpp is the main file of this program. Its the main code. It is explained in parts below: //Input files, options are set here! #include \"config/settings.cpp\" It imports configurations about macro.cpp //Check if the name of dir is ok if ( string ( directoryToSave ). back () != string ( \"/\" )) { cerr << \"To avoid errors, please end the result directory with a \\\" / \\\" \" << endl ; abort (); } //Check if dir exists and create if ( gSystem -> AccessPathName ( directoryToSave )) { if ( gSystem -> mkdir ( directoryToSave , true )) { cerr << \" \\\" \" << directoryToSave << \" \\\" path could not be found and could not be created ERROR\" << endl ; cerr << \"Try to create manually this folder path\" << endl ; abort (); } else { cout << \" \\\" \" << directoryToSave << \" \\\" directory created OK\" << endl ; } } else { cout << \" \\\" \" << directoryToSave << \" \\\" directory OK\" << endl ; } Check if the directoryToSave (setted in settings.cpp) has a valid name and if exists. If not, the code creates the folder. //Compatibility adjusts on file read (for data_histoall ntupples) string folderName = \"tagandprobe/\" ; if ( needsRetroCompatibility ) folderName = \"demo/\" ; //Open and read files TFile * file0 = TFile :: Open ( files [ useFile ]); TTree * TreePC = ( TTree * ) file0 -> Get (( folderName + \"PlotControl\" ). data ()); TTree * TreeAT = ( TTree * ) file0 -> Get (( folderName + \"AnalysisTree\" ). data ()); cout << \"Using \\\" \" << files [ useFile ] << \" \\\" ntupple\" << endl ; This part is responsible to open the file and do conversions. The first one file is a bit different of the other ones, so it needs compatibiliy besides its not important anymore and is a obsolete file. //Create variables double ProbeMuon_Pt ; double ProbeMuon_Eta ; double ProbeMuon_Phi ; double TagMuon_Pt ; double TagMuon_Eta ; double TagMuon_Phi ; double InvariantMass ; int PassingProbeTrackingMuon ; int PassingProbeStandAloneMuon ; int PassingProbeGlobalMuon ; //Assign variables TreePC -> SetBranchAddress ( \"ProbeMuon_Pt\" , & ProbeMuon_Pt ); TreePC -> SetBranchAddress ( \"ProbeMuon_Eta\" , & ProbeMuon_Eta ); TreePC -> SetBranchAddress ( \"ProbeMuon_Phi\" , & ProbeMuon_Phi ); TreePC -> SetBranchAddress ( \"TagMuon_Pt\" , & TagMuon_Pt ); TreePC -> SetBranchAddress ( \"TagMuon_Eta\" , & TagMuon_Eta ); TreePC -> SetBranchAddress ( \"TagMuon_Phi\" , & TagMuon_Phi ); if ( needsRetroCompatibility ) TreePC -> SetBranchAddress ( \"InvariantMass\" , & InvariantMass ); else TreeAT -> SetBranchAddress ( \"InvariantMass\" , & InvariantMass ); TreeAT -> SetBranchAddress ( \"PassingProbeTrackingMuon\" , & PassingProbeTrackingMuon ); TreeAT -> SetBranchAddress ( \"PassingProbeStandAloneMuon\" , & PassingProbeStandAloneMuon ); TreeAT -> SetBranchAddress ( \"PassingProbeGlobalMuon\" , & PassingProbeGlobalMuon ); double * quantities [] = { & ProbeMuon_Pt , & ProbeMuon_Eta , & ProbeMuon_Phi , & TagMuon_Pt , & TagMuon_Eta , & TagMuon_Phi , & InvariantMass , }; int * types [] = { & PassingProbeTrackingMuon , & PassingProbeStandAloneMuon , & PassingProbeGlobalMuon }; Now variables are created and linked to branches in ntupple. Then a array of these variables are set. //Create a object and set configs SidebandSubtraction SdS { resonance }; SdS . canvasWatermark = canvasWatermark ; SdS . directoryToSave = directoryToSave ; SdS . doTracker = doTracker ; SdS . doStandalone = doStandalone ; SdS . doGlobal = doGlobal ; SdS . doTagMuon = doTagMuon ; SdS . doProbeMuon = doProbeMuon ; cout << \"resonance: \" << SdS . resonance << \" \\n \" ; cout << \"Using subtraction factor as integral of background fit \\n \" ; The macro.cpp now creates the SdS object and assign variables setted in settings.cpp. At this point, it creates all histograms that you will need such as invariant mass histograms and pT, eta, phi histograms. //Get data size and set data limit if has long long numberEntries = TreePC -> GetEntries (); if ( limitData > 0 && limitData < numberEntries ) numberEntries = limitData ; printf ( \"Data analysed = %lld of %lld \\n \" , numberEntries , TreePC -> GetEntries ()); //Prepare for showing progress string progressFormat = \"Progress: %05.2f%% %0\" + to_string ( strlen ( to_string ( numberEntries ). data ())) + \"lld/%lld \\r \" ; auto lastTime = std :: chrono :: steady_clock :: now (); auto start = std :: chrono :: steady_clock :: now (); Now the code are limiting data if you setted and setting a string for progress information while filling histograms. cout << \" \\n Filling Invariant Mass Histograms..... (1/2) \\n \" ; //Loop between the components for ( long long i = 0 ; i < numberEntries ; i ++ ) { //Select particle pair TreePC -> GetEntry ( i ); TreeAT -> GetEntry ( i ); //Show progress on screen if ( chrono :: duration_cast < chrono :: milliseconds > ( chrono :: steady_clock :: now () - lastTime ). count () >= 1000 || i == numberEntries - 1 ) { printf ( progressFormat . data (), ( float )( i + 1 ) / ( float ) numberEntries * 100 , i + 1 , numberEntries ); lastTime = chrono :: steady_clock :: now (); } //Fill histograms if ( applyCuts ( quantities , types )) { SdS . fillMassHistograms ( quantities , types ); } } cout << \" \\n Took \" << chrono :: duration_cast < chrono :: milliseconds > ( chrono :: steady_clock :: now () - start ). count () << \" ms \\n \" ; This part of the code fill invariant mass histograms. Cuts are applyied in cuts.h. At this point, macro.cpp separes in passing and all muons. //Do function fit over the histogram SdS . doFit (); //Get values for invariant mass and sigma from plot SdS . updateMassValuesAll (); After filling mass histograms, it is necessary to apply the fit function. After doing fit, updateMassValuesAll() get regions for sideband subtraction mostly based in fitting. //------------------------------------- // Generate and save files //------------------------------------- //Create file root to store generated files TFile * generatedFile = TFile :: Open (( string ( directoryToSave ) + \"generated_hist.root\" ). data (), \"RECREATE\" ); generatedFile -> mkdir ( \"canvas/\" ); generatedFile -> cd ( \"canvas/\" ); if ( shouldDrawInvariantMassCanvas ) { bool drawRegions = false ; bool shouldWrite = true ; bool shouldSavePNG = true ; SdS . createMassCanvas ( drawRegions , shouldWrite , shouldSavePNG ); } if ( shouldDrawInvariantMassCanvasRegion && ! isMC ) { bool drawRegions = true ; bool shouldWrite = true ; bool shouldSavePNG = true ; SdS . createMassCanvas ( drawRegions , shouldWrite , shouldSavePNG ); } Canvas are drawn and saved in the generated_hist.root file and in the folder as .png . //Prepare for showing progress lastTime = std :: chrono :: steady_clock :: now (); start = std :: chrono :: steady_clock :: now (); cout << \" \\n Filling Quantities Histograms..... (2/2) \\n \" ; //Loop between the components again for ( long long i = 0 ; i < numberEntries ; i ++ ) { //Select particle pair TreePC -> GetEntry ( i ); TreeAT -> GetEntry ( i ); //Show progress on screen if ( chrono :: duration_cast < chrono :: milliseconds > ( chrono :: steady_clock :: now () - lastTime ). count () >= 1000 || i == numberEntries - 1 ) { printf ( progressFormat . data (), ( float )( i + 1 ) / ( float ) numberEntries * 100 , i + 1 , numberEntries ); lastTime = chrono :: steady_clock :: now (); } //Fill histograms if ( applyCuts ( quantities , types )) { SdS . fillQuantitiesHistograms ( quantities , types ); } } cout << \" \\n Took \" << chrono :: duration_cast < chrono :: milliseconds > ( chrono :: steady_clock :: now () - start ). count () << \" ms \\n \" ; At this point of the code, this will separate all histogram in signal + background (signal region) and background (sideband region) due the regions for sideband choosen before. //Normalize Histograms for variable binning cout << \" \\n \" ; SdS . normalizeHistograms (); After folling histograms, as some of them has variable bins, it needs to be normalized. This function does this. //For sideband subtraction SdS . subtractSigHistograms (); Subtract background from signal + background histogram to create signal histogram. This method is what is called sideband subtraction . if ( shouldDrawQuantitiesCanvas ) { bool shouldWrite = true ; bool shouldSavePNG = true ; cout << endl ; SdS . createQuantitiesCanvas ( shouldWrite , shouldSavePNG ); } The code here draw the canvas for all pT, eta and phi quantities it has. Including background , signal and signal + background . //Debug consistency for histograms SdS . consistencyDebugCout (); This is a checker of how consistent is our result values and print on terminal results. For all histograms this calculations should result 0. For more details about how exactly it works, see consistencyDebugCout() . //Save histograms generatedFile -> mkdir ( \"histograms/\" ); generatedFile -> cd ( \"histograms/\" ); //Write quantities histograms on file { bool writehSigBack = true ; bool writehSig = true ; bool writehBack = true ; SdS . writeQuantitiesHistogramsOnFile ( writehSigBack , writehSig , writehBack ); } //Write mass histograms on file { bool writehPass = true ; bool writehAll = true ; SdS . writeMassHistogramsOnFile ( writehPass , writehAll ); } At this point, the code will write all histograms in a folder in the .root generated file. Including mass histograms and quantities histograms. //Save plots generatedFile -> mkdir ( \"efficiency/plots/\" ); generatedFile -> cd ( \"efficiency/plots/\" ); //Creates efficiency plots { bool shouldWrite = true ; SdS . createEfficiencyPlot ( shouldWrite ); } It calculates the efficiency of the quantities by using TEfficiency class of ROOT. Then saves the plots in another folder inside the .root file. //Saves new histograms and canvas in file generatedFile -> mkdir ( \"efficiency/canvas/\" ); generatedFile -> cd ( \"efficiency/canvas/\" ); if ( shouldDrawEfficiencyCanvas ) { bool shouldWrite = true ; bool shouldSavePNG = true ; cout << \" \\n \" ; SdS . createEfficiencyCanvas ( shouldWrite , shouldSavePNG ); } //Close files generatedFile -> Close (); cout << \" \\n Done. All result files can be found at \\\" \" << SdS . directoryToSave << \" \\\"\\n\\n \" ; The end point of this function. It creates a canvas for every efficiency plot calculated above and also saves in the generated file. After this, the task is done. Results \u00b6 All results are saved in a folder setted in directoryToSave variable. The result contains a file .root with all canvas, histograms and plots aside of .png images of all canvas created.","title":"The Macro"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/macro/#the-macro","text":"A macro is a code file create to be interpreted by a program. In this case, ROOT program will interpret it. The main code of this tool is in the file macro.ccp . In this section what compose this file is explained in details.","title":"The Macro"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/macro/#about-the-code","text":"macro.cpp is a example how to use Sideband Subtraction to get reconstruction efficiencies for a Tag & Probe ntupple. It analyzes J/psi and Upsilon reconstruction efficiency for tracker , standalone and global muons. The file is encountered in folder main . Now, I going to talk about what this function do and how it does in the text below.","title":"About the code"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/macro/#classes-list","text":"There are some classes in Sideband Subtraction Tag And Probe project and they are distributed in these files with same name: Static functions : FitFunctions Primary Merged Jpsi Upsilon Classes and struct : SidebandSubtraction Type InvariantMass MassValues TagProbe PtEtaPhi PassingFailing This format shows what nested classes. Classes or structs below slided at right represents they are nested with the class above it.","title":"Classes list"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/macro/#sideband-subtraction-code-structure","text":"The diagram below represents the structure of objects in code. At left we have the structure of objects name. At right we have the correspondent class name of objects in these line. Also in Mass object we have: Notice that all objects in same line shares the same structure.","title":"Sideband Subtraction code structure"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/macro/#before-macrocpp","text":"There are some files in folder config aside of macro.ccp . The sections below explain about them.","title":"Before macro.cpp"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/macro/#cutsh","text":"This is it content: //This files holds some functions used in macro.cpp for particle selection //Return if is a accepted particle or no bool applyCuts ( double ** quantities , int ** types ) { //Assign variables for easy visualization double & ProbeMuon_Pt = * quantities [ 0 ]; double & ProbeMuon_Eta = * quantities [ 1 ]; double & ProbeMuon_Phi = * quantities [ 2 ]; double & TagMuon_Pt = * quantities [ 3 ]; double & TagMuon_Eta = * quantities [ 4 ]; double & TagMuon_Phi = * quantities [ 5 ]; double & InvariantMass = * quantities [ 6 ]; int & PassingProbeTrackingMuon = * types [ 0 ]; int & PassingProbeStandAloneMuon = * types [ 1 ]; int & PassingProbeGlobalMuon = * types [ 2 ]; //Apply cuts if ( TagMuon_Pt >= 7.0 && fabs ( TagMuon_Eta ) <= 2.4 ) return true ; return false ; } It stores the function applyCuts(), where return true for allowed pair of particles and false for not allowed.","title":"cuts.h"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/macro/#createhistogramh","text":"This file is called in PassingFailing.cpp and set quantity histograms bins and create the hitogram. Its default content is shwon bellow: void createHistogram ( TH1D * & histo , const char * histoName ) { //Set parameters string hName = string ( particleType ) + string ( passingOrFailing ) + string ( tagOrProbe ) + string ( particleName ) + \"_\" + string ( quantityName ) + string ( histoName ); string hTitle = string ( passingOrFailing ) + \" in \" + string ( particleType ) + \" \" + string ( tagOrProbe ); string xAxisTitle = string ( xAxisName ); string yAxisTitleForm = \"Events\" ; //Add unit if has if ( strcmp ( quantityUnit , \"\" ) != 0 ) xAxisTitle += \" [\" + string ( quantityUnit ) + \"]\" ; //Change title is passing if ( strcmp ( passingOrFailing , \"Passing\" ) == 0 ) hTitle = string ( particleType ) + \" \" + string ( particleName ) + \" \" + string ( tagOrProbe ); if ( strcmp ( passingOrFailing , \"All\" ) == 0 ) hTitle = \"All \" + string ( particleName ) + \" \" + string ( tagOrProbe ); //Variable bin for pT if ( strcmp ( quantityName , \"Pt\" ) == 0 ) { double xbins [] = { 0. , 2.0 , 3.4 , 4.0 , 4.4 , 4.7 , 5.0 , 5.6 , 5.8 , 6.0 , 6.2 , 6.4 , 6.6 , 6.8 , 7.3 , 9.5 , 13.0 , 17.0 , 40. }; int nbins = sizeof ( xbins ) / sizeof ( * xbins ) - 1 ; histo = new TH1D ( hName . data (), hTitle . data (), nbins , xbins ); } //Variable bin for eta else if ( strcmp ( quantityName , \"Eta\" ) == 0 ) { double xbins [] = { -2.4 , -1.8 , -1.4 , -1.2 , -1.0 , -0.8 , -0.5 , -0.2 , 0 , 0.2 , 0.5 , 0.8 , 1.0 , 1.2 , 1.4 , 1.8 , 2.4 }; int nbins = sizeof ( xbins ) / sizeof ( * xbins ) - 1 ; histo = new TH1D ( hName . data (), hTitle . data (), nbins , xbins ); } //Bins for phi else { double xbins [] = { -3.0 , -1.8 , -1.6 , -1.2 , -1.0 , -0.7 , -0.4 , -0.2 , 0 , 0.2 , 0.4 , 0.7 , 1.0 , 1.2 , 1.6 , 1.8 , 3.0 }; int nbins = sizeof ( xbins ) / sizeof ( * xbins ) - 1 ; histo = new TH1D ( hName . data (), hTitle . data (), nbins , xbins ); } //Edit histogram axis histo -> GetYaxis () -> SetTitle ( Form ( yAxisTitleForm . data (), histo -> GetBinWidth ( 0 ))); histo -> GetXaxis () -> SetTitle ( xAxisTitle . data ()); }","title":"createHistogram.h"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/macro/#settingscpp","text":"It stores many configurations used in macro.cpp : //List of files const char * files [] = { \"../data_histoall.root\" , \"../Run2011AMuOnia_mergeNtuple.root\" , \"../JPsiToMuMu_mergeMCNtuple.root\" , \"../Run2011A_MuOnia_Upsilon.root\" , \"../Upsilon1SToMuMu_MC_full.root\" }; const char * directoriesToSave [] = { \"../results/result/\" , \"../results/Jpsi_Run_2011/\" , \"../results/Jpsi_MC_2020_sbs/\" , \"../results/Upsilon_Run_2011/\" , \"../results/Upsilon_MC_2020_sbs/\" }; //MAIN OPTIONS //Which file of files (variable above) should use int useFile = 4 ; //Set the canvasW wtermark const char * canvasWatermark = \"#bf{CMS Open Data}\" ; //Path where is going to save results const char * directoryToSave = directoriesToSave [ useFile ]; //directoryToSave = \"../result/\"; //Should limit data? long long limitData = 0 ; //0 -> do not limit //Canvas drawing bool shouldDrawInvariantMassCanvas = true ; bool shouldDrawInvariantMassCanvasRegion = true ; bool shouldDrawQuantitiesCanvas = true ; bool shouldDrawEfficiencyCanvas = true ; //Muon id anlyse bool doTracker = true ; bool doStandalone = false ; bool doGlobal = false ; //Muon label anlyse bool doTagMuon = false ; bool doProbeMuon = true ; //ENDED MAIN OPTIONS And then there are more automatically set options: //Auto detect resonance due file index const char * resonance = \"Jpsi\" ; if ( useFile > 2 ) resonance = \"Upsilon\" ; if ( useFile == 4 ) resonance = \"Upsilon1S\" ; //Auto detect limit of data if ( limitData > 0 ) directoryToSave = \"../partial_result/\" ; //Compatibility adjusts on file read (for data_histoall ntupples) bool needsRetroCompatibility = false ; if ( useFile == 0 ) needsRetroCompatibility = true ;","title":"settings.cpp"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/macro/#code-explained-in-parts","text":"macro.cpp is the main file of this program. Its the main code. It is explained in parts below: //Input files, options are set here! #include \"config/settings.cpp\" It imports configurations about macro.cpp //Check if the name of dir is ok if ( string ( directoryToSave ). back () != string ( \"/\" )) { cerr << \"To avoid errors, please end the result directory with a \\\" / \\\" \" << endl ; abort (); } //Check if dir exists and create if ( gSystem -> AccessPathName ( directoryToSave )) { if ( gSystem -> mkdir ( directoryToSave , true )) { cerr << \" \\\" \" << directoryToSave << \" \\\" path could not be found and could not be created ERROR\" << endl ; cerr << \"Try to create manually this folder path\" << endl ; abort (); } else { cout << \" \\\" \" << directoryToSave << \" \\\" directory created OK\" << endl ; } } else { cout << \" \\\" \" << directoryToSave << \" \\\" directory OK\" << endl ; } Check if the directoryToSave (setted in settings.cpp) has a valid name and if exists. If not, the code creates the folder. //Compatibility adjusts on file read (for data_histoall ntupples) string folderName = \"tagandprobe/\" ; if ( needsRetroCompatibility ) folderName = \"demo/\" ; //Open and read files TFile * file0 = TFile :: Open ( files [ useFile ]); TTree * TreePC = ( TTree * ) file0 -> Get (( folderName + \"PlotControl\" ). data ()); TTree * TreeAT = ( TTree * ) file0 -> Get (( folderName + \"AnalysisTree\" ). data ()); cout << \"Using \\\" \" << files [ useFile ] << \" \\\" ntupple\" << endl ; This part is responsible to open the file and do conversions. The first one file is a bit different of the other ones, so it needs compatibiliy besides its not important anymore and is a obsolete file. //Create variables double ProbeMuon_Pt ; double ProbeMuon_Eta ; double ProbeMuon_Phi ; double TagMuon_Pt ; double TagMuon_Eta ; double TagMuon_Phi ; double InvariantMass ; int PassingProbeTrackingMuon ; int PassingProbeStandAloneMuon ; int PassingProbeGlobalMuon ; //Assign variables TreePC -> SetBranchAddress ( \"ProbeMuon_Pt\" , & ProbeMuon_Pt ); TreePC -> SetBranchAddress ( \"ProbeMuon_Eta\" , & ProbeMuon_Eta ); TreePC -> SetBranchAddress ( \"ProbeMuon_Phi\" , & ProbeMuon_Phi ); TreePC -> SetBranchAddress ( \"TagMuon_Pt\" , & TagMuon_Pt ); TreePC -> SetBranchAddress ( \"TagMuon_Eta\" , & TagMuon_Eta ); TreePC -> SetBranchAddress ( \"TagMuon_Phi\" , & TagMuon_Phi ); if ( needsRetroCompatibility ) TreePC -> SetBranchAddress ( \"InvariantMass\" , & InvariantMass ); else TreeAT -> SetBranchAddress ( \"InvariantMass\" , & InvariantMass ); TreeAT -> SetBranchAddress ( \"PassingProbeTrackingMuon\" , & PassingProbeTrackingMuon ); TreeAT -> SetBranchAddress ( \"PassingProbeStandAloneMuon\" , & PassingProbeStandAloneMuon ); TreeAT -> SetBranchAddress ( \"PassingProbeGlobalMuon\" , & PassingProbeGlobalMuon ); double * quantities [] = { & ProbeMuon_Pt , & ProbeMuon_Eta , & ProbeMuon_Phi , & TagMuon_Pt , & TagMuon_Eta , & TagMuon_Phi , & InvariantMass , }; int * types [] = { & PassingProbeTrackingMuon , & PassingProbeStandAloneMuon , & PassingProbeGlobalMuon }; Now variables are created and linked to branches in ntupple. Then a array of these variables are set. //Create a object and set configs SidebandSubtraction SdS { resonance }; SdS . canvasWatermark = canvasWatermark ; SdS . directoryToSave = directoryToSave ; SdS . doTracker = doTracker ; SdS . doStandalone = doStandalone ; SdS . doGlobal = doGlobal ; SdS . doTagMuon = doTagMuon ; SdS . doProbeMuon = doProbeMuon ; cout << \"resonance: \" << SdS . resonance << \" \\n \" ; cout << \"Using subtraction factor as integral of background fit \\n \" ; The macro.cpp now creates the SdS object and assign variables setted in settings.cpp. At this point, it creates all histograms that you will need such as invariant mass histograms and pT, eta, phi histograms. //Get data size and set data limit if has long long numberEntries = TreePC -> GetEntries (); if ( limitData > 0 && limitData < numberEntries ) numberEntries = limitData ; printf ( \"Data analysed = %lld of %lld \\n \" , numberEntries , TreePC -> GetEntries ()); //Prepare for showing progress string progressFormat = \"Progress: %05.2f%% %0\" + to_string ( strlen ( to_string ( numberEntries ). data ())) + \"lld/%lld \\r \" ; auto lastTime = std :: chrono :: steady_clock :: now (); auto start = std :: chrono :: steady_clock :: now (); Now the code are limiting data if you setted and setting a string for progress information while filling histograms. cout << \" \\n Filling Invariant Mass Histograms..... (1/2) \\n \" ; //Loop between the components for ( long long i = 0 ; i < numberEntries ; i ++ ) { //Select particle pair TreePC -> GetEntry ( i ); TreeAT -> GetEntry ( i ); //Show progress on screen if ( chrono :: duration_cast < chrono :: milliseconds > ( chrono :: steady_clock :: now () - lastTime ). count () >= 1000 || i == numberEntries - 1 ) { printf ( progressFormat . data (), ( float )( i + 1 ) / ( float ) numberEntries * 100 , i + 1 , numberEntries ); lastTime = chrono :: steady_clock :: now (); } //Fill histograms if ( applyCuts ( quantities , types )) { SdS . fillMassHistograms ( quantities , types ); } } cout << \" \\n Took \" << chrono :: duration_cast < chrono :: milliseconds > ( chrono :: steady_clock :: now () - start ). count () << \" ms \\n \" ; This part of the code fill invariant mass histograms. Cuts are applyied in cuts.h. At this point, macro.cpp separes in passing and all muons. //Do function fit over the histogram SdS . doFit (); //Get values for invariant mass and sigma from plot SdS . updateMassValuesAll (); After filling mass histograms, it is necessary to apply the fit function. After doing fit, updateMassValuesAll() get regions for sideband subtraction mostly based in fitting. //------------------------------------- // Generate and save files //------------------------------------- //Create file root to store generated files TFile * generatedFile = TFile :: Open (( string ( directoryToSave ) + \"generated_hist.root\" ). data (), \"RECREATE\" ); generatedFile -> mkdir ( \"canvas/\" ); generatedFile -> cd ( \"canvas/\" ); if ( shouldDrawInvariantMassCanvas ) { bool drawRegions = false ; bool shouldWrite = true ; bool shouldSavePNG = true ; SdS . createMassCanvas ( drawRegions , shouldWrite , shouldSavePNG ); } if ( shouldDrawInvariantMassCanvasRegion && ! isMC ) { bool drawRegions = true ; bool shouldWrite = true ; bool shouldSavePNG = true ; SdS . createMassCanvas ( drawRegions , shouldWrite , shouldSavePNG ); } Canvas are drawn and saved in the generated_hist.root file and in the folder as .png . //Prepare for showing progress lastTime = std :: chrono :: steady_clock :: now (); start = std :: chrono :: steady_clock :: now (); cout << \" \\n Filling Quantities Histograms..... (2/2) \\n \" ; //Loop between the components again for ( long long i = 0 ; i < numberEntries ; i ++ ) { //Select particle pair TreePC -> GetEntry ( i ); TreeAT -> GetEntry ( i ); //Show progress on screen if ( chrono :: duration_cast < chrono :: milliseconds > ( chrono :: steady_clock :: now () - lastTime ). count () >= 1000 || i == numberEntries - 1 ) { printf ( progressFormat . data (), ( float )( i + 1 ) / ( float ) numberEntries * 100 , i + 1 , numberEntries ); lastTime = chrono :: steady_clock :: now (); } //Fill histograms if ( applyCuts ( quantities , types )) { SdS . fillQuantitiesHistograms ( quantities , types ); } } cout << \" \\n Took \" << chrono :: duration_cast < chrono :: milliseconds > ( chrono :: steady_clock :: now () - start ). count () << \" ms \\n \" ; At this point of the code, this will separate all histogram in signal + background (signal region) and background (sideband region) due the regions for sideband choosen before. //Normalize Histograms for variable binning cout << \" \\n \" ; SdS . normalizeHistograms (); After folling histograms, as some of them has variable bins, it needs to be normalized. This function does this. //For sideband subtraction SdS . subtractSigHistograms (); Subtract background from signal + background histogram to create signal histogram. This method is what is called sideband subtraction . if ( shouldDrawQuantitiesCanvas ) { bool shouldWrite = true ; bool shouldSavePNG = true ; cout << endl ; SdS . createQuantitiesCanvas ( shouldWrite , shouldSavePNG ); } The code here draw the canvas for all pT, eta and phi quantities it has. Including background , signal and signal + background . //Debug consistency for histograms SdS . consistencyDebugCout (); This is a checker of how consistent is our result values and print on terminal results. For all histograms this calculations should result 0. For more details about how exactly it works, see consistencyDebugCout() . //Save histograms generatedFile -> mkdir ( \"histograms/\" ); generatedFile -> cd ( \"histograms/\" ); //Write quantities histograms on file { bool writehSigBack = true ; bool writehSig = true ; bool writehBack = true ; SdS . writeQuantitiesHistogramsOnFile ( writehSigBack , writehSig , writehBack ); } //Write mass histograms on file { bool writehPass = true ; bool writehAll = true ; SdS . writeMassHistogramsOnFile ( writehPass , writehAll ); } At this point, the code will write all histograms in a folder in the .root generated file. Including mass histograms and quantities histograms. //Save plots generatedFile -> mkdir ( \"efficiency/plots/\" ); generatedFile -> cd ( \"efficiency/plots/\" ); //Creates efficiency plots { bool shouldWrite = true ; SdS . createEfficiencyPlot ( shouldWrite ); } It calculates the efficiency of the quantities by using TEfficiency class of ROOT. Then saves the plots in another folder inside the .root file. //Saves new histograms and canvas in file generatedFile -> mkdir ( \"efficiency/canvas/\" ); generatedFile -> cd ( \"efficiency/canvas/\" ); if ( shouldDrawEfficiencyCanvas ) { bool shouldWrite = true ; bool shouldSavePNG = true ; cout << \" \\n \" ; SdS . createEfficiencyCanvas ( shouldWrite , shouldSavePNG ); } //Close files generatedFile -> Close (); cout << \" \\n Done. All result files can be found at \\\" \" << SdS . directoryToSave << \" \\\"\\n\\n \" ; The end point of this function. It creates a canvas for every efficiency plot calculated above and also saves in the generated file. After this, the task is done.","title":"Code explained in parts"},{"location":"analysis/selection/idefficiencystudy/sidebandreferenceguide/macro/#results","text":"All results are saved in a folder setted in directoryToSave variable. The result contains a file .root with all canvas, histograms and plots aside of .png images of all canvas created.","title":"Results"},{"location":"analysis/selection/idefficiencystudy/tutorial/01-introduction/","text":"What is the tag and probe method? \u00b6 The tag and probe method is a data-driven technique for measuring particle detection efficiencies. It is based on the decays of known resonances (e.g. J/\u03c8, \u03d2 and Z) to pairs of the particles being studied. In this exercise, these particles are muons, and the \u03d2(1S) resonance is nominally used. The determination of the detector efficiency is a critical ingredient in any physics measurement. It accounts for the particles that were produced in the collision but escaped detection (did not reach the detector elements, were missed by the reconstructions algorithms, etc). It can be in general estimated using simulations, but simulations need to be calibrated with data. The T&P method here described provides a useful and elegant mechanism for extracting efficiencies directly from data! . What is \"tag\" and \"probe\"? \u00b6 The resonance, used to calculate the efficiencies, decays to a pair of particles: the tag and the probe. Tag muon = well identified, triggered muon (tight selection criteria). Probe muon = unbiased set of muon candidates (very loose selection criteria), either passing or failing the criteria for which the efficiency is to be measured. How do we calculate the efficiency? \u00b6 The efficiency is given by the fraction of probe muons that pass a given criteria (in this case, the Muon ID which we explain below ): The denominator corresponds to the number of resonance candidates (tag+probe pairs) reconstructed in the dataset. The numerator corresponds to the subset for which the probe passes the criteria. The tag+probe invariant mass distribution is used to select only signal, that is, only true Y(1S) candidates decaying to dimuons. This is achieved in this exercise by the usage of two methods: fitting and side-band-subtraction . CMS Muon identification and reconstruction \u00b6 The final objective in this lesson is to measure the efficiency for identifying reconstructed tracker muons . We present here a short description of the muon identification and reconstruction employed in the CMS experiment at the LHC. In the standard CMS reconstruction for proton-proton collisions, tracks are first reconstructed independently in the inner tracker and in the muon system. Based on these objects, two reconstruction approaches are used: Tracker Muon reconstruction (red line): In this approach, all tracker tracks with pT > 0.5 GeV/c and total momentum p > 2.5 GeV/c are considered as possible muon candidates and are extrapolated to the muon system taking into account the magnetic field; Standalone Muon reconstruction (green line): they are all tracks of the segments reconstructed in the muon chambers (performed using segments and hits from Drift Tubes - DTs in the barrel region, Cathode strip chambers - CSCs in the endcaps and Resistive Plates Chambers - RPCs for all muon system) are used to generate \"seeds\" consisting of position and direction vectors and an estimate of the muon transverse momentum; Global Muon reconstruction (blue line): For each standalone-muon track, a matching tracker track is found by comparing parameters of the two tracks propagated onto a common surface. You can find more details concerning CMS Muon Identification and reconstruction in this paper JINST 7 (2012) P10002 .","title":"Introduction"},{"location":"analysis/selection/idefficiencystudy/tutorial/01-introduction/#what-is-the-tag-and-probe-method","text":"The tag and probe method is a data-driven technique for measuring particle detection efficiencies. It is based on the decays of known resonances (e.g. J/\u03c8, \u03d2 and Z) to pairs of the particles being studied. In this exercise, these particles are muons, and the \u03d2(1S) resonance is nominally used. The determination of the detector efficiency is a critical ingredient in any physics measurement. It accounts for the particles that were produced in the collision but escaped detection (did not reach the detector elements, were missed by the reconstructions algorithms, etc). It can be in general estimated using simulations, but simulations need to be calibrated with data. The T&P method here described provides a useful and elegant mechanism for extracting efficiencies directly from data! .","title":"What is the tag and probe method?"},{"location":"analysis/selection/idefficiencystudy/tutorial/01-introduction/#what-is-tag-and-probe","text":"The resonance, used to calculate the efficiencies, decays to a pair of particles: the tag and the probe. Tag muon = well identified, triggered muon (tight selection criteria). Probe muon = unbiased set of muon candidates (very loose selection criteria), either passing or failing the criteria for which the efficiency is to be measured.","title":"What is \"tag\" and \"probe\"?"},{"location":"analysis/selection/idefficiencystudy/tutorial/01-introduction/#how-do-we-calculate-the-efficiency","text":"The efficiency is given by the fraction of probe muons that pass a given criteria (in this case, the Muon ID which we explain below ): The denominator corresponds to the number of resonance candidates (tag+probe pairs) reconstructed in the dataset. The numerator corresponds to the subset for which the probe passes the criteria. The tag+probe invariant mass distribution is used to select only signal, that is, only true Y(1S) candidates decaying to dimuons. This is achieved in this exercise by the usage of two methods: fitting and side-band-subtraction .","title":"How do we calculate the efficiency?"},{"location":"analysis/selection/idefficiencystudy/tutorial/01-introduction/#cms-muon-identification-and-reconstruction","text":"The final objective in this lesson is to measure the efficiency for identifying reconstructed tracker muons . We present here a short description of the muon identification and reconstruction employed in the CMS experiment at the LHC. In the standard CMS reconstruction for proton-proton collisions, tracks are first reconstructed independently in the inner tracker and in the muon system. Based on these objects, two reconstruction approaches are used: Tracker Muon reconstruction (red line): In this approach, all tracker tracks with pT > 0.5 GeV/c and total momentum p > 2.5 GeV/c are considered as possible muon candidates and are extrapolated to the muon system taking into account the magnetic field; Standalone Muon reconstruction (green line): they are all tracks of the segments reconstructed in the muon chambers (performed using segments and hits from Drift Tubes - DTs in the barrel region, Cathode strip chambers - CSCs in the endcaps and Resistive Plates Chambers - RPCs for all muon system) are used to generate \"seeds\" consisting of position and direction vectors and an estimate of the muon transverse momentum; Global Muon reconstruction (blue line): For each standalone-muon track, a matching tracker track is found by comparing parameters of the two tracks propagated onto a common surface. You can find more details concerning CMS Muon Identification and reconstruction in this paper JINST 7 (2012) P10002 .","title":"CMS Muon identification and reconstruction"},{"location":"analysis/selection/idefficiencystudy/tutorial/02-fitting/","text":"Setting it up \u00b6 In order to run this exercise you do not really need to be in a CMSSW area. It would be actually better if you worked outside your usual CMSSW_5_3_32 environment. So, if, for instance, you are working with the Docker container, instead of working on /home/cmsusr/CMSSW_5_3_32/src you could work on any directory you can create at the /home/cmsusr level. Alternatively, you could work directly on your own host machine if you managed to install ROOT on it. For this example we assume you will be working in either the Docker container or the virtual machine. Since we will be needing ROOT version greater than 6, then do not forget to set it up from LCG (as you learned in the ROOT pre-exercise) by doing: source /cvmfs/sft.cern.ch/lcg/views/LCG_95/x86_64-slc6-gcc8-opt/setup.sh Clone the repository and go to the fitting method tutorial: git clone git://github.com/allanjales/TagAndProbe cd TagAndProbe/efficiency_tools/fitting A brief explanation of this repository In this repository, you are only required to make changes to the Efficiency.C macro. These changes are highlighted as such: /*-----------------------------------I N S E R T C O D E H E R E-----------------------------------*/ So when you see this comment, know that it's your turn to code! If you don't, the macro won't run and the following errors are to be expected: Error In file included from input_line_11:1: /Users/thomasgaehtgens/Desktop/CMS-tutorial/Efficiency.C:13:23: error: expected expression bool DataIsMC = ... ; ^ /Users/thomasgaehtgens/Desktop/CMS-tutorial/Efficiency.C:15:23: error: expected expression string MuonId = ... ; ^ /Users/thomasgaehtgens/Desktop/CMS-tutorial/Efficiency.C:17:23: error: expected expression string quantity = ... ; //Pt, Eta or Phi ^ /Users/thomasgaehtgens/Desktop/CMS-tutorial/Efficiency.C:25:22: error: expected expression double bins[] = {...}; ^ /Users/thomasgaehtgens/Desktop/CMS-tutorial/Efficiency.C:26:21: error: expected expression int bin_n = ...; ^ /Users/thomasgaehtgens/Desktop/CMS-tutorial/Efficiency.C:33:35: error: expected expression init_conditions[0] = /*peak1*/; ^ /Users/thomasgaehtgens/Desktop/CMS-tutorial/Efficiency.C:34:35: error: expected expression init_conditions[1] = /*peak2*/; ^ /Users/thomasgaehtgens/Desktop/CMS-tutorial/Efficiency.C:35:35: error: expected expression init_conditions[2] = /*peak3*/; ^ /Users/thomasgaehtgens/Desktop/CMS-tutorial/Efficiency.C:36:35: error: expected expression init_conditions[3] = /*sigma*/; The Fitting Method \u00b6 First, a brief explanation of the method we\u2019ll be studying. It consists on fitting the invariant mass of the tag & probe pairs, in the two categories: passing probes, and all probes. I.e., for the unbiased leg of the decay, one can apply a selection criteria (a set of cuts) and determine whether the object passes those criteria or not. The procedure is applied after splitting the data in bins of a kinematic variable of the probe object (e.g. the traverse momentum, p T ); as such, the efficiency will be measured as a function of that quantity for each of the bins. So, in the picture below, on the left, let's imagine that the p T bin we are selecting is the one marked in red. But, of course, in that bin (like in the rest) you will have true \u03d2 decays as well as muon pairs from other processes (maybe QCD, for instance). The true decays would make up our signal , whereas the other events will be considered the background . The fit, which is made in a different space (the invariant mass space) allows to statistically discriminate between signal and background. To compute the efficiency we simply divide the signal yield from the fits to the passing category by the signal yield from the fit of the inclusive (All) category. This approach is depicted in the middle and right-hand plots of the image below. At the end of the day, then, you will have to make these fits for each bin in the range of interest. Let's start exploring our dataset. From the cloned directory, type: cd DATA/Upsilon/trackerMuon/ root -l T \\& P_UPSILON_DATA.root If everything's right, you should get something like: Attaching file T&P_UPSILON_DATA.root as _file0... U(TFile *) 0x7fe2f34ca270 Of course, you can explore this file, if you want, using all the tools you learn in the ROOT pre-exercise. This file contains ntuples that were obtained using procedures similar to the ones you have been learning in this workshop. Note In the following plots, remember that the units of the x axis are in GeV/c. Now, before we start fitting the invariant mass it's important to look at it's shape first. To visualize our data's invariant mass, do (within ROOT): root [] UPSILON_DATA -> Draw ( \"InvariantMass\" ) If you got the previous result, we're ready to go. The dataset used in this exercise has been collected by the CMS experiment, in proton-proton collisions at the LHC. It contains 986100 entries (muon pair candidates) with an associated invariant mass. For each candidate, the transverse momentum (p T ), rapidity(\u03b7) and azimuthal angle (\u03c6) are stored, along with a binary flag PassingProbeTrackingMuon , which is 1 in case the corresponding probe satisfied the tracker muon selection criteria and 0 in case it doesn't. Note Note that it does not really matter what kind of selection criteria these ntuples were created with. The procedure would be the same. You can create your own, similar ntuples with the criteria that you need to study. As you may have seen, after exploring the content of the root file, the UPSILON_DATA tree has these variables: | InvarianMass | | PassingProbeTrackingMuon | | ProbeMuon_Pt | | ProbeMuon_Eta | | ProbeMuon_Phi| We'll start by calculating the efficiency as a function of p T . It is useful to have an idea of the distribution of the quantity we want to study. In order to do this, we\u2019ll repeat the steps previously used to plot the invariant mass, but now for the ProbeMuon_Pt variable. root [] UPSILON_DATA -> Draw ( \"ProbeMuon_Pt\" ) Hmm.. seems like our domain is larger than we need it to be. To fix this, we can apply a constraint to our plot. Try: root [] UPSILON_DATA -> Draw ( \"ProbeMuon_Pt\" , \"ProbeMuon_Pt < 20\" ) Exit ROOT and get back to the main area: root [] .q cd ../../../ Now that you're acquainted with the data, open the Efficiency.C file. You'll have to make some small adjustments to the code in this section (from line:19 to line:34): /*-----------------------------------I N S E R T C O D E H E R E-----------------------------------*/ //string quantity = \"Pt\"; double bins[] = {0., 2.0, 3.4, 4.0, 4.4, 4.7, 5.0, 5.6, 5.8, 6.0, 6.2, 6.4, 6.6, 6.8, 7.3, 9.5, 13.0, 17.0, 40.}; //string quantity = \"Eta\"; double bins[] = {-2.4, -1.8, -1.4, -1.2, -1.0, -0.8, -0.5, -0.2, 0, 0.2, 0.5, 0.8, 1.0, 1.2, 1.4, 1.8, 2.4}; string quantity = \"Phi\" ; double bins [] = { -3.0 , -1.8 , -1.6 , -1.2 , -1.0 , -0.7 , -0.4 , -0.2 , 0 , 0.2 , 0.4 , 0.7 , 1.0 , 1.2 , 1.6 , 1.8 , 3.0 }; int bin_n = sizeof ( bins ) / sizeof ( * bins ) - 1 ; /*------------------------------------------------------------------------------------------------------*/ //Now we must choose initial conditions in order to fit our data double * init_conditions = new double [ 4 ]; /*-----------------------------------I N S E R T C O D E H E R E-----------------------------------*/ init_conditions [ 0 ] = /*peak1*/ ; init_conditions [ 1 ] = /*peak2*/ ; init_conditions [ 2 ] = /*peak3*/ ; init_conditions [ 3 ] = /*sigma*/ ; /*------------------------------------------------------------------------------------------------------*/ We'll start by choosing the desired bins for the transverse momentum. If you're feeling brave, choose appropriate bins for our fit remembering that we need a fair amount of data in each bin (more events mean a better fit!). If not, we've left a suggestion that you can paste onto the Efficiency.C file. Start with the p T variable. Bin Suggestion //-- BINS USED TO CALCULATE PT double bins [] = { 2 , 3.4 , 4 , 4.2 , 4.4 , 4.7 , 5.0 , 5.1 , 5.2 , 5.4 , 5.5 , 5.6 , 5.7 , 5.8 , 5.9 , 6.2 , 6.4 , 6.6 , 6.8 , 7.3 , 9.5 , 13.0 , 17.0 , 40 }; //-- BINS USED TO CALCULATE PHI double bins [] = { -3 , -2.8 , -2.6 , -2.4 , -2.2 , -2.0 , -1.8 , -1.6 , -1.4 , -1.2 , -1.0 , -0.8 , -0.6 , -0.4 , -0.2 , 0 , 0.2 , 0.4 , 0.5 , 0.6 , 1.0 , 1.2 , 1.4 , 1.6 , 1.8 , 2.0 , 2.2 , 2.4 , 2.6 , 2.8 , 3.0 }; //-- BINS USED TO CALCULATE ETA double bins [] = { -2.0 , -1.9 , -1.8 , -1.7 , -1.6 , -1.5 , -1.4 , -1.2 , -1.0 , -0.8 , -0.6 , -0.4 , 0 , 0.2 , 0.4 , 0.6 , 0.7 , 0.95 , 1.2 , 1.4 , 1.5 , 1.6 , 2.0 }; Now that the bins are set, we'll need to define the initial parameters for our fit. You can try to get a good 1st approximation from the plot of the invariant mass that we got before: or use the suggested values Suggestion for the Initial Values Try the following initial values: init_conditions [ 0 ] = 9.46030 ; init_conditions [ 1 ] = 10.02326 ; init_conditions [ 2 ] = 10.3552 ; init_conditions [ 3 ] = 0.08 ; We are now ready to execute the fits! The Fit \u00b6 We execute a simultaneous fit using a Gaussian curve and a Crystall Ball function for the fist peak (1S) and a gaussian for the remaining peaks. For the background we use a Chebychev polynomial. The function used, doFit() , is implemented in the source file src/DoFit.cpp and it was based on the RooFit library. You can find generic tutorials for this library here . If you\u2019re starting with RooFit you may also find this one particularly useful. You won't need to do anything in src/DoFit.cpp but you can check it out if you're curious. Check out src/DoFit.cpp The code here is presented in smaller \"digestible\" chunks, so it's easier to understand. We begin by linking our dataset to a usable object ( the TTree ) and by creating a TCanvas to store the fit plots. we then define a few RooRealVar and RooFormulaVar objects will be used to select the bin associated to the string condition (i.e. \"ProbeMuon_Pt 10 && ProbeMuon_Pt < 10\"). After spliting the original dataset, the resulting two RooDataSet are used to create two binned RooDataHist in which we'll perform the fits. double * doFit ( string condition , string MuonID_str , string quant , double * init_conditions , bool save = true ) // RETURNS ARRAY WITH [yield_all, yield_pass, err_all, err_pass] -> OUTPUT ARRAY { string MuonID_file = \"\" ; if ( MuonID_str == \"PassingProbeTrackingMuon\" ) MuonID_file = \"trackerMuon\" ; if ( MuonID_str == \"PassingProbeStandAloneMuon\" ) MuonID_file = \"standaloneMuon\" ; if ( MuonID_str == \"PassingProbeGlobalMuon\" ) MuonID_file = \"globalMuon\" ; TFile * file0 = TFile :: Open (( \"DATA/Upsilon/\" + MuonID_file + \"/T&P_UPSILON_DATA_MC.root\" ). c_str ()); TTree * DataTree = ( TTree * ) file0 -> Get (( \"UPSILON_DATA\" )); double _mmin = 9 ; double _mmax = 10.8 ; RooRealVar MuonID ( MuonID_str . c_str (), MuonID_str . c_str (), 0 , 1 ); //Muon_Id RooRealVar InvariantMass ( \"InvariantMass\" , \"InvariantMass\" , _mmin , _mmax ); double * limits = new double [ 2 ]; if ( quant == \"Pt\" ) { limits [ 0 ] = 0 ; limits [ 1 ] = 40 ; } if ( quant == \"Eta\" ) { limits [ 0 ] = -3 ; limits [ 1 ] = 3 ; } if ( quant == \"Phi\" ) { limits [ 0 ] = -2 ; limits [ 1 ] = 2 ; } RooRealVar quantity (( \"ProbeMuon_\" + quant ). c_str (), ( \"ProbeMuon_\" + quant ). c_str (), limits [ 0 ], limits [ 1 ]); RooFormulaVar * redeuce = new RooFormulaVar ( \"PPTM\" , condition . c_str (), RooArgList ( quantity )); RooDataSet * Data_ALL = new RooDataSet ( \"DATA\" , \"DATA\" , DataTree , RooArgSet ( InvariantMass , MuonID , quantity ), * redeuce ); RooFormulaVar * cutvar = new RooFormulaVar ( \"PPTM\" , ( condition + \" && \" + MuonID_str + \" == 1\" ). c_str () , RooArgList ( MuonID , quantity )); RooDataSet * Data_PASSING = new RooDataSet ( \"DATA_PASS\" , \"DATA_PASS\" , DataTree , RooArgSet ( InvariantMass , MuonID , quantity ), * cutvar ); // RooDataHist * dh_ALL = Data_ALL -> binnedClone (); RooDataHist * dh_PASSING = Data_PASSING -> binnedClone (); We then create the variables used as parameters in the fit. a0 and a1 used in the Chebychev polynomial ( RooChebychev , for the background and sigma , mean1 , mean2 , mean3 used on the RooCBShape and RooGaussian for the signal. frac1 and frac2 are used as normalization values. For the yields of the fits, we defined the n_signal and n_background pairs. // BACKGROUND VARIABLES RooRealVar a0 ( \"a0\" , \"a0\" , 0 , -10 , 10 ); RooRealVar a1 ( \"a1\" , \"a1\" , 0 , -10 , 10 ); // BACKGROUND FUNCTION RooChebychev background ( \"background\" , \"background\" , InvariantMass , RooArgList ( a0 , a1 )); // GAUSSIAN VARIABLES RooRealVar sigma ( \"sigma\" , \"sigma\" , init_conditions [ 3 ]); RooRealVar mean1 ( \"mean1\" , \"mean1\" , init_conditions [ 0 ]); RooRealVar mean2 ( \"mean2\" , \"mean2\" , init_conditions [ 1 ]); RooRealVar mean3 ( \"mean3\" , \"mean3\" , init_conditions [ 2 ]); // CRYSTAL BALL VARIABLES RooRealVar alpha ( \"alpha\" , \"alpha\" , 1.4384e+00 ); RooRealVar n ( \"n\" , \"n\" , 1.6474e+01 ); // FIT FUNCTIONS RooCBShape gaussian1 ( \"signal1\" , \"signal1\" , InvariantMass , mean1 , sigma , alpha , n ); RooGaussian gaussian2 ( \"signal2\" , \"signal2\" , InvariantMass , mean2 , sigma ); RooGaussian gaussian3 ( \"signal3\" , \"signal3\" , InvariantMass , mean3 , sigma ); double n_signal_initial1 = ( Data_ALL -> sumEntries ( TString :: Format ( \"abs(InvariantMass-%g)<0.015\" , init_conditions [ 1 ])) - Data_ALL -> sumEntries ( TString :: Format ( \"abs(InvariantMass-%g)<0.030&&abs(InvariantMass-%g)>.015\" , init_conditions [ 1 ], init_conditions [ 1 ]))) / Data_ALL -> sumEntries (); double n_signal_initial2 = ( Data_ALL -> sumEntries ( TString :: Format ( \"abs(InvariantMass-%g)<0.015\" , init_conditions [ 2 ])) - Data_ALL -> sumEntries ( TString :: Format ( \"abs(InvariantMass-%g)<0.030&&abs(InvariantMass-%g)>.015\" , init_conditions [ 2 ], init_conditions [ 2 ]))) / Data_ALL -> sumEntries (); double n_signal_initial3 = ( Data_ALL -> sumEntries ( TString :: Format ( \"abs(InvariantMass-%g)<0.015\" , init_conditions [ 3 ])) - Data_ALL -> sumEntries ( TString :: Format ( \"abs(InvariantMass-%g)<0.030&&abs(InvariantMass-%g)>.015\" , init_conditions [ 3 ], init_conditions [ 3 ]))) / Data_ALL -> sumEntries (); double n_signal_initial_total = n_signal_initial1 + n_signal_initial2 + n_signal_initial3 ; RooRealVar frac1 ( \"frac1\" , \"frac1\" , 7.1345e-01 ); RooRealVar frac2 ( \"frac2\" , \"frac2\" , 1.9309e-01 ); RooAddPdf * signal ; signal = new RooAddPdf ( \"signal\" , \"signal\" , RooArgList ( gaussian1 , gaussian2 , gaussian3 ), RooArgList ( frac1 , frac2 )); double n_back_initial = 1. - n_signal_initial1 - n_signal_initial2 - n_signal_initial3 ; RooRealVar n_signal_total ( \"n_signal_total\" , \"n_signal_total\" , n_signal_initial_total , 0. , Data_ALL -> sumEntries ()); RooRealVar n_signal_total_pass ( \"n_signal_total_pass\" , \"n_signal_total_pass\" , n_signal_initial_total , 0. , Data_PASSING -> sumEntries ()); After defining the individual pdfs that will be used in the fit, we add them together to make our model with the signal and background. We then combine the data onto a RooSimultaneous so that we can execute a simultaneous fit with the fitTo method. The fit result is then stored. RooRealVar n_back ( \"n_back\" , \"n_back\" , n_back_initial , 0. , Data_ALL -> sumEntries ()); RooRealVar n_back_pass ( \"n_back_pass\" , \"n_back_pass\" , n_back_initial , 0. , Data_PASSING -> sumEntries ()); RooAddPdf * model ; RooAddPdf * model_pass ; model = new RooAddPdf ( \"model\" , \"model\" , RooArgList ( * signal , background ), RooArgList ( n_signal_total , n_back )); model_pass = new RooAddPdf ( \"model_pass\" , \"model_pass\" , RooArgList ( * signal , background ), RooArgList ( n_signal_total_pass , n_back_pass )); // SIMULTANEOUS FIT RooCategory sample ( \"sample\" , \"sample\" ) ; sample . defineType ( \"All\" ) ; sample . defineType ( \"PASSING\" ) ; RooDataHist combData ( \"combData\" , \"combined data\" , InvariantMass , Index ( sample ), Import ( \"ALL\" , * dh_ALL ), Import ( \"PASSING\" , * dh_PASSING )); RooSimultaneous simPdf ( \"simPdf\" , \"simultaneous pdf\" , sample ) ; simPdf . addPdf ( * model , \"ALL\" ); simPdf . addPdf ( * model_pass , \"PASSING\" ); RooFitResult * fitres = new RooFitResult ; fitres = simPdf . fitTo ( combData , RooFit :: Save ()); // OUTPUT ARRAY double * output = new double [ 4 ]; RooRealVar * yield_ALL = ( RooRealVar * ) fitres -> floatParsFinal (). find ( \"n_signal_total\" ); RooRealVar * yield_PASS = ( RooRealVar * ) fitres -> floatParsFinal (). find ( \"n_signal_total_pass\" ); output [ 0 ] = yield_ALL -> getVal (); output [ 1 ] = yield_PASS -> getVal (); output [ 2 ] = yield_ALL -> getError (); output [ 3 ] = yield_PASS -> getError (); The rest of the code has to do with the plotting of the fit and with memory management. frame -> SetTitle ( \"ALL\" ); frame -> SetXTitle ( \"#mu^{+}#mu^{-} invariant mass [GeV/c^{2}]\" ); Data_ALL -> plotOn ( frame ); model -> plotOn ( frame ); model -> plotOn ( frame , RooFit :: Components ( \"signal1\" ), RooFit :: LineStyle ( kDashed ), RooFit :: LineColor ( kGreen )); model -> plotOn ( frame , RooFit :: Components ( \"signal2\" ), RooFit :: LineStyle ( kDashed ), RooFit :: LineColor ( kMagenta - 5 )); model -> plotOn ( frame , RooFit :: Components ( \"signal3\" ), RooFit :: LineStyle ( kDashed ), RooFit :: LineColor ( kOrange )); model -> plotOn ( frame , RooFit :: Components ( \"background\" ), RooFit :: LineStyle ( kDashed ), RooFit :: LineColor ( kRed )); c_all -> cd (); frame -> Draw ( \"\" ); RooPlot * frame_pass = InvariantMass . frame ( RooFit :: Title ( \"Invariant Mass\" )); c_pass -> cd (); frame_pass -> SetTitle ( \"PASSING\" ); frame_pass -> SetXTitle ( \"#mu^{+}#mu^{-} invariant mass [GeV/c^{2}]\" ); Data_PASSING -> plotOn ( frame_pass ); model_pass -> plotOn ( frame_pass ); model_pass -> plotOn ( frame_pass , RooFit :: Components ( \"signal1\" ), RooFit :: LineStyle ( kDashed ), RooFit :: LineColor ( kGreen )); model_pass -> plotOn ( frame_pass , RooFit :: Components ( \"signal2\" ), RooFit :: LineStyle ( kDashed ), RooFit :: LineColor ( kMagenta - 5 )); model_pass -> plotOn ( frame_pass , RooFit :: Components ( \"signal3\" ), RooFit :: LineStyle ( kDashed ), RooFit :: LineColor ( kOrange )); model_pass -> plotOn ( frame_pass , RooFit :: Components ( \"background\" ), RooFit :: LineStyle ( kDashed ), RooFit :: LineColor ( kRed )); frame_pass -> Draw (); if ( save ) { c_pass -> SaveAs (( \"Fit Result/\" + condition + \"_ALL.pdf\" ). c_str ()); c_all -> SaveAs (( \"Fit Result/\" + condition + \"_PASS.pdf\" ). c_str ()); } // DELETING ALLOCATED MEMORY delete [] limits ; // delete file0 ; // delete Data_ALL ; delete Data_PASSING ; // delete dh_ALL ; delete dh_PASSING ; // delete cutvar ; delete redeuce ; // delete signal ; // delete c_all ; delete c_pass ; // delete model ; delete model_pass ; delete fitres ; return output ; } } The fitting and storing of the fit output of each bin is achieved by the following loop in the Efficiency.C code. for ( int i = 0 ; i < bin_n ; i ++ ) { if ( DataIsMC ) yields_n_errs [ i ] = McYield ( conditions [ i ], quantity ); else yields_n_errs [ i ] = doFit ( conditions [ i ], MuonId , quantity , init_conditions ); //doFit returns: [yield_all, yield_pass, err_all, err_pass] } The McYield() function ( src/McYield.cpp ) has the same output as doFit() and has to do with Monte Carlo dataset, which only contains signal for the 1S peak. To get the efficiency plot, we used the TEfficiency class from ROOT. You'll see that in order to create a TEfficiency object, one of the constructors requires two TH1 objects, i.e., two histograms. One with all the probes and one with the passing probes. The creation of these TH1 objects is taken care of by the src/make_hist.cpp code. Check out src/make_hist.cpp TH1F * make_hist ( string name , double ** values , int qnt , int bin_n , Double_t * binning , bool IsDataMc , bool DRAW = false ) { //AddBinContent //HISTOGRAM NEEDS TO HAVE VARIABLE BINS TH1F * hist = new TH1F ( name . c_str (), name . c_str (), bin_n , binning ); for ( int i = 0 ; i < bin_n ; i ++ ) { hist - SetBinContent ( i , values [ i ][ qnt ]); if ( IsDataMc == false ) hist - SetBinError ( i , values [ i ][ qnt + 2 ]); } if ( DRAW ) { TCanvas * xperiment = new TCanvas ; xperiment - cd (); hist - Draw (); } return hist ; } To plot the efficiency we used the src/get_efficiency.cpp function. Check out get_efficiency.cpp TEfficiency * get_efficiency ( TH1F * ALL , TH1F * PASS , string quantity , bool DataIsMc ) { gSystem -> cd ( \"Efficiency Result\" ); gSystem -> cd ( quantity . c_str ()); string * file_name = new string [ 2 ]; file_name [ 0 ] = \"Efficiency_Run2011.root\" ; file_name [ 1 ] = \"Efficiency_MC.root\" ; TFile * pFile = new TFile ( file_name [ DataIsMc ]. c_str (), \"recreate\" ); TEfficiency * pEff = new TEfficiency (); pEff -> SetName ( \"Efficiency\" ); pEff -> SetPassedHistogram ( * PASS , \"f\" ); pEff -> SetTotalHistogram ( * ALL , \"f\" ); pEff -> SetDirectory ( gDirectory ); pFile -> Write (); TCanvas * oi = new TCanvas (); oi -> cd (); pEff -> Draw (); gPad -> Update (); auto graph = pEff -> GetPaintedGraph (); graph -> SetMinimum ( 0.8 ); graph -> SetMaximum ( 1.2 ); gPad -> Update (); gSystem -> cd ( \"../..\" ); delete [] file_name ; return pEff ; } Note that we load all these functions in the src area directly in header of the Efficiency.C code. Now that you understand what the Efficiency.C macro does, run your code with in a batch mode ( -b ) and with a quit-when-done switch ( -q ): root -q -b Efficiency.C When the execution finishes, you should have 2 new files. One on your working directory: Histograms.root , and another one Efficiency_Run2011.root located at /Efficiency Result/Pt . The second contains the efficiency we calculated! the first file is used to redo any unusable fits. To open Efficiency_Run2011.root , on your working directory type: root -l new TBrowser A window like this should have popped up. If you click on Efficiency_Run2011.root , a plot will show up with the efficiency value for each bin! If you want, check out the PDF files under the Fit\\ Result/ directory, which contain the fitting results. Now we must re-run the code, but before that, change DataIsMc value to TRUE . This will generate an efficiency for the simulated data, so that we can compare it with the 2011 run. Check that you have both Efficiency_Run2011.root and Efficiency_MC.root files in the following directory Efficiency Result/Pt . If so, now uncomment Efficiency.C line: 66: //compare_efficiency(quantity, \"Efficiency Result/\" + quantity + \"/Efficiency_MC.root\", \"Efficiency Result/\" + quantity + \"/Efficiency_Run2011.root\"); and run the macro again. You should get something like the following result if you inspect the image at Comparison\\ Run2011\\ vs\\ MC/Efficiency.png . If everything went well and you still have time to go, repeat this process for the two other variables, \u03b7 and \u03c6! In case you want to change one of the fit results, use the change_bin.cpp function commented on line:61. Important note! Don't forget to comment line:68 when repeating the procedure for the other quantities! compare_efficiency ( quantity , \"Efficiency Result/\" + quantity + \"/Efficiency_MC.root\" , \"Efficiency Result/\" + quantity + \"/Efficiency_Run2011.root\" ); Extra challenge Fancy some more work? Download this J/\u03c8 dataset and try out the new methods you just learned! You'll have to change the DoFit.cpp function since J/\u03c8's only peak is made up of a Crystall ball and a Gaussian curve. Good luck!","title":"Fitting"},{"location":"analysis/selection/idefficiencystudy/tutorial/02-fitting/#setting-it-up","text":"In order to run this exercise you do not really need to be in a CMSSW area. It would be actually better if you worked outside your usual CMSSW_5_3_32 environment. So, if, for instance, you are working with the Docker container, instead of working on /home/cmsusr/CMSSW_5_3_32/src you could work on any directory you can create at the /home/cmsusr level. Alternatively, you could work directly on your own host machine if you managed to install ROOT on it. For this example we assume you will be working in either the Docker container or the virtual machine. Since we will be needing ROOT version greater than 6, then do not forget to set it up from LCG (as you learned in the ROOT pre-exercise) by doing: source /cvmfs/sft.cern.ch/lcg/views/LCG_95/x86_64-slc6-gcc8-opt/setup.sh Clone the repository and go to the fitting method tutorial: git clone git://github.com/allanjales/TagAndProbe cd TagAndProbe/efficiency_tools/fitting","title":"Setting it up"},{"location":"analysis/selection/idefficiencystudy/tutorial/02-fitting/#the-fitting-method","text":"First, a brief explanation of the method we\u2019ll be studying. It consists on fitting the invariant mass of the tag & probe pairs, in the two categories: passing probes, and all probes. I.e., for the unbiased leg of the decay, one can apply a selection criteria (a set of cuts) and determine whether the object passes those criteria or not. The procedure is applied after splitting the data in bins of a kinematic variable of the probe object (e.g. the traverse momentum, p T ); as such, the efficiency will be measured as a function of that quantity for each of the bins. So, in the picture below, on the left, let's imagine that the p T bin we are selecting is the one marked in red. But, of course, in that bin (like in the rest) you will have true \u03d2 decays as well as muon pairs from other processes (maybe QCD, for instance). The true decays would make up our signal , whereas the other events will be considered the background . The fit, which is made in a different space (the invariant mass space) allows to statistically discriminate between signal and background. To compute the efficiency we simply divide the signal yield from the fits to the passing category by the signal yield from the fit of the inclusive (All) category. This approach is depicted in the middle and right-hand plots of the image below. At the end of the day, then, you will have to make these fits for each bin in the range of interest. Let's start exploring our dataset. From the cloned directory, type: cd DATA/Upsilon/trackerMuon/ root -l T \\& P_UPSILON_DATA.root If everything's right, you should get something like: Attaching file T&P_UPSILON_DATA.root as _file0... U(TFile *) 0x7fe2f34ca270 Of course, you can explore this file, if you want, using all the tools you learn in the ROOT pre-exercise. This file contains ntuples that were obtained using procedures similar to the ones you have been learning in this workshop. Note In the following plots, remember that the units of the x axis are in GeV/c. Now, before we start fitting the invariant mass it's important to look at it's shape first. To visualize our data's invariant mass, do (within ROOT): root [] UPSILON_DATA -> Draw ( \"InvariantMass\" ) If you got the previous result, we're ready to go. The dataset used in this exercise has been collected by the CMS experiment, in proton-proton collisions at the LHC. It contains 986100 entries (muon pair candidates) with an associated invariant mass. For each candidate, the transverse momentum (p T ), rapidity(\u03b7) and azimuthal angle (\u03c6) are stored, along with a binary flag PassingProbeTrackingMuon , which is 1 in case the corresponding probe satisfied the tracker muon selection criteria and 0 in case it doesn't. Note Note that it does not really matter what kind of selection criteria these ntuples were created with. The procedure would be the same. You can create your own, similar ntuples with the criteria that you need to study. As you may have seen, after exploring the content of the root file, the UPSILON_DATA tree has these variables: | InvarianMass | | PassingProbeTrackingMuon | | ProbeMuon_Pt | | ProbeMuon_Eta | | ProbeMuon_Phi| We'll start by calculating the efficiency as a function of p T . It is useful to have an idea of the distribution of the quantity we want to study. In order to do this, we\u2019ll repeat the steps previously used to plot the invariant mass, but now for the ProbeMuon_Pt variable. root [] UPSILON_DATA -> Draw ( \"ProbeMuon_Pt\" ) Hmm.. seems like our domain is larger than we need it to be. To fix this, we can apply a constraint to our plot. Try: root [] UPSILON_DATA -> Draw ( \"ProbeMuon_Pt\" , \"ProbeMuon_Pt < 20\" ) Exit ROOT and get back to the main area: root [] .q cd ../../../ Now that you're acquainted with the data, open the Efficiency.C file. You'll have to make some small adjustments to the code in this section (from line:19 to line:34): /*-----------------------------------I N S E R T C O D E H E R E-----------------------------------*/ //string quantity = \"Pt\"; double bins[] = {0., 2.0, 3.4, 4.0, 4.4, 4.7, 5.0, 5.6, 5.8, 6.0, 6.2, 6.4, 6.6, 6.8, 7.3, 9.5, 13.0, 17.0, 40.}; //string quantity = \"Eta\"; double bins[] = {-2.4, -1.8, -1.4, -1.2, -1.0, -0.8, -0.5, -0.2, 0, 0.2, 0.5, 0.8, 1.0, 1.2, 1.4, 1.8, 2.4}; string quantity = \"Phi\" ; double bins [] = { -3.0 , -1.8 , -1.6 , -1.2 , -1.0 , -0.7 , -0.4 , -0.2 , 0 , 0.2 , 0.4 , 0.7 , 1.0 , 1.2 , 1.6 , 1.8 , 3.0 }; int bin_n = sizeof ( bins ) / sizeof ( * bins ) - 1 ; /*------------------------------------------------------------------------------------------------------*/ //Now we must choose initial conditions in order to fit our data double * init_conditions = new double [ 4 ]; /*-----------------------------------I N S E R T C O D E H E R E-----------------------------------*/ init_conditions [ 0 ] = /*peak1*/ ; init_conditions [ 1 ] = /*peak2*/ ; init_conditions [ 2 ] = /*peak3*/ ; init_conditions [ 3 ] = /*sigma*/ ; /*------------------------------------------------------------------------------------------------------*/ We'll start by choosing the desired bins for the transverse momentum. If you're feeling brave, choose appropriate bins for our fit remembering that we need a fair amount of data in each bin (more events mean a better fit!). If not, we've left a suggestion that you can paste onto the Efficiency.C file. Start with the p T variable. Bin Suggestion //-- BINS USED TO CALCULATE PT double bins [] = { 2 , 3.4 , 4 , 4.2 , 4.4 , 4.7 , 5.0 , 5.1 , 5.2 , 5.4 , 5.5 , 5.6 , 5.7 , 5.8 , 5.9 , 6.2 , 6.4 , 6.6 , 6.8 , 7.3 , 9.5 , 13.0 , 17.0 , 40 }; //-- BINS USED TO CALCULATE PHI double bins [] = { -3 , -2.8 , -2.6 , -2.4 , -2.2 , -2.0 , -1.8 , -1.6 , -1.4 , -1.2 , -1.0 , -0.8 , -0.6 , -0.4 , -0.2 , 0 , 0.2 , 0.4 , 0.5 , 0.6 , 1.0 , 1.2 , 1.4 , 1.6 , 1.8 , 2.0 , 2.2 , 2.4 , 2.6 , 2.8 , 3.0 }; //-- BINS USED TO CALCULATE ETA double bins [] = { -2.0 , -1.9 , -1.8 , -1.7 , -1.6 , -1.5 , -1.4 , -1.2 , -1.0 , -0.8 , -0.6 , -0.4 , 0 , 0.2 , 0.4 , 0.6 , 0.7 , 0.95 , 1.2 , 1.4 , 1.5 , 1.6 , 2.0 }; Now that the bins are set, we'll need to define the initial parameters for our fit. You can try to get a good 1st approximation from the plot of the invariant mass that we got before: or use the suggested values Suggestion for the Initial Values Try the following initial values: init_conditions [ 0 ] = 9.46030 ; init_conditions [ 1 ] = 10.02326 ; init_conditions [ 2 ] = 10.3552 ; init_conditions [ 3 ] = 0.08 ; We are now ready to execute the fits!","title":"The Fitting Method"},{"location":"analysis/selection/idefficiencystudy/tutorial/02-fitting/#the-fit","text":"We execute a simultaneous fit using a Gaussian curve and a Crystall Ball function for the fist peak (1S) and a gaussian for the remaining peaks. For the background we use a Chebychev polynomial. The function used, doFit() , is implemented in the source file src/DoFit.cpp and it was based on the RooFit library. You can find generic tutorials for this library here . If you\u2019re starting with RooFit you may also find this one particularly useful. You won't need to do anything in src/DoFit.cpp but you can check it out if you're curious. Check out src/DoFit.cpp The code here is presented in smaller \"digestible\" chunks, so it's easier to understand. We begin by linking our dataset to a usable object ( the TTree ) and by creating a TCanvas to store the fit plots. we then define a few RooRealVar and RooFormulaVar objects will be used to select the bin associated to the string condition (i.e. \"ProbeMuon_Pt 10 && ProbeMuon_Pt < 10\"). After spliting the original dataset, the resulting two RooDataSet are used to create two binned RooDataHist in which we'll perform the fits. double * doFit ( string condition , string MuonID_str , string quant , double * init_conditions , bool save = true ) // RETURNS ARRAY WITH [yield_all, yield_pass, err_all, err_pass] -> OUTPUT ARRAY { string MuonID_file = \"\" ; if ( MuonID_str == \"PassingProbeTrackingMuon\" ) MuonID_file = \"trackerMuon\" ; if ( MuonID_str == \"PassingProbeStandAloneMuon\" ) MuonID_file = \"standaloneMuon\" ; if ( MuonID_str == \"PassingProbeGlobalMuon\" ) MuonID_file = \"globalMuon\" ; TFile * file0 = TFile :: Open (( \"DATA/Upsilon/\" + MuonID_file + \"/T&P_UPSILON_DATA_MC.root\" ). c_str ()); TTree * DataTree = ( TTree * ) file0 -> Get (( \"UPSILON_DATA\" )); double _mmin = 9 ; double _mmax = 10.8 ; RooRealVar MuonID ( MuonID_str . c_str (), MuonID_str . c_str (), 0 , 1 ); //Muon_Id RooRealVar InvariantMass ( \"InvariantMass\" , \"InvariantMass\" , _mmin , _mmax ); double * limits = new double [ 2 ]; if ( quant == \"Pt\" ) { limits [ 0 ] = 0 ; limits [ 1 ] = 40 ; } if ( quant == \"Eta\" ) { limits [ 0 ] = -3 ; limits [ 1 ] = 3 ; } if ( quant == \"Phi\" ) { limits [ 0 ] = -2 ; limits [ 1 ] = 2 ; } RooRealVar quantity (( \"ProbeMuon_\" + quant ). c_str (), ( \"ProbeMuon_\" + quant ). c_str (), limits [ 0 ], limits [ 1 ]); RooFormulaVar * redeuce = new RooFormulaVar ( \"PPTM\" , condition . c_str (), RooArgList ( quantity )); RooDataSet * Data_ALL = new RooDataSet ( \"DATA\" , \"DATA\" , DataTree , RooArgSet ( InvariantMass , MuonID , quantity ), * redeuce ); RooFormulaVar * cutvar = new RooFormulaVar ( \"PPTM\" , ( condition + \" && \" + MuonID_str + \" == 1\" ). c_str () , RooArgList ( MuonID , quantity )); RooDataSet * Data_PASSING = new RooDataSet ( \"DATA_PASS\" , \"DATA_PASS\" , DataTree , RooArgSet ( InvariantMass , MuonID , quantity ), * cutvar ); // RooDataHist * dh_ALL = Data_ALL -> binnedClone (); RooDataHist * dh_PASSING = Data_PASSING -> binnedClone (); We then create the variables used as parameters in the fit. a0 and a1 used in the Chebychev polynomial ( RooChebychev , for the background and sigma , mean1 , mean2 , mean3 used on the RooCBShape and RooGaussian for the signal. frac1 and frac2 are used as normalization values. For the yields of the fits, we defined the n_signal and n_background pairs. // BACKGROUND VARIABLES RooRealVar a0 ( \"a0\" , \"a0\" , 0 , -10 , 10 ); RooRealVar a1 ( \"a1\" , \"a1\" , 0 , -10 , 10 ); // BACKGROUND FUNCTION RooChebychev background ( \"background\" , \"background\" , InvariantMass , RooArgList ( a0 , a1 )); // GAUSSIAN VARIABLES RooRealVar sigma ( \"sigma\" , \"sigma\" , init_conditions [ 3 ]); RooRealVar mean1 ( \"mean1\" , \"mean1\" , init_conditions [ 0 ]); RooRealVar mean2 ( \"mean2\" , \"mean2\" , init_conditions [ 1 ]); RooRealVar mean3 ( \"mean3\" , \"mean3\" , init_conditions [ 2 ]); // CRYSTAL BALL VARIABLES RooRealVar alpha ( \"alpha\" , \"alpha\" , 1.4384e+00 ); RooRealVar n ( \"n\" , \"n\" , 1.6474e+01 ); // FIT FUNCTIONS RooCBShape gaussian1 ( \"signal1\" , \"signal1\" , InvariantMass , mean1 , sigma , alpha , n ); RooGaussian gaussian2 ( \"signal2\" , \"signal2\" , InvariantMass , mean2 , sigma ); RooGaussian gaussian3 ( \"signal3\" , \"signal3\" , InvariantMass , mean3 , sigma ); double n_signal_initial1 = ( Data_ALL -> sumEntries ( TString :: Format ( \"abs(InvariantMass-%g)<0.015\" , init_conditions [ 1 ])) - Data_ALL -> sumEntries ( TString :: Format ( \"abs(InvariantMass-%g)<0.030&&abs(InvariantMass-%g)>.015\" , init_conditions [ 1 ], init_conditions [ 1 ]))) / Data_ALL -> sumEntries (); double n_signal_initial2 = ( Data_ALL -> sumEntries ( TString :: Format ( \"abs(InvariantMass-%g)<0.015\" , init_conditions [ 2 ])) - Data_ALL -> sumEntries ( TString :: Format ( \"abs(InvariantMass-%g)<0.030&&abs(InvariantMass-%g)>.015\" , init_conditions [ 2 ], init_conditions [ 2 ]))) / Data_ALL -> sumEntries (); double n_signal_initial3 = ( Data_ALL -> sumEntries ( TString :: Format ( \"abs(InvariantMass-%g)<0.015\" , init_conditions [ 3 ])) - Data_ALL -> sumEntries ( TString :: Format ( \"abs(InvariantMass-%g)<0.030&&abs(InvariantMass-%g)>.015\" , init_conditions [ 3 ], init_conditions [ 3 ]))) / Data_ALL -> sumEntries (); double n_signal_initial_total = n_signal_initial1 + n_signal_initial2 + n_signal_initial3 ; RooRealVar frac1 ( \"frac1\" , \"frac1\" , 7.1345e-01 ); RooRealVar frac2 ( \"frac2\" , \"frac2\" , 1.9309e-01 ); RooAddPdf * signal ; signal = new RooAddPdf ( \"signal\" , \"signal\" , RooArgList ( gaussian1 , gaussian2 , gaussian3 ), RooArgList ( frac1 , frac2 )); double n_back_initial = 1. - n_signal_initial1 - n_signal_initial2 - n_signal_initial3 ; RooRealVar n_signal_total ( \"n_signal_total\" , \"n_signal_total\" , n_signal_initial_total , 0. , Data_ALL -> sumEntries ()); RooRealVar n_signal_total_pass ( \"n_signal_total_pass\" , \"n_signal_total_pass\" , n_signal_initial_total , 0. , Data_PASSING -> sumEntries ()); After defining the individual pdfs that will be used in the fit, we add them together to make our model with the signal and background. We then combine the data onto a RooSimultaneous so that we can execute a simultaneous fit with the fitTo method. The fit result is then stored. RooRealVar n_back ( \"n_back\" , \"n_back\" , n_back_initial , 0. , Data_ALL -> sumEntries ()); RooRealVar n_back_pass ( \"n_back_pass\" , \"n_back_pass\" , n_back_initial , 0. , Data_PASSING -> sumEntries ()); RooAddPdf * model ; RooAddPdf * model_pass ; model = new RooAddPdf ( \"model\" , \"model\" , RooArgList ( * signal , background ), RooArgList ( n_signal_total , n_back )); model_pass = new RooAddPdf ( \"model_pass\" , \"model_pass\" , RooArgList ( * signal , background ), RooArgList ( n_signal_total_pass , n_back_pass )); // SIMULTANEOUS FIT RooCategory sample ( \"sample\" , \"sample\" ) ; sample . defineType ( \"All\" ) ; sample . defineType ( \"PASSING\" ) ; RooDataHist combData ( \"combData\" , \"combined data\" , InvariantMass , Index ( sample ), Import ( \"ALL\" , * dh_ALL ), Import ( \"PASSING\" , * dh_PASSING )); RooSimultaneous simPdf ( \"simPdf\" , \"simultaneous pdf\" , sample ) ; simPdf . addPdf ( * model , \"ALL\" ); simPdf . addPdf ( * model_pass , \"PASSING\" ); RooFitResult * fitres = new RooFitResult ; fitres = simPdf . fitTo ( combData , RooFit :: Save ()); // OUTPUT ARRAY double * output = new double [ 4 ]; RooRealVar * yield_ALL = ( RooRealVar * ) fitres -> floatParsFinal (). find ( \"n_signal_total\" ); RooRealVar * yield_PASS = ( RooRealVar * ) fitres -> floatParsFinal (). find ( \"n_signal_total_pass\" ); output [ 0 ] = yield_ALL -> getVal (); output [ 1 ] = yield_PASS -> getVal (); output [ 2 ] = yield_ALL -> getError (); output [ 3 ] = yield_PASS -> getError (); The rest of the code has to do with the plotting of the fit and with memory management. frame -> SetTitle ( \"ALL\" ); frame -> SetXTitle ( \"#mu^{+}#mu^{-} invariant mass [GeV/c^{2}]\" ); Data_ALL -> plotOn ( frame ); model -> plotOn ( frame ); model -> plotOn ( frame , RooFit :: Components ( \"signal1\" ), RooFit :: LineStyle ( kDashed ), RooFit :: LineColor ( kGreen )); model -> plotOn ( frame , RooFit :: Components ( \"signal2\" ), RooFit :: LineStyle ( kDashed ), RooFit :: LineColor ( kMagenta - 5 )); model -> plotOn ( frame , RooFit :: Components ( \"signal3\" ), RooFit :: LineStyle ( kDashed ), RooFit :: LineColor ( kOrange )); model -> plotOn ( frame , RooFit :: Components ( \"background\" ), RooFit :: LineStyle ( kDashed ), RooFit :: LineColor ( kRed )); c_all -> cd (); frame -> Draw ( \"\" ); RooPlot * frame_pass = InvariantMass . frame ( RooFit :: Title ( \"Invariant Mass\" )); c_pass -> cd (); frame_pass -> SetTitle ( \"PASSING\" ); frame_pass -> SetXTitle ( \"#mu^{+}#mu^{-} invariant mass [GeV/c^{2}]\" ); Data_PASSING -> plotOn ( frame_pass ); model_pass -> plotOn ( frame_pass ); model_pass -> plotOn ( frame_pass , RooFit :: Components ( \"signal1\" ), RooFit :: LineStyle ( kDashed ), RooFit :: LineColor ( kGreen )); model_pass -> plotOn ( frame_pass , RooFit :: Components ( \"signal2\" ), RooFit :: LineStyle ( kDashed ), RooFit :: LineColor ( kMagenta - 5 )); model_pass -> plotOn ( frame_pass , RooFit :: Components ( \"signal3\" ), RooFit :: LineStyle ( kDashed ), RooFit :: LineColor ( kOrange )); model_pass -> plotOn ( frame_pass , RooFit :: Components ( \"background\" ), RooFit :: LineStyle ( kDashed ), RooFit :: LineColor ( kRed )); frame_pass -> Draw (); if ( save ) { c_pass -> SaveAs (( \"Fit Result/\" + condition + \"_ALL.pdf\" ). c_str ()); c_all -> SaveAs (( \"Fit Result/\" + condition + \"_PASS.pdf\" ). c_str ()); } // DELETING ALLOCATED MEMORY delete [] limits ; // delete file0 ; // delete Data_ALL ; delete Data_PASSING ; // delete dh_ALL ; delete dh_PASSING ; // delete cutvar ; delete redeuce ; // delete signal ; // delete c_all ; delete c_pass ; // delete model ; delete model_pass ; delete fitres ; return output ; } } The fitting and storing of the fit output of each bin is achieved by the following loop in the Efficiency.C code. for ( int i = 0 ; i < bin_n ; i ++ ) { if ( DataIsMC ) yields_n_errs [ i ] = McYield ( conditions [ i ], quantity ); else yields_n_errs [ i ] = doFit ( conditions [ i ], MuonId , quantity , init_conditions ); //doFit returns: [yield_all, yield_pass, err_all, err_pass] } The McYield() function ( src/McYield.cpp ) has the same output as doFit() and has to do with Monte Carlo dataset, which only contains signal for the 1S peak. To get the efficiency plot, we used the TEfficiency class from ROOT. You'll see that in order to create a TEfficiency object, one of the constructors requires two TH1 objects, i.e., two histograms. One with all the probes and one with the passing probes. The creation of these TH1 objects is taken care of by the src/make_hist.cpp code. Check out src/make_hist.cpp TH1F * make_hist ( string name , double ** values , int qnt , int bin_n , Double_t * binning , bool IsDataMc , bool DRAW = false ) { //AddBinContent //HISTOGRAM NEEDS TO HAVE VARIABLE BINS TH1F * hist = new TH1F ( name . c_str (), name . c_str (), bin_n , binning ); for ( int i = 0 ; i < bin_n ; i ++ ) { hist - SetBinContent ( i , values [ i ][ qnt ]); if ( IsDataMc == false ) hist - SetBinError ( i , values [ i ][ qnt + 2 ]); } if ( DRAW ) { TCanvas * xperiment = new TCanvas ; xperiment - cd (); hist - Draw (); } return hist ; } To plot the efficiency we used the src/get_efficiency.cpp function. Check out get_efficiency.cpp TEfficiency * get_efficiency ( TH1F * ALL , TH1F * PASS , string quantity , bool DataIsMc ) { gSystem -> cd ( \"Efficiency Result\" ); gSystem -> cd ( quantity . c_str ()); string * file_name = new string [ 2 ]; file_name [ 0 ] = \"Efficiency_Run2011.root\" ; file_name [ 1 ] = \"Efficiency_MC.root\" ; TFile * pFile = new TFile ( file_name [ DataIsMc ]. c_str (), \"recreate\" ); TEfficiency * pEff = new TEfficiency (); pEff -> SetName ( \"Efficiency\" ); pEff -> SetPassedHistogram ( * PASS , \"f\" ); pEff -> SetTotalHistogram ( * ALL , \"f\" ); pEff -> SetDirectory ( gDirectory ); pFile -> Write (); TCanvas * oi = new TCanvas (); oi -> cd (); pEff -> Draw (); gPad -> Update (); auto graph = pEff -> GetPaintedGraph (); graph -> SetMinimum ( 0.8 ); graph -> SetMaximum ( 1.2 ); gPad -> Update (); gSystem -> cd ( \"../..\" ); delete [] file_name ; return pEff ; } Note that we load all these functions in the src area directly in header of the Efficiency.C code. Now that you understand what the Efficiency.C macro does, run your code with in a batch mode ( -b ) and with a quit-when-done switch ( -q ): root -q -b Efficiency.C When the execution finishes, you should have 2 new files. One on your working directory: Histograms.root , and another one Efficiency_Run2011.root located at /Efficiency Result/Pt . The second contains the efficiency we calculated! the first file is used to redo any unusable fits. To open Efficiency_Run2011.root , on your working directory type: root -l new TBrowser A window like this should have popped up. If you click on Efficiency_Run2011.root , a plot will show up with the efficiency value for each bin! If you want, check out the PDF files under the Fit\\ Result/ directory, which contain the fitting results. Now we must re-run the code, but before that, change DataIsMc value to TRUE . This will generate an efficiency for the simulated data, so that we can compare it with the 2011 run. Check that you have both Efficiency_Run2011.root and Efficiency_MC.root files in the following directory Efficiency Result/Pt . If so, now uncomment Efficiency.C line: 66: //compare_efficiency(quantity, \"Efficiency Result/\" + quantity + \"/Efficiency_MC.root\", \"Efficiency Result/\" + quantity + \"/Efficiency_Run2011.root\"); and run the macro again. You should get something like the following result if you inspect the image at Comparison\\ Run2011\\ vs\\ MC/Efficiency.png . If everything went well and you still have time to go, repeat this process for the two other variables, \u03b7 and \u03c6! In case you want to change one of the fit results, use the change_bin.cpp function commented on line:61. Important note! Don't forget to comment line:68 when repeating the procedure for the other quantities! compare_efficiency ( quantity , \"Efficiency Result/\" + quantity + \"/Efficiency_MC.root\" , \"Efficiency Result/\" + quantity + \"/Efficiency_Run2011.root\" ); Extra challenge Fancy some more work? Download this J/\u03c8 dataset and try out the new methods you just learned! You'll have to change the DoFit.cpp function since J/\u03c8's only peak is made up of a Crystall ball and a Gaussian curve. Good luck!","title":"The Fit"},{"location":"analysis/selection/idefficiencystudy/tutorial/03-sidebandsubtraction/","text":"Signal extraction: sideband subtraction method \u00b6 The reconstruction efficiency is calculated using only signal muons . In order to measure the efficiency, we need a way to extract signal from the dataset. You've used the fitting method and now you'll meet the sideband subtraction method. This method consists in choosing sideband and signal regions in invariant mass distribution. The sideband regions (shaded in red in the figure) have background particles and the signal region (shared in green in the figure) has background and signal particles. Note The background corresponds to candidates that do not correspond to the decay of a genuine resonance; for example, the pair is formed by the tag muon associated to an uncorrelated track produced elsewhere in the collision; the corresponding invariant mass has thus a smooth continuous shape, that is extrapolated from the signal regions into the sideband region. Note We choose only the \u03d2 (1S) signal for selecting the signal region; simulation information is further available for this resonance, allowing in the end for a comparison of results, between data and simulation. For each event category (i.e. Pass and All), and for a given variable of interest (e.g., the probe pT), two distributions are obtained, one for each region (Signal and Sideband). In order to obtain the variable distribution for the signal only, we proceed by subtracting the Background distribution (Sideband region) from the Signal+Background one (Signal region): Where the normalization \u03b1 factor quantifies the quantity of background present in the signal region> And for the uncertainty: Applying those equations we get histograms like this: Solid blue line (Total) = particles in signal region; Dashed blue line (Background) = particles in sideband regions; Solid magenta line (signal) = signal histogram (background subtracted). You will see this histogram on this exercise. About this code More info about this code can be found here . Preparing files \u00b6 First, from the root folder of our downloades repository, we need to go sideband subtraction method tutorial: cd efficiency_tools/sideband_subtraction To copy the \u03d2 dataset from real data file to your machine (requires 441 MB), type: wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm= $( wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1Fj-rrKts8jSSMdwvOnvux68ydZcKB521' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p' ) &id=1Fj-rrKts8jSSMdwvOnvux68ydZcKB521\" -O Run2011A_MuOnia_Upsilon.root && rm -rf /tmp/cookies.txt This code downloads the file directly from Google Drive. Run this code to download the simulation ntuple for \u03d2 (requires 66 MB): wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm= $( wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1ZzAOOLCKmCz0Q6pVi3AAiYFGKEpP2efM' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p' ) &id=1ZzAOOLCKmCz0Q6pVi3AAiYFGKEpP2efM\" -O Upsilon1SToMuMu_MC_full.root && rm -rf /tmp/cookies.txt Now, check if everything is ok: ls main README.md Run2011A_MuOnia_Upsilon.root Upsilon1SToMuMu_MC_full.root Your efficiency_tagandprobe folder should have these files: Preparing code for Data \u00b6 Note I will teach you to manage the files on the terminal, but you can use a graphical file explorer. We need to edit some settings. Open settings.cpp : cd main/config ls cuts.h settings.cpp There are different ways to open this file. You can try to run: gedit settings.cpp Or, if you can not use gedit, try nano: nano settings.cpp I do not have nano! You can try to use any text editor , but here is some commands you cant try to use to install it: Ubuntu/Debian: sudo apt-get -y install nano . RedHat/CentOS/Fedora: sudo yum install nano . Mac OS X: nano is installed by default . We want to calculate efficiencies of tracker muons . With the settings.cpp file opened, make sure to let the variables like this: //Canvas drawing bool shouldDrawInvariantMassCanvas = true ; bool shouldDrawInvariantMassCanvasRegion = true ; bool shouldDrawQuantitiesCanvas = true ; bool shouldDrawEfficiencyCanvas = true ; //Muon id analyse bool doTracker = true ; bool doStandalone = false ; bool doGlobal = false ; We want to calculate the efficiency using specific files that we downloaded. They name are Run2011A_MuOnia_Upsilon.root and Upsilon1SToMuMu_MC_full.root and are listed in const char *files[] . While settings.cpp is open, try to use the variable int useFile to run Run2011A_MuOnia_Upsilon.root . How to do this Make sure useFile is correct: //List of files const char * files [] = { \"../data_histoall.root\" , \"../Run2011AMuOnia_mergeNtuple.root\" , \"\" \"../JPsiToMuMu_mergeMCNtuple.root\" , \"../Run2011A_MuOnia_Upsilon.root\" , \"../Upsilon1SToMuMu_MC_full.root\" }; const char * directoriesToSave [] = { \"../results/result/\" , \"../results/Jpsi Run 2011/\" , \"../results/Jpsi MC 2020/\" , \"../results/Upsilon Run 2011/\" , \"../results/Upsilon MC 2020/\" }; //MAIN OPTIONS //Which file of files (variable above) should use int useFile = 3 ; It will tell which configuration the program will use. So, the macro will run with the ntuple in files[useFile] and the results will be stored in directoriesToSave[useFile] . the first three files won't be used in this execise. About code Normally we need to set the variables bool isMC and const char* resonance , but at this time it is already done and set automatically for these ntuples' names. Editting bins \u00b6 The code allows to define the binning of the kinematic variable, to ensure each bin is sufficiently populated, for increased robustness. To change the binning, locate PassingFailing.h cd ../classes ls FitFunctions.h MassValues.h PtEtaPhi.h TagProbe.h InvariantMass.h PassingFailing.h SidebandSubtraction.h Type.h And then Open PassingFailing.h gedit PassingFailing.h Search for the createEfficiencyPlot(...) function. You'll find something like this: void createHistogram ( TH1D * & histo , const char * histoName ) {...} For each quantity (pT, eta, phi) we used different bins. To change the bins, look inside the createEfficiencyPlot(...) function. In a simpler version, you'll see a structure like this: //Variable bin for pT if ( strcmp ( quantityName , \"Pt\" ) == 0 ) { //Here creates histogram for pT } //Variable bin for eta else if ( strcmp ( quantityName , \"Eta\" ) == 0 ) { //Here creates histogram for eta } //Bins for phi else { //Here creates histogram for phi } See the whole scructure Don't be scared! Code doens't bite. //Variable bin for pT if ( strcmp ( quantityName , \"Pt\" ) == 0 ) { double xbins [ 10000 ]; xbins [ 0 ] = .0 ; int nbins = 0 ; double binWidth = 1. ; for ( int i = 1 ; xbins [ i -1 ] < xMax + binWidth ; i ++ ) { xbins [ i ] = xbins [ i -1 ] < 1. ? 1. : xbins [ i -1 ] * ( 1 + binWidth ); nbins ++ ; } histo = new TH1D ( hName . data (), hTitle . data (), nbins , xbins ); } //Variable bin for eta else if ( strcmp ( quantityName , \"Eta\" ) == 0 ) { double xbins [ 10000 ]; xbins [ 0 ] = .5 ; int nbins = 0 ; double binWidth = 0.2 ; //For positive for ( int i = 1 ; xbins [ i -1 ] < xMax + binWidth ; i ++ ) { xbins [ i ] = xbins [ i -1 ] < 1. ? 1. : xbins [ i -1 ] * ( 1 + binWidth ); nbins ++ ; } //Duplicate array and create another double rxbins [ nbins * 2 + 1 ]; int entry = 0 ; for ( int i = nbins ; i = 0 ; i -- ) { rxbins [ entry ] = - xbins [ i ]; entry ++ ; } rxbins [ entry ] = 0. ; entry ++ ; for ( int i = 0 ; i <= nbins ; i ++ ) { rxbins [ entry ] = xbins [ i ]; entry ++ ; } histo = new TH1D ( hName . data (), hTitle . data (), entry -1 , rxbins ); } //Bins for phi else { if ( strcmp ( quantityUnit , \"\" ) == 0 ) { yAxisTitleForm += \" / (%1.\" + to_string ( decimals ) + \"f)\" ; } else { yAxisTitleForm += \" / (%1.\" + to_string ( decimals ) + \"f \" + string ( quantityUnit ) + \")\" ; } histo = new TH1D ( hName . data (), hTitle . data (), nBins , xMin , xMax ); } The code that creates the histogram bins is located inside the conditionals and is commented. You can edit this code and uncomment to create histogram bins however you want. Instead of using a function to generate the bins, we can also define them manually. As we intend to compare the results between data and simulation, but also between the sideband and fitting methods, you are advised to employ the same bin choice. Change your the code to this: //Variable bin for pT if ( strcmp ( quantityName , \"Pt\" ) == 0 ) { double xbins [] = { 2. , 3.4 , 4 , 4.2 , 4.4 , 4.7 , 5.0 , 5.1 , 5.2 , 5.4 , 5.5 , 5.6 , 5.7 , 5.8 , 5.9 , 6.2 , 6.4 , 6.6 , 6.8 , 7.3 , 9.5 , 13.0 , 17.0 , 40. }; int nbins = 23 ; histo = new TH1D ( hName . data (), hTitle . data (), nbins , xbins ); } //Variable bin for eta else if ( strcmp ( quantityName , \"Eta\" ) == 0 ) { double xbins [] = { -2.0 , -1.9 , -1.8 , -1.7 , -1.6 , -1.5 , -1.4 , -1.2 , -1.0 , -0.8 , -0.6 , -0.4 , 0 , 0.2 , 0.4 , 0.6 , 0.7 , 0.95 , 1.2 , 1.4 , 1.5 , 1.6 , 2.0 }; int nbins = 22 ; histo = new TH1D ( hName . data (), hTitle . data (), nbins , xbins ); } //Bins for phi else { double xbins [] = { -3 , -2.8 , -2.6 , -2.4 , -2.2 , -2.0 , -1.8 , -1.6 , -1.4 , -1.2 , -1.0 , -0.8 , -0.6 , -0.4 , -0.2 , 0 , 0.2 , 0.4 , 0.5 , 0.6 , 1.0 , 1.2 , 1.4 , 1.6 , 1.8 , 2.0 , 2.2 , 2.4 , 2.6 , 2.8 , 3.0 }; int nbins = 30 ; histo = new TH1D ( hName . data (), hTitle . data (), nbins , xbins ); } Running the code \u00b6 After setting the configurations, it's time to run the code. Go back to the main directory and make sure macro.cpp is there. cd .. ls classes compare_efficiency.cpp config macro.cpp Run the macro.cpp: root -l -b -q macro.cpp \"../results/Upsilon Run 2011/\" directory created OK Using \"../Run2011A_MuOnia_Upsilon.root\" ntuple resonance: Upsilon Using method 2 Data analysed = 986100 of 986100 In this process, more informations will be printed in terminal while plots will be created on specified (these plots are been saved in a folder). The message below tells you that code has finished running: Done. All result files can be found at \"../results/Upsilon_Run_2011/\" Common errors If you run the code and your terminal printed some erros like: Error in <ROOT::Math::Cephes::incbi : Wrong domain for parameter b (must be 0) {: .error} This occurs when the contents of a bin of the pass histogram is greater than the corresponding bin in the total histogram. With sideband subtraction, depending on bins you choose, this can happen and will result in enormous error bars. This issue may be avoided by fine-tuning the binning choice. For now, these messages may be ignored. Probe Efficiency results for Data \u00b6 If all went well, your results are going to be like these: Preparing and running the code for simulation \u00b6 Challenge Try to run the same code on the Upsilon1SToMuMu_MC_full.root file we downloaded. Tip You will need the redo the steps above, setting: int useFile = 4 ; in main/config/settings.cpp file. Comparison between real data and simulation We'll do this in the last section of this exercise. So the challenge above is mandatory. Extra challenge If you are looking for an extra exercise, you can try to apply the same logic, changing some variables you saw, in order to get results for the J/\u03c8 nutpple. To download the J/\u03c8 real data ntupple (requires 3.3 GB): wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm= $( wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=16OqVrHIB4wn_5X8GEZ3NxnAycZ2ItemZ' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p' ) &id=16OqVrHIB4wn_5X8GEZ3NxnAycZ2ItemZ\" -O Run2011AMuOnia_mergeNtuple.root && rm -rf /tmp/cookies.txt To download the J/\u03c8 simulated data ntuple (requires 515 MB): wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm= $( wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1dKLJ5RIGrBp5aIJrvOQw5lWLQSHUgEnf' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p' ) &id=1dKLJ5RIGrBp5aIJrvOQw5lWLQSHUgEnf\" -O JPsiToMuMu_mergeMCNtuple.root && rm -rf /tmp/cookies.txt As this dataset is larger, the code will run slowly. It can take several minutes to be completed depending where the code is been running","title":"Sideband Subtraction"},{"location":"analysis/selection/idefficiencystudy/tutorial/03-sidebandsubtraction/#signal-extraction-sideband-subtraction-method","text":"The reconstruction efficiency is calculated using only signal muons . In order to measure the efficiency, we need a way to extract signal from the dataset. You've used the fitting method and now you'll meet the sideband subtraction method. This method consists in choosing sideband and signal regions in invariant mass distribution. The sideband regions (shaded in red in the figure) have background particles and the signal region (shared in green in the figure) has background and signal particles. Note The background corresponds to candidates that do not correspond to the decay of a genuine resonance; for example, the pair is formed by the tag muon associated to an uncorrelated track produced elsewhere in the collision; the corresponding invariant mass has thus a smooth continuous shape, that is extrapolated from the signal regions into the sideband region. Note We choose only the \u03d2 (1S) signal for selecting the signal region; simulation information is further available for this resonance, allowing in the end for a comparison of results, between data and simulation. For each event category (i.e. Pass and All), and for a given variable of interest (e.g., the probe pT), two distributions are obtained, one for each region (Signal and Sideband). In order to obtain the variable distribution for the signal only, we proceed by subtracting the Background distribution (Sideband region) from the Signal+Background one (Signal region): Where the normalization \u03b1 factor quantifies the quantity of background present in the signal region> And for the uncertainty: Applying those equations we get histograms like this: Solid blue line (Total) = particles in signal region; Dashed blue line (Background) = particles in sideband regions; Solid magenta line (signal) = signal histogram (background subtracted). You will see this histogram on this exercise. About this code More info about this code can be found here .","title":"Signal extraction: sideband subtraction method"},{"location":"analysis/selection/idefficiencystudy/tutorial/03-sidebandsubtraction/#preparing-files","text":"First, from the root folder of our downloades repository, we need to go sideband subtraction method tutorial: cd efficiency_tools/sideband_subtraction To copy the \u03d2 dataset from real data file to your machine (requires 441 MB), type: wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm= $( wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1Fj-rrKts8jSSMdwvOnvux68ydZcKB521' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p' ) &id=1Fj-rrKts8jSSMdwvOnvux68ydZcKB521\" -O Run2011A_MuOnia_Upsilon.root && rm -rf /tmp/cookies.txt This code downloads the file directly from Google Drive. Run this code to download the simulation ntuple for \u03d2 (requires 66 MB): wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm= $( wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1ZzAOOLCKmCz0Q6pVi3AAiYFGKEpP2efM' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p' ) &id=1ZzAOOLCKmCz0Q6pVi3AAiYFGKEpP2efM\" -O Upsilon1SToMuMu_MC_full.root && rm -rf /tmp/cookies.txt Now, check if everything is ok: ls main README.md Run2011A_MuOnia_Upsilon.root Upsilon1SToMuMu_MC_full.root Your efficiency_tagandprobe folder should have these files:","title":"Preparing files"},{"location":"analysis/selection/idefficiencystudy/tutorial/03-sidebandsubtraction/#preparing-code-for-data","text":"Note I will teach you to manage the files on the terminal, but you can use a graphical file explorer. We need to edit some settings. Open settings.cpp : cd main/config ls cuts.h settings.cpp There are different ways to open this file. You can try to run: gedit settings.cpp Or, if you can not use gedit, try nano: nano settings.cpp I do not have nano! You can try to use any text editor , but here is some commands you cant try to use to install it: Ubuntu/Debian: sudo apt-get -y install nano . RedHat/CentOS/Fedora: sudo yum install nano . Mac OS X: nano is installed by default . We want to calculate efficiencies of tracker muons . With the settings.cpp file opened, make sure to let the variables like this: //Canvas drawing bool shouldDrawInvariantMassCanvas = true ; bool shouldDrawInvariantMassCanvasRegion = true ; bool shouldDrawQuantitiesCanvas = true ; bool shouldDrawEfficiencyCanvas = true ; //Muon id analyse bool doTracker = true ; bool doStandalone = false ; bool doGlobal = false ; We want to calculate the efficiency using specific files that we downloaded. They name are Run2011A_MuOnia_Upsilon.root and Upsilon1SToMuMu_MC_full.root and are listed in const char *files[] . While settings.cpp is open, try to use the variable int useFile to run Run2011A_MuOnia_Upsilon.root . How to do this Make sure useFile is correct: //List of files const char * files [] = { \"../data_histoall.root\" , \"../Run2011AMuOnia_mergeNtuple.root\" , \"\" \"../JPsiToMuMu_mergeMCNtuple.root\" , \"../Run2011A_MuOnia_Upsilon.root\" , \"../Upsilon1SToMuMu_MC_full.root\" }; const char * directoriesToSave [] = { \"../results/result/\" , \"../results/Jpsi Run 2011/\" , \"../results/Jpsi MC 2020/\" , \"../results/Upsilon Run 2011/\" , \"../results/Upsilon MC 2020/\" }; //MAIN OPTIONS //Which file of files (variable above) should use int useFile = 3 ; It will tell which configuration the program will use. So, the macro will run with the ntuple in files[useFile] and the results will be stored in directoriesToSave[useFile] . the first three files won't be used in this execise. About code Normally we need to set the variables bool isMC and const char* resonance , but at this time it is already done and set automatically for these ntuples' names.","title":"Preparing code for Data"},{"location":"analysis/selection/idefficiencystudy/tutorial/03-sidebandsubtraction/#editting-bins","text":"The code allows to define the binning of the kinematic variable, to ensure each bin is sufficiently populated, for increased robustness. To change the binning, locate PassingFailing.h cd ../classes ls FitFunctions.h MassValues.h PtEtaPhi.h TagProbe.h InvariantMass.h PassingFailing.h SidebandSubtraction.h Type.h And then Open PassingFailing.h gedit PassingFailing.h Search for the createEfficiencyPlot(...) function. You'll find something like this: void createHistogram ( TH1D * & histo , const char * histoName ) {...} For each quantity (pT, eta, phi) we used different bins. To change the bins, look inside the createEfficiencyPlot(...) function. In a simpler version, you'll see a structure like this: //Variable bin for pT if ( strcmp ( quantityName , \"Pt\" ) == 0 ) { //Here creates histogram for pT } //Variable bin for eta else if ( strcmp ( quantityName , \"Eta\" ) == 0 ) { //Here creates histogram for eta } //Bins for phi else { //Here creates histogram for phi } See the whole scructure Don't be scared! Code doens't bite. //Variable bin for pT if ( strcmp ( quantityName , \"Pt\" ) == 0 ) { double xbins [ 10000 ]; xbins [ 0 ] = .0 ; int nbins = 0 ; double binWidth = 1. ; for ( int i = 1 ; xbins [ i -1 ] < xMax + binWidth ; i ++ ) { xbins [ i ] = xbins [ i -1 ] < 1. ? 1. : xbins [ i -1 ] * ( 1 + binWidth ); nbins ++ ; } histo = new TH1D ( hName . data (), hTitle . data (), nbins , xbins ); } //Variable bin for eta else if ( strcmp ( quantityName , \"Eta\" ) == 0 ) { double xbins [ 10000 ]; xbins [ 0 ] = .5 ; int nbins = 0 ; double binWidth = 0.2 ; //For positive for ( int i = 1 ; xbins [ i -1 ] < xMax + binWidth ; i ++ ) { xbins [ i ] = xbins [ i -1 ] < 1. ? 1. : xbins [ i -1 ] * ( 1 + binWidth ); nbins ++ ; } //Duplicate array and create another double rxbins [ nbins * 2 + 1 ]; int entry = 0 ; for ( int i = nbins ; i = 0 ; i -- ) { rxbins [ entry ] = - xbins [ i ]; entry ++ ; } rxbins [ entry ] = 0. ; entry ++ ; for ( int i = 0 ; i <= nbins ; i ++ ) { rxbins [ entry ] = xbins [ i ]; entry ++ ; } histo = new TH1D ( hName . data (), hTitle . data (), entry -1 , rxbins ); } //Bins for phi else { if ( strcmp ( quantityUnit , \"\" ) == 0 ) { yAxisTitleForm += \" / (%1.\" + to_string ( decimals ) + \"f)\" ; } else { yAxisTitleForm += \" / (%1.\" + to_string ( decimals ) + \"f \" + string ( quantityUnit ) + \")\" ; } histo = new TH1D ( hName . data (), hTitle . data (), nBins , xMin , xMax ); } The code that creates the histogram bins is located inside the conditionals and is commented. You can edit this code and uncomment to create histogram bins however you want. Instead of using a function to generate the bins, we can also define them manually. As we intend to compare the results between data and simulation, but also between the sideband and fitting methods, you are advised to employ the same bin choice. Change your the code to this: //Variable bin for pT if ( strcmp ( quantityName , \"Pt\" ) == 0 ) { double xbins [] = { 2. , 3.4 , 4 , 4.2 , 4.4 , 4.7 , 5.0 , 5.1 , 5.2 , 5.4 , 5.5 , 5.6 , 5.7 , 5.8 , 5.9 , 6.2 , 6.4 , 6.6 , 6.8 , 7.3 , 9.5 , 13.0 , 17.0 , 40. }; int nbins = 23 ; histo = new TH1D ( hName . data (), hTitle . data (), nbins , xbins ); } //Variable bin for eta else if ( strcmp ( quantityName , \"Eta\" ) == 0 ) { double xbins [] = { -2.0 , -1.9 , -1.8 , -1.7 , -1.6 , -1.5 , -1.4 , -1.2 , -1.0 , -0.8 , -0.6 , -0.4 , 0 , 0.2 , 0.4 , 0.6 , 0.7 , 0.95 , 1.2 , 1.4 , 1.5 , 1.6 , 2.0 }; int nbins = 22 ; histo = new TH1D ( hName . data (), hTitle . data (), nbins , xbins ); } //Bins for phi else { double xbins [] = { -3 , -2.8 , -2.6 , -2.4 , -2.2 , -2.0 , -1.8 , -1.6 , -1.4 , -1.2 , -1.0 , -0.8 , -0.6 , -0.4 , -0.2 , 0 , 0.2 , 0.4 , 0.5 , 0.6 , 1.0 , 1.2 , 1.4 , 1.6 , 1.8 , 2.0 , 2.2 , 2.4 , 2.6 , 2.8 , 3.0 }; int nbins = 30 ; histo = new TH1D ( hName . data (), hTitle . data (), nbins , xbins ); }","title":"Editting bins"},{"location":"analysis/selection/idefficiencystudy/tutorial/03-sidebandsubtraction/#running-the-code","text":"After setting the configurations, it's time to run the code. Go back to the main directory and make sure macro.cpp is there. cd .. ls classes compare_efficiency.cpp config macro.cpp Run the macro.cpp: root -l -b -q macro.cpp \"../results/Upsilon Run 2011/\" directory created OK Using \"../Run2011A_MuOnia_Upsilon.root\" ntuple resonance: Upsilon Using method 2 Data analysed = 986100 of 986100 In this process, more informations will be printed in terminal while plots will be created on specified (these plots are been saved in a folder). The message below tells you that code has finished running: Done. All result files can be found at \"../results/Upsilon_Run_2011/\" Common errors If you run the code and your terminal printed some erros like: Error in <ROOT::Math::Cephes::incbi : Wrong domain for parameter b (must be 0) {: .error} This occurs when the contents of a bin of the pass histogram is greater than the corresponding bin in the total histogram. With sideband subtraction, depending on bins you choose, this can happen and will result in enormous error bars. This issue may be avoided by fine-tuning the binning choice. For now, these messages may be ignored.","title":"Running the code"},{"location":"analysis/selection/idefficiencystudy/tutorial/03-sidebandsubtraction/#probe-efficiency-results-for-data","text":"If all went well, your results are going to be like these:","title":"Probe Efficiency results for Data"},{"location":"analysis/selection/idefficiencystudy/tutorial/03-sidebandsubtraction/#preparing-and-running-the-code-for-simulation","text":"Challenge Try to run the same code on the Upsilon1SToMuMu_MC_full.root file we downloaded. Tip You will need the redo the steps above, setting: int useFile = 4 ; in main/config/settings.cpp file. Comparison between real data and simulation We'll do this in the last section of this exercise. So the challenge above is mandatory. Extra challenge If you are looking for an extra exercise, you can try to apply the same logic, changing some variables you saw, in order to get results for the J/\u03c8 nutpple. To download the J/\u03c8 real data ntupple (requires 3.3 GB): wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm= $( wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=16OqVrHIB4wn_5X8GEZ3NxnAycZ2ItemZ' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p' ) &id=16OqVrHIB4wn_5X8GEZ3NxnAycZ2ItemZ\" -O Run2011AMuOnia_mergeNtuple.root && rm -rf /tmp/cookies.txt To download the J/\u03c8 simulated data ntuple (requires 515 MB): wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm= $( wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1dKLJ5RIGrBp5aIJrvOQw5lWLQSHUgEnf' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p' ) &id=1dKLJ5RIGrBp5aIJrvOQw5lWLQSHUgEnf\" -O JPsiToMuMu_mergeMCNtuple.root && rm -rf /tmp/cookies.txt As this dataset is larger, the code will run slowly. It can take several minutes to be completed depending where the code is been running","title":"Preparing and running the code for simulation"},{"location":"analysis/selection/idefficiencystudy/tutorial/04-comparison/","text":"How sideband subtraction method code stores its files \u00b6 the Sideband subtraction code saves every efficiency plot in efficiency/plots/ folder inside a single generated_hist.root file. Lets check it! You're probably on the main directory. Lets go back a directory. cd .. ls main README.md results Run2011A_MuOnia_Upsilon.root Upsilon1SToMuMu_MC_full.root A folder named results showed up on this folder. Lets go check its content. cd results ls Comparison_Upsilon_Sideband_Run_vs_MC Upsilon_MC_2020 Upsilon_Run_2011 If you did every step of the sideband subtraction on this page lesson, these results should match with the results on your pc. Access one of those folders (except comparison). cd Upsilon_Run_2011 ls Efficiency_Tracker_Probe_Eta.png Tracker_Probe_Phi_All.png Efficiency_Tracker_Probe_Phi.png Tracker_Probe_Phi_Passing.png Efficiency_Tracker_Probe_Pt.png Tracker_Probe_Pt_All.png Efficiency_Tracker_Tag_Eta.png Tracker_Probe_Pt_Passing.png Efficiency_Tracker_Tag_Phi.png Tracker_Tag_Eta_All.png Efficiency_Tracker_Tag_Pt.png Tracker_Tag_Eta_Passing.png generated_hist.root Tracker_Tag_Phi_All.png InvariantMass_Tracker.png Tracker_Tag_Phi_Passing.png InvariantMass_Tracker_region.png Tracker_Tag_Pt_All.png Tracker_Probe_Eta_All.png Tracker_Tag_Pt_Passing.png Tracker_Probe_Eta_Passing.png Here, all the output plots you saw when running the sideband subtraction method are stored as a .png . Aside from them, there's a generated_hist.root that stores the efficiency in a way that we can manipulate it after. This file is needed to run the comparison between efficiencies for the sideband subtraction method. Lets look inside of this file. Run this command to open generated_hist.root with ROOT: root -l generated_hist.root root [0] Attaching file generated_hist.root as _file0... (TFile *) 0x55dca0f04c50 root [1] Lets check its content. Type on terminal: new TBrowser You should see something like this: This is a visual navigator of a .root file. Here you can see the struture of generated_hist.root . Double click the folders to open them and see their content. The Efficiency plots we see are stored in efficiency/plots/ folder: You can double click each plot to see its content: Tip To close this window, click on terminal and press Ctrl + C . This command stops any processes happening in the terminal. Key Point As you see, the .root file has a path inside and the efficiencies plots have paths inside them as well! Comparison results between real data and simulations for sideband method \u00b6 After runinng the sideband subtraction code, we get a .root with all the efficiencies plots inside it in two different folders: ../results/Upsilon_Run_2011/generated_hist.root ../results/Upsilon_MC_2020/generated_hist.root We'll get back to this on the discussion below. Head back to the main folder. Inside of it there is a code for the efficiency plot comparison. Lets check it out. cd main ls classes compare_efficiency.cpp config macro.cpp There is it. Now lets open it. gedit compare_efficiency.cpp Its easy to prepare it for the sideband subtraction comparison. Our main editing point can be found in this part: int useScheme = 0 ; //Upsilon Sideband Run vs Upsilon Sideband MC //Upsilon Fitting Run vs Upsilon Fitting MC //Upsilon Sideband Run vs Upsilon Fitting Run //Root files and paths for Tefficiency objects inside these files const char * filePathsEff0 [][ 2 ] = { { \"../results/Upsilon_Run_2011/generated_hist.root\" , \"efficiency/plots/Muon_Pt_Tracker_Probe_Efficiency\" }, { \"../results/Upsilon_Run_2011/generated_hist.root\" , \"efficiency/plots/Muon_Eta_Tracker_Probe_Efficiency\" }, { \"../results/Upsilon_Run_2011/generated_hist.root\" , \"efficiency/plots/Muon_Phi_Tracker_Probe_Efficiency\" }, { \"../results/Upsilon_Run_2011/generated_hist.root\" , \"efficiency/plots/Muon_Pt_Standalone_Probe_Efficiency\" }, { \"../results/Upsilon_Run_2011/generated_hist.root\" , \"efficiency/plots/Muon_Eta_Standalone_Probe_Efficiency\" }, { \"../results/Upsilon_Run_2011/generated_hist.root\" , \"efficiency/plots/Muon_Phi_Standalone_Probe_Efficiency\" }, { \"../results/Upsilon_Run_2011/generated_hist.root\" , \"efficiency/plots/Muon_Pt_Global_Probe_Efficiency\" }, { \"../results/Upsilon_Run_2011/generated_hist.root\" , \"efficiency/plots/Muon_Eta_Global_Probe_Efficiency\" }, { \"../results/Upsilon_Run_2011/generated_hist.root\" , \"efficiency/plots/Muon_Phi_Global_Probe_Efficiency\" } }; //Root files and paths for Tefficiency objects inside these files const char * filePathsEff1 [][ 2 ] = { { \"../results/Upsilon_MC_2020/generated_hist.root\" , \"efficiency/plots/Muon_Pt_Tracker_Probe_Efficiency\" }, { \"../results/Upsilon_MC_2020/generated_hist.root\" , \"efficiency/plots/Muon_Eta_Tracker_Probe_Efficiency\" }, { \"../results/Upsilon_MC_2020/generated_hist.root\" , \"efficiency/plots/Muon_Phi_Tracker_Probe_Efficiency\" }, { \"../results/Upsilon_MC_2020/generated_hist.root\" , \"efficiency/plots/Muon_Pt_Standalone_Probe_Efficiency\" }, { \"../results/Upsilon_MC_2020/generated_hist.root\" , \"efficiency/plots/Muon_Eta_Standalone_Probe_Efficiency\" }, { \"../results/Upsilon_MC_2020/generated_hist.root\" , \"efficiency/plots/Muon_Phi_Standalone_Probe_Efficiency\" }, { \"../results/Upsilon_MC_2020/generated_hist.root\" , \"efficiency/plots/Muon_Pt_Global_Probe_Efficiency\" }, { \"../results/Upsilon_MC_2020/generated_hist.root\" , \"efficiency/plots/Muon_Eta_Global_Probe_Efficiency\" }, { \"../results/Upsilon_MC_2020/generated_hist.root\" , \"efficiency/plots/Muon_Phi_Global_Probe_Efficiency\" } }; //How comparisons will be saved const char * resultNames [] = { \"Muon_Pt_Tracker_Probe_Efficiency.png\" , \"Muon_Eta_Tracker_Probe_Efficiency.png\" , \"Muon_Phi_Tracker_Probe_Efficiency.png\" , \"Muon_Pt_Standalone_Probe_Efficiency.png\" , \"Muon_Eta_Standalone_Probe_Efficiency.png\" , \"Muon_Phi_Standalone_Probe_Efficiency.png\" , \"Muon_Pt_Global_Probe_Efficiency.png\" , \"Muon_Eta_Global_Probe_Efficiency.png\" , \"Muon_Phi_Global_Probe_Efficiency.png\" }; Note In the scope above we see: int useScheme represents which comparison you are doing. const char* filePathsEff0 is an array with location of the first plots. const char* filePathsEff1 is an array with location of the second plots. const char resultNames is an array with names which comparison will be saved. Plots in const char* filePathsEff0[i] will be compared with plots in const char* filePathsEff1[i] . The result will be saved as const char* resultNames[i] . Everything is uptodate to compare sideband subtraction's results between real data and simulations, except it is comparing standalone and global muons. As we are looking for tracker muons efficiencies only, you should delete lines with Standalone and Global words See result scructure If you deleted the right lines, your code now should be like this: int useScheme = 0 ; //Upsilon Sideband Run vs Upsilon Sideband MC //Upsilon Fitting Run vs Upsilon Fitting MC //Upsilon Sideband Run vs Upsilon Fitting Run //Root files and paths for Tefficiency objects inside these files const char * filePathsEff0 [][ 2 ] = { { \"../results/Upsilon_Run_2011/generated_hist.root\" , \"efficiency/plots/Muon_Pt_Tracker_Probe_Efficiency\" }, { \"../results/Upsilon_Run_2011/generated_hist.root\" , \"efficiency/plots/Muon_Eta_Tracker_Probe_Efficiency\" }, { \"../results/Upsilon_Run_2011/generated_hist.root\" , \"efficiency/plots/Muon_Phi_Tracker_Probe_Efficiency\" } }; //Root files and paths for Tefficiency objects inside these files const char * filePathsEff1 [][ 2 ] = { { \"../results/Upsilon_MC_2020/generated_hist.root\" , \"efficiency/plots/Muon_Pt_Tracker_Probe_Efficiency\" }, { \"../results/Upsilon_MC_2020/generated_hist.root\" , \"efficiency/plots/Muon_Eta_Tracker_Probe_Efficiency\" }, { \"../results/Upsilon_MC_2020/generated_hist.root\" , \"efficiency/plots/Muon_Phi_Tracker_Probe_Efficiency\" } }; //How comparisons will be saved const char * resultNames [] = { \"Muon_Pt_Tracker_Probe_Efficiency.png\" , \"Muon_Eta_Tracker_Probe_Efficiency.png\" , \"Muon_Phi_Tracker_Probe_Efficiency.png\" }; Let your variables like this. Now you need to run the code. To do this, save the file and type on your terminal: root -l compare_efficiency.cpp If everything went well, the message you'll see in terminal at end of the process is: Use Scheme: 0 Done. All result files can be found at \"../results/Comparison_Upsilon_Sideband_Run_vs_MC/\" Note The command above to run the code will display three new windows on your screen with comparison plots. You can avoid them by running straight the command below . root - l - b - q compare_efficiency . cpp In this case, to check it results you are going to need go for result folder (printed on code run) and check images there by yourself. You can try to run TBrowser again: cd [ FOLDER_PATH ] root - l new TBrowser And as output plots comparsion, you get: Now you can type the command below to quit root and close all created windows: .q How fitting method code stores its files \u00b6 To do the next part, first you need to understand how the fitting method code saves its files in a different way to the sideband subtraction method code. Lets look at how they are saved. If you look inside CMS-tutorial\\Efficiency Result folder, where is stored fitting method results, you will see another folder named trackerMuon . Inside of it you'll see: Inside of them, there are two files: If you go with your terminal to this folder and run this command, you'll see that the result files only have one plot.\\ root -l Efficiency_Run2011.root root [0] Attaching file Efficiency_Run2011.root as _file0... (TFile *) 0x55f7152a8970 root [1] Now lets look at its content. Type on terminal: new TBrowser It has only one plot, because the others are in different files. Key Point There is a .root file for each efficiency plot created with the fitting method. Comparison results between real data and simulations for fitting method \u00b6 Go back to the main folder. cd main ls classes compare_efficiency.cpp config macro.cpp Open compare_efficiency.cpp again gedit compare_efficiency.cpp This is how your code should look like now: int useScheme = 0 ; //Upsilon Sideband Run vs Upsilon Sideband MC //Upsilon Fitting Run vs Upsilon Fitting MC //Upsilon Sideband Run vs Upsilon Fitting Run //Root files and paths for Tefficiency objects inside these files const char * filePathsEff0 [][ 2 ] = { { \"../results/Upsilon_Run_2011/generated_hist.root\" , \"efficiency/plots/Muon_Pt_Tracker_Probe_Efficiency\" }, { \"../results/Upsilon_Run_2011/generated_hist.root\" , \"efficiency/plots/Muon_Eta_Tracker_Probe_Efficiency\" }, { \"../results/Upsilon_Run_2011/generated_hist.root\" , \"efficiency/plots/Muon_Phi_Tracker_Probe_Efficiency\" } }; //Root files and paths for Tefficiency objects inside these files const char * filePathsEff1 [][ 2 ] = { { \"../results/Upsilon_MC_2020/generated_hist.root\" , \"efficiency/plots/Muon_Pt_Tracker_Probe_Efficiency\" }, { \"../results/Upsilon_MC_2020/generated_hist.root\" , \"efficiency/plots/Muon_Eta_Tracker_Probe_Efficiency\" }, { \"../results/Upsilon_MC_2020/generated_hist.root\" , \"efficiency/plots/Muon_Phi_Tracker_Probe_Efficiency\" } }; //How comparisons will be saved const char * resultNames [] = { \"Muon_Pt_Tracker_Probe_Efficiency.png\" , \"Muon_Eta_Tracker_Probe_Efficiency.png\" , \"Muon_Phi_Tracker_Probe_Efficiency.png\" }; You have to do three things: Edit int useScheme value to current analysis. Change all second item of arrays in const char* filePathsEff1[] and const char* filePathsEff1[] to \"Efficiency\" , because is the path inside the .root file where all plots are stored. Change all first item of arrays in const char* filePathsEff1[] and const char* filePathsEff1[] to the location where created file is. In the end of task, your code should be something like this: int useScheme = 1 ; //Upsilon Sideband Run vs Upsilon Sideband MC //Upsilon Fitting Run vs Upsilon Fitting MC //Upsilon Sideband Run vs Upsilon Fitting Run //Root files and paths for Tefficiency objects inside these files const char * filePathsEff0 [][ 2 ] = { { \"../../CMS-tutorial/Efficiency Result/Pt/Efficiency_Run2011.root\" , \"Efficiency\" }, { \"../../CMS-tutorial/Efficiency Result/Eta/Efficiency_Run2011.root\" , \"Efficiency\" }, { \"../../CMS-tutorial/Efficiency Result/Phi/Efficiency_Run2011.root\" , \"Efficiency\" } }; //Root files and paths for Tefficiency objects inside these files const char * filePathsEff1 [][ 2 ] = { { \"../../CMS-tutorial/Efficiency Result/Pt//Efficiency_MC.root\" , \"Efficiency\" }, { \"../../CMS-tutorial/Efficiency Result/Eta//Efficiency_MC.root\" , \"Efficiency\" }, { \"../../CMS-tutorial/Efficiency Result/Phi//Efficiency_MC.root\" , \"Efficiency\" } }; //How comparisons will be saved const char * resultNames [] = { \"Muon_Pt_Tracker_Probe_Efficiency.png\" , \"Muon_Eta_Tracker_Probe_Efficiency.png\" , \"Muon_Phi_Tracker_Probe_Efficiency.png\" }; Doing this and running the program with: root -l compare_efficiency.cpp Should get you these results: Now you can type the command below to quit root and close all created windows: .q Comparison results between data from the sideband and data from the fitting method \u00b6 Challenge Using what you did before, try to mix them and plot a comparison between real data for sideband method and real data for sthe fitting method and get an analysis. Notice that: Real data = Run 2011 Simulations = Monte Carlo = MC Tip: you just need to change what you saw in this page to do this comparison. Extra challenge As you did with the last 2 extras challenges, try to redo this exercise comparing results between challenges. Extra - recreate ntuples If you are looking go far than this workshop, you can try to recreate those ntuples we used here. Try to get results from a J/\u03c8 decaying in dimuons ntuple @7 TeV. The code used to create them can be found here . Concerning the datasets used to produce these extra exercises, you can find them in these links below: Real data (2011 legacy) \u03d2 Monte Carlo simulations J/\u03c8 Monte Carlo simulations This is work in progress adapted from CMS official code to create CMS Open Data Tag and Probe ntuples.","title":"Comparison"},{"location":"analysis/selection/idefficiencystudy/tutorial/04-comparison/#how-sideband-subtraction-method-code-stores-its-files","text":"the Sideband subtraction code saves every efficiency plot in efficiency/plots/ folder inside a single generated_hist.root file. Lets check it! You're probably on the main directory. Lets go back a directory. cd .. ls main README.md results Run2011A_MuOnia_Upsilon.root Upsilon1SToMuMu_MC_full.root A folder named results showed up on this folder. Lets go check its content. cd results ls Comparison_Upsilon_Sideband_Run_vs_MC Upsilon_MC_2020 Upsilon_Run_2011 If you did every step of the sideband subtraction on this page lesson, these results should match with the results on your pc. Access one of those folders (except comparison). cd Upsilon_Run_2011 ls Efficiency_Tracker_Probe_Eta.png Tracker_Probe_Phi_All.png Efficiency_Tracker_Probe_Phi.png Tracker_Probe_Phi_Passing.png Efficiency_Tracker_Probe_Pt.png Tracker_Probe_Pt_All.png Efficiency_Tracker_Tag_Eta.png Tracker_Probe_Pt_Passing.png Efficiency_Tracker_Tag_Phi.png Tracker_Tag_Eta_All.png Efficiency_Tracker_Tag_Pt.png Tracker_Tag_Eta_Passing.png generated_hist.root Tracker_Tag_Phi_All.png InvariantMass_Tracker.png Tracker_Tag_Phi_Passing.png InvariantMass_Tracker_region.png Tracker_Tag_Pt_All.png Tracker_Probe_Eta_All.png Tracker_Tag_Pt_Passing.png Tracker_Probe_Eta_Passing.png Here, all the output plots you saw when running the sideband subtraction method are stored as a .png . Aside from them, there's a generated_hist.root that stores the efficiency in a way that we can manipulate it after. This file is needed to run the comparison between efficiencies for the sideband subtraction method. Lets look inside of this file. Run this command to open generated_hist.root with ROOT: root -l generated_hist.root root [0] Attaching file generated_hist.root as _file0... (TFile *) 0x55dca0f04c50 root [1] Lets check its content. Type on terminal: new TBrowser You should see something like this: This is a visual navigator of a .root file. Here you can see the struture of generated_hist.root . Double click the folders to open them and see their content. The Efficiency plots we see are stored in efficiency/plots/ folder: You can double click each plot to see its content: Tip To close this window, click on terminal and press Ctrl + C . This command stops any processes happening in the terminal. Key Point As you see, the .root file has a path inside and the efficiencies plots have paths inside them as well!","title":"How sideband subtraction method code stores its files"},{"location":"analysis/selection/idefficiencystudy/tutorial/04-comparison/#comparison-results-between-real-data-and-simulations-for-sideband-method","text":"After runinng the sideband subtraction code, we get a .root with all the efficiencies plots inside it in two different folders: ../results/Upsilon_Run_2011/generated_hist.root ../results/Upsilon_MC_2020/generated_hist.root We'll get back to this on the discussion below. Head back to the main folder. Inside of it there is a code for the efficiency plot comparison. Lets check it out. cd main ls classes compare_efficiency.cpp config macro.cpp There is it. Now lets open it. gedit compare_efficiency.cpp Its easy to prepare it for the sideband subtraction comparison. Our main editing point can be found in this part: int useScheme = 0 ; //Upsilon Sideband Run vs Upsilon Sideband MC //Upsilon Fitting Run vs Upsilon Fitting MC //Upsilon Sideband Run vs Upsilon Fitting Run //Root files and paths for Tefficiency objects inside these files const char * filePathsEff0 [][ 2 ] = { { \"../results/Upsilon_Run_2011/generated_hist.root\" , \"efficiency/plots/Muon_Pt_Tracker_Probe_Efficiency\" }, { \"../results/Upsilon_Run_2011/generated_hist.root\" , \"efficiency/plots/Muon_Eta_Tracker_Probe_Efficiency\" }, { \"../results/Upsilon_Run_2011/generated_hist.root\" , \"efficiency/plots/Muon_Phi_Tracker_Probe_Efficiency\" }, { \"../results/Upsilon_Run_2011/generated_hist.root\" , \"efficiency/plots/Muon_Pt_Standalone_Probe_Efficiency\" }, { \"../results/Upsilon_Run_2011/generated_hist.root\" , \"efficiency/plots/Muon_Eta_Standalone_Probe_Efficiency\" }, { \"../results/Upsilon_Run_2011/generated_hist.root\" , \"efficiency/plots/Muon_Phi_Standalone_Probe_Efficiency\" }, { \"../results/Upsilon_Run_2011/generated_hist.root\" , \"efficiency/plots/Muon_Pt_Global_Probe_Efficiency\" }, { \"../results/Upsilon_Run_2011/generated_hist.root\" , \"efficiency/plots/Muon_Eta_Global_Probe_Efficiency\" }, { \"../results/Upsilon_Run_2011/generated_hist.root\" , \"efficiency/plots/Muon_Phi_Global_Probe_Efficiency\" } }; //Root files and paths for Tefficiency objects inside these files const char * filePathsEff1 [][ 2 ] = { { \"../results/Upsilon_MC_2020/generated_hist.root\" , \"efficiency/plots/Muon_Pt_Tracker_Probe_Efficiency\" }, { \"../results/Upsilon_MC_2020/generated_hist.root\" , \"efficiency/plots/Muon_Eta_Tracker_Probe_Efficiency\" }, { \"../results/Upsilon_MC_2020/generated_hist.root\" , \"efficiency/plots/Muon_Phi_Tracker_Probe_Efficiency\" }, { \"../results/Upsilon_MC_2020/generated_hist.root\" , \"efficiency/plots/Muon_Pt_Standalone_Probe_Efficiency\" }, { \"../results/Upsilon_MC_2020/generated_hist.root\" , \"efficiency/plots/Muon_Eta_Standalone_Probe_Efficiency\" }, { \"../results/Upsilon_MC_2020/generated_hist.root\" , \"efficiency/plots/Muon_Phi_Standalone_Probe_Efficiency\" }, { \"../results/Upsilon_MC_2020/generated_hist.root\" , \"efficiency/plots/Muon_Pt_Global_Probe_Efficiency\" }, { \"../results/Upsilon_MC_2020/generated_hist.root\" , \"efficiency/plots/Muon_Eta_Global_Probe_Efficiency\" }, { \"../results/Upsilon_MC_2020/generated_hist.root\" , \"efficiency/plots/Muon_Phi_Global_Probe_Efficiency\" } }; //How comparisons will be saved const char * resultNames [] = { \"Muon_Pt_Tracker_Probe_Efficiency.png\" , \"Muon_Eta_Tracker_Probe_Efficiency.png\" , \"Muon_Phi_Tracker_Probe_Efficiency.png\" , \"Muon_Pt_Standalone_Probe_Efficiency.png\" , \"Muon_Eta_Standalone_Probe_Efficiency.png\" , \"Muon_Phi_Standalone_Probe_Efficiency.png\" , \"Muon_Pt_Global_Probe_Efficiency.png\" , \"Muon_Eta_Global_Probe_Efficiency.png\" , \"Muon_Phi_Global_Probe_Efficiency.png\" }; Note In the scope above we see: int useScheme represents which comparison you are doing. const char* filePathsEff0 is an array with location of the first plots. const char* filePathsEff1 is an array with location of the second plots. const char resultNames is an array with names which comparison will be saved. Plots in const char* filePathsEff0[i] will be compared with plots in const char* filePathsEff1[i] . The result will be saved as const char* resultNames[i] . Everything is uptodate to compare sideband subtraction's results between real data and simulations, except it is comparing standalone and global muons. As we are looking for tracker muons efficiencies only, you should delete lines with Standalone and Global words See result scructure If you deleted the right lines, your code now should be like this: int useScheme = 0 ; //Upsilon Sideband Run vs Upsilon Sideband MC //Upsilon Fitting Run vs Upsilon Fitting MC //Upsilon Sideband Run vs Upsilon Fitting Run //Root files and paths for Tefficiency objects inside these files const char * filePathsEff0 [][ 2 ] = { { \"../results/Upsilon_Run_2011/generated_hist.root\" , \"efficiency/plots/Muon_Pt_Tracker_Probe_Efficiency\" }, { \"../results/Upsilon_Run_2011/generated_hist.root\" , \"efficiency/plots/Muon_Eta_Tracker_Probe_Efficiency\" }, { \"../results/Upsilon_Run_2011/generated_hist.root\" , \"efficiency/plots/Muon_Phi_Tracker_Probe_Efficiency\" } }; //Root files and paths for Tefficiency objects inside these files const char * filePathsEff1 [][ 2 ] = { { \"../results/Upsilon_MC_2020/generated_hist.root\" , \"efficiency/plots/Muon_Pt_Tracker_Probe_Efficiency\" }, { \"../results/Upsilon_MC_2020/generated_hist.root\" , \"efficiency/plots/Muon_Eta_Tracker_Probe_Efficiency\" }, { \"../results/Upsilon_MC_2020/generated_hist.root\" , \"efficiency/plots/Muon_Phi_Tracker_Probe_Efficiency\" } }; //How comparisons will be saved const char * resultNames [] = { \"Muon_Pt_Tracker_Probe_Efficiency.png\" , \"Muon_Eta_Tracker_Probe_Efficiency.png\" , \"Muon_Phi_Tracker_Probe_Efficiency.png\" }; Let your variables like this. Now you need to run the code. To do this, save the file and type on your terminal: root -l compare_efficiency.cpp If everything went well, the message you'll see in terminal at end of the process is: Use Scheme: 0 Done. All result files can be found at \"../results/Comparison_Upsilon_Sideband_Run_vs_MC/\" Note The command above to run the code will display three new windows on your screen with comparison plots. You can avoid them by running straight the command below . root - l - b - q compare_efficiency . cpp In this case, to check it results you are going to need go for result folder (printed on code run) and check images there by yourself. You can try to run TBrowser again: cd [ FOLDER_PATH ] root - l new TBrowser And as output plots comparsion, you get: Now you can type the command below to quit root and close all created windows: .q","title":"Comparison results between real data and simulations for sideband method"},{"location":"analysis/selection/idefficiencystudy/tutorial/04-comparison/#how-fitting-method-code-stores-its-files","text":"To do the next part, first you need to understand how the fitting method code saves its files in a different way to the sideband subtraction method code. Lets look at how they are saved. If you look inside CMS-tutorial\\Efficiency Result folder, where is stored fitting method results, you will see another folder named trackerMuon . Inside of it you'll see: Inside of them, there are two files: If you go with your terminal to this folder and run this command, you'll see that the result files only have one plot.\\ root -l Efficiency_Run2011.root root [0] Attaching file Efficiency_Run2011.root as _file0... (TFile *) 0x55f7152a8970 root [1] Now lets look at its content. Type on terminal: new TBrowser It has only one plot, because the others are in different files. Key Point There is a .root file for each efficiency plot created with the fitting method.","title":"How fitting method code stores its files"},{"location":"analysis/selection/idefficiencystudy/tutorial/04-comparison/#comparison-results-between-real-data-and-simulations-for-fitting-method","text":"Go back to the main folder. cd main ls classes compare_efficiency.cpp config macro.cpp Open compare_efficiency.cpp again gedit compare_efficiency.cpp This is how your code should look like now: int useScheme = 0 ; //Upsilon Sideband Run vs Upsilon Sideband MC //Upsilon Fitting Run vs Upsilon Fitting MC //Upsilon Sideband Run vs Upsilon Fitting Run //Root files and paths for Tefficiency objects inside these files const char * filePathsEff0 [][ 2 ] = { { \"../results/Upsilon_Run_2011/generated_hist.root\" , \"efficiency/plots/Muon_Pt_Tracker_Probe_Efficiency\" }, { \"../results/Upsilon_Run_2011/generated_hist.root\" , \"efficiency/plots/Muon_Eta_Tracker_Probe_Efficiency\" }, { \"../results/Upsilon_Run_2011/generated_hist.root\" , \"efficiency/plots/Muon_Phi_Tracker_Probe_Efficiency\" } }; //Root files and paths for Tefficiency objects inside these files const char * filePathsEff1 [][ 2 ] = { { \"../results/Upsilon_MC_2020/generated_hist.root\" , \"efficiency/plots/Muon_Pt_Tracker_Probe_Efficiency\" }, { \"../results/Upsilon_MC_2020/generated_hist.root\" , \"efficiency/plots/Muon_Eta_Tracker_Probe_Efficiency\" }, { \"../results/Upsilon_MC_2020/generated_hist.root\" , \"efficiency/plots/Muon_Phi_Tracker_Probe_Efficiency\" } }; //How comparisons will be saved const char * resultNames [] = { \"Muon_Pt_Tracker_Probe_Efficiency.png\" , \"Muon_Eta_Tracker_Probe_Efficiency.png\" , \"Muon_Phi_Tracker_Probe_Efficiency.png\" }; You have to do three things: Edit int useScheme value to current analysis. Change all second item of arrays in const char* filePathsEff1[] and const char* filePathsEff1[] to \"Efficiency\" , because is the path inside the .root file where all plots are stored. Change all first item of arrays in const char* filePathsEff1[] and const char* filePathsEff1[] to the location where created file is. In the end of task, your code should be something like this: int useScheme = 1 ; //Upsilon Sideband Run vs Upsilon Sideband MC //Upsilon Fitting Run vs Upsilon Fitting MC //Upsilon Sideband Run vs Upsilon Fitting Run //Root files and paths for Tefficiency objects inside these files const char * filePathsEff0 [][ 2 ] = { { \"../../CMS-tutorial/Efficiency Result/Pt/Efficiency_Run2011.root\" , \"Efficiency\" }, { \"../../CMS-tutorial/Efficiency Result/Eta/Efficiency_Run2011.root\" , \"Efficiency\" }, { \"../../CMS-tutorial/Efficiency Result/Phi/Efficiency_Run2011.root\" , \"Efficiency\" } }; //Root files and paths for Tefficiency objects inside these files const char * filePathsEff1 [][ 2 ] = { { \"../../CMS-tutorial/Efficiency Result/Pt//Efficiency_MC.root\" , \"Efficiency\" }, { \"../../CMS-tutorial/Efficiency Result/Eta//Efficiency_MC.root\" , \"Efficiency\" }, { \"../../CMS-tutorial/Efficiency Result/Phi//Efficiency_MC.root\" , \"Efficiency\" } }; //How comparisons will be saved const char * resultNames [] = { \"Muon_Pt_Tracker_Probe_Efficiency.png\" , \"Muon_Eta_Tracker_Probe_Efficiency.png\" , \"Muon_Phi_Tracker_Probe_Efficiency.png\" }; Doing this and running the program with: root -l compare_efficiency.cpp Should get you these results: Now you can type the command below to quit root and close all created windows: .q","title":"Comparison results between real data and simulations for fitting method"},{"location":"analysis/selection/idefficiencystudy/tutorial/04-comparison/#comparison-results-between-data-from-the-sideband-and-data-from-the-fitting-method","text":"Challenge Using what you did before, try to mix them and plot a comparison between real data for sideband method and real data for sthe fitting method and get an analysis. Notice that: Real data = Run 2011 Simulations = Monte Carlo = MC Tip: you just need to change what you saw in this page to do this comparison. Extra challenge As you did with the last 2 extras challenges, try to redo this exercise comparing results between challenges. Extra - recreate ntuples If you are looking go far than this workshop, you can try to recreate those ntuples we used here. Try to get results from a J/\u03c8 decaying in dimuons ntuple @7 TeV. The code used to create them can be found here . Concerning the datasets used to produce these extra exercises, you can find them in these links below: Real data (2011 legacy) \u03d2 Monte Carlo simulations J/\u03c8 Monte Carlo simulations This is work in progress adapted from CMS official code to create CMS Open Data Tag and Probe ntuples.","title":"Comparison results between data from the sideband and data from the fitting method"},{"location":"analysis/systematics/lumiuncertain/","text":"Luminosity Uncertainty \u00b6 Warning This page is under construction","title":"Luminosity Uncertainties"},{"location":"analysis/systematics/lumiuncertain/#luminosity-uncertainty","text":"Warning This page is under construction","title":"Luminosity Uncertainty"},{"location":"analysis/systematics/mcuncertain/","text":"MC Uncertainty \u00b6 Warning This page is under construction","title":"MC Uncertainty"},{"location":"analysis/systematics/mcuncertain/#mc-uncertainty","text":"Warning This page is under construction","title":"MC Uncertainty"},{"location":"analysis/systematics/objectsuncertain/","text":"Object Uncertainty \u00b6 Warning This page is under construction","title":"Object Uncertainty"},{"location":"analysis/systematics/objectsuncertain/#object-uncertainty","text":"Warning This page is under construction","title":"Object Uncertainty"},{"location":"analysis/systematics/pileupuncertain/","text":"Pileup Uncertainty \u00b6 Warning This page is under construction","title":"Pileup Uncertainty"},{"location":"analysis/systematics/pileupuncertain/#pileup-uncertainty","text":"Warning This page is under construction","title":"Pileup Uncertainty"},{"location":"cmssw/cmsswanalyzers/","text":"Analyzers \u00b6 First, a few general words about analysis in the CMSSW framework. Physics analysis proceeds via a series of subsequent steps. Building blocks are identified and more complex objects are built on top of them. How to write a Framework Module and run the job with the cmsRun can be found here . When setting up code for the new EDM (such as creating a new EDProducer) there is a fair amount of 'boiler plate' code that you must write. To make writing such code easier CMS provides a series of scripts that will generate the necessary directory structure and files needed so that all you need to do is write your actual algorithms. CMSSW distiguishes the following module types : EDAnalyzer: takes input from the event and processes the input without writing information back to the event EDProducer: takes input from the event and produces new output which is saved in the event EDFilter: decides if processing the event can be stopped and continued EventSetup: external service not bound to the event structure which provides information useable by all modules (e.g. Geometry, Magnetic Field, etc.) In order to generate above modules: mkedanlzr : makes a skeleton of a package containing an EDAnalyzer mkedprod : makes a skeleton of a package containing an EDProducer mkedfltr : makes a skeleton of a package containing an EDFilter mkrecord : makes a complete implementation of a Record used by the EventSetup More generators are available and you can find them here Warning This page is under construction","title":"Analyzers"},{"location":"cmssw/cmsswanalyzers/#analyzers","text":"First, a few general words about analysis in the CMSSW framework. Physics analysis proceeds via a series of subsequent steps. Building blocks are identified and more complex objects are built on top of them. How to write a Framework Module and run the job with the cmsRun can be found here . When setting up code for the new EDM (such as creating a new EDProducer) there is a fair amount of 'boiler plate' code that you must write. To make writing such code easier CMS provides a series of scripts that will generate the necessary directory structure and files needed so that all you need to do is write your actual algorithms. CMSSW distiguishes the following module types : EDAnalyzer: takes input from the event and processes the input without writing information back to the event EDProducer: takes input from the event and produces new output which is saved in the event EDFilter: decides if processing the event can be stopped and continued EventSetup: external service not bound to the event structure which provides information useable by all modules (e.g. Geometry, Magnetic Field, etc.) In order to generate above modules: mkedanlzr : makes a skeleton of a package containing an EDAnalyzer mkedprod : makes a skeleton of a package containing an EDProducer mkedfltr : makes a skeleton of a package containing an EDFilter mkrecord : makes a complete implementation of a Record used by the EventSetup More generators are available and you can find them here Warning This page is under construction","title":"Analyzers"},{"location":"cmssw/cmsswconditions/","text":"Conditions \u00b6 This page explains the use of global tags and the condition database with the CMS Open Data. All information was taken from here . A Global Tag is a coherent collection of records of additional data needed by the reconstruction and analysis software. The Global Tag is defined for each data-taking period, separately for collision and simulated data. These records are stored in the condition database. Condition data include non-event-related information (Alignment, Calibration, Temperature, etc.) and parameters for the simulation/reconstruction/analysis software. For CMS Open Data, the condition data are provided as sqlite files in the /cvmfs/cms-opendata-conddb.cern.ch/ directory, which is accessible through the CMS Open Data VM. Most physics objects such as electrons , muons , photons in the CMS Open Data are already calibrated and ready-to-use, and no additional corrections are needed other than selection and identification criteria, which will be applied in the analysis code. Therefore, simple analyses do not need to access the condition database. For example you can check the Higgs analysis example . However, access to the condition database is necessary, for example, for jet energy corrections and trigger configuration information. Examples of such analyses are for the PAT object production or the top quark pair production . Note that when you need to access the condition database, the first time you run the job on the CMS Open Data VM, it will download the condition data from the /cvmfs area. It will take time (an example run of a 10 Mbps line took 45 mins), but it will only happen once as the files will be cached on your VM. The job will not produce any output during this time, but you can check the ongoing processes with the command 'top' and you can monitor the progress of reading the condition data to the local cache with the command 'df'. Collision data and Monte Carlo data sets can be found at http://opendata.cern.ch/docs/cms-guide-for-condition-database for years 2010, 2011 and 2012. Warning This page is under construction","title":"Conditions Data"},{"location":"cmssw/cmsswconditions/#conditions","text":"This page explains the use of global tags and the condition database with the CMS Open Data. All information was taken from here . A Global Tag is a coherent collection of records of additional data needed by the reconstruction and analysis software. The Global Tag is defined for each data-taking period, separately for collision and simulated data. These records are stored in the condition database. Condition data include non-event-related information (Alignment, Calibration, Temperature, etc.) and parameters for the simulation/reconstruction/analysis software. For CMS Open Data, the condition data are provided as sqlite files in the /cvmfs/cms-opendata-conddb.cern.ch/ directory, which is accessible through the CMS Open Data VM. Most physics objects such as electrons , muons , photons in the CMS Open Data are already calibrated and ready-to-use, and no additional corrections are needed other than selection and identification criteria, which will be applied in the analysis code. Therefore, simple analyses do not need to access the condition database. For example you can check the Higgs analysis example . However, access to the condition database is necessary, for example, for jet energy corrections and trigger configuration information. Examples of such analyses are for the PAT object production or the top quark pair production . Note that when you need to access the condition database, the first time you run the job on the CMS Open Data VM, it will download the condition data from the /cvmfs area. It will take time (an example run of a 10 Mbps line took 45 mins), but it will only happen once as the files will be cached on your VM. The job will not produce any output during this time, but you can check the ongoing processes with the command 'top' and you can monitor the progress of reading the condition data to the local cache with the command 'df'. Collision data and Monte Carlo data sets can be found at http://opendata.cern.ch/docs/cms-guide-for-condition-database for years 2010, 2011 and 2012. Warning This page is under construction","title":"Conditions"},{"location":"cmssw/cmsswconfigure/","text":"Configuration \u00b6 A configuration document, written using the Python language, is used to configure the cmsRun executable. A Python configuration program specifies which modules, inputs, outputs and services are to be loaded during execution, how to configure these modules and services, and in what order to execute them. All information can be found at twiki.cern.ch/twiki/bin/view/CMSPublic/SWGuideAboutPythonConfigFile .","title":"Configuration"},{"location":"cmssw/cmsswconfigure/#configuration","text":"A configuration document, written using the Python language, is used to configure the cmsRun executable. A Python configuration program specifies which modules, inputs, outputs and services are to be loaded during execution, how to configure these modules and services, and in what order to execute them. All information can be found at twiki.cern.ch/twiki/bin/view/CMSPublic/SWGuideAboutPythonConfigFile .","title":"Configuration"},{"location":"cmssw/cmsswdatamodel/","text":"Data Model \u00b6 The CMS Event Data Model (EDM) is centered around the concept of an Event . Physically, an event is the result of a single readout of the detector electronics and the signals that will (in general) have been generated by particles, tracks, energy deposits, present in a number of bunch crossings. In software terms, an Event starts as a collection of the RAW data from a detector or MC event, stored as a single entity in memory, a C++ type-safe container called edm::Event . An Event is a C++ object container for all RAW and reconstructed data related to a particular collision. During processing, data are passed from one module to the next via the Event, and are accessed only through the Event. All objects in the Event may be individually or collectively stored in ROOT files, and are thus directly browsable in ROOT. More and detailed information can be found here . The CMS Data Hierarchy \u00b6 CMS Data is arranged into a hierarchy of data tiers. Each physics event is written into each data tier, where the tiers each contain different levels of information about the event. The different tiers each have different uses. The three main data tiers written in CMS are: RAW: full event information from the Tier-0 (i.e. from CERN), containing 'raw' detector information (detector element hits, etc) RAW is not used directly for analysis RECO (\"RECOnstructed data\"): the output from first-pass processing by the Tier-0. This layer contains reconstructed physics objects, but it's still very detailed. RECO can be used for analysis, but is too big for frequent or heavy use when CMS has collected a substantial data sample. RECO Data Format Table AOD (\"Analysis Object Data\"): this is a \"distilled\" version of the RECO event information, and is expected to be used for most analyses. AOD provides a trade-off between event size and complexity of the available information to optimize flexibility and speed for analyses. AOD Data Format Table The data tiers are described in more detail in a dedicated WorkBook chapter on Data Formats and Tiers .","title":"Data Model"},{"location":"cmssw/cmsswdatamodel/#data-model","text":"The CMS Event Data Model (EDM) is centered around the concept of an Event . Physically, an event is the result of a single readout of the detector electronics and the signals that will (in general) have been generated by particles, tracks, energy deposits, present in a number of bunch crossings. In software terms, an Event starts as a collection of the RAW data from a detector or MC event, stored as a single entity in memory, a C++ type-safe container called edm::Event . An Event is a C++ object container for all RAW and reconstructed data related to a particular collision. During processing, data are passed from one module to the next via the Event, and are accessed only through the Event. All objects in the Event may be individually or collectively stored in ROOT files, and are thus directly browsable in ROOT. More and detailed information can be found here .","title":"Data Model"},{"location":"cmssw/cmsswdatamodel/#the-cms-data-hierarchy","text":"CMS Data is arranged into a hierarchy of data tiers. Each physics event is written into each data tier, where the tiers each contain different levels of information about the event. The different tiers each have different uses. The three main data tiers written in CMS are: RAW: full event information from the Tier-0 (i.e. from CERN), containing 'raw' detector information (detector element hits, etc) RAW is not used directly for analysis RECO (\"RECOnstructed data\"): the output from first-pass processing by the Tier-0. This layer contains reconstructed physics objects, but it's still very detailed. RECO can be used for analysis, but is too big for frequent or heavy use when CMS has collected a substantial data sample. RECO Data Format Table AOD (\"Analysis Object Data\"): this is a \"distilled\" version of the RECO event information, and is expected to be used for most analyses. AOD provides a trade-off between event size and complexity of the available information to optimize flexibility and speed for analyses. AOD Data Format Table The data tiers are described in more detail in a dedicated WorkBook chapter on Data Formats and Tiers .","title":"The CMS Data Hierarchy"},{"location":"cmssw/cmsswoverview/","text":"Overview \u00b6 The overall collection of software, referred to as CMS Software (CMSSW), is built around a Framework, an Event Data Model (EDM), and Services needed by the simulation, calibration and alignment, and reconstruction modules that process event data so that physicists can perform analysis. The primary goal of the Framework and EDM is to facilitate the development and deployment of reconstruction and analysis software. The CMSSW event processing model consists of one executable, called cmsRun , and many plug-in modules which are managed by the Framework. All the code needed in the event processing (calibration, reconstruction algorithms, etc.) is contained in the modules. The same executable is used for both detector and Monte Carlo data. More and detailed information can be found here .","title":"Overview"},{"location":"cmssw/cmsswoverview/#overview","text":"The overall collection of software, referred to as CMS Software (CMSSW), is built around a Framework, an Event Data Model (EDM), and Services needed by the simulation, calibration and alignment, and reconstruction modules that process event data so that physicists can perform analysis. The primary goal of the Framework and EDM is to facilitate the development and deployment of reconstruction and analysis software. The CMSSW event processing model consists of one executable, called cmsRun , and many plug-in modules which are managed by the Framework. All the code needed in the event processing (calibration, reconstruction algorithms, etc.) is contained in the modules. The same executable is used for both detector and Monte Carlo data. More and detailed information can be found here .","title":"Overview"},{"location":"tools/cernportal/","text":"The CERN Open Data Portal \u00b6 All CMS open data is available through the CERN Open Data portal . The portal hosts data from many experiments and offers search options, such as experiment, type or energy of collisions, type of data (from collisions or simulated), and many more. A brief description of the portal and those of each experiment are available from the \"About\" dropdown menu top right. The CERN Open Data portal contains the data records, environment, software and supplementary material to enable research-level use of open data. It also includes some basic documentation and topical guides. For CMS, this Open data guide complements the information available on the portal. The data records are accessed either using XRootD, which allows the data to be streamed, or through direct http download. A command-line tool cernopendata-client is also available for data download and inspection.","title":"CERN Open Data Portal"},{"location":"tools/cernportal/#the-cern-open-data-portal","text":"All CMS open data is available through the CERN Open Data portal . The portal hosts data from many experiments and offers search options, such as experiment, type or energy of collisions, type of data (from collisions or simulated), and many more. A brief description of the portal and those of each experiment are available from the \"About\" dropdown menu top right. The CERN Open Data portal contains the data records, environment, software and supplementary material to enable research-level use of open data. It also includes some basic documentation and topical guides. For CMS, this Open data guide complements the information available on the portal. The data records are accessed either using XRootD, which allows the data to be streamed, or through direct http download. A command-line tool cernopendata-client is also available for data download and inspection.","title":"The CERN Open Data Portal"},{"location":"tools/cmsopendata/","text":"CMS Open Data \u00b6 Warning This page is under construction","title":"CMS Open Data"},{"location":"tools/cmsopendata/#cms-open-data","text":"Warning This page is under construction","title":"CMS Open Data"},{"location":"tools/cmstwiki/","text":"The CMS Twiki \u00b6 Warning This page is under construction","title":"CMS Twiki"},{"location":"tools/cmstwiki/#the-cms-twiki","text":"Warning This page is under construction","title":"The CMS Twiki"},{"location":"tools/cppandpython/","text":"C++ and python \u00b6 Warning This page is under construction","title":"C++ and Python"},{"location":"tools/cppandpython/#c-and-python","text":"Warning This page is under construction","title":"C++ and python"},{"location":"tools/docker/","text":"Docker \u00b6 Warning This page is under construction Docker is a commercial implementation of a container , a way to package up a snapshot of everything needed to run some particular version of software (OS, libraries, compilers, etc.). It is a very effective way of interfacing with the CMS open data as it gives you the proper environment you need to analyze these data. To learn more about Docker in general, from a HEP perspective, you may want to check out this Introduction to Docker , from Matthew Feickert. You can also jump right in with a tutorial on running CMS analysis code using Docker .","title":"Docker"},{"location":"tools/docker/#docker","text":"Warning This page is under construction Docker is a commercial implementation of a container , a way to package up a snapshot of everything needed to run some particular version of software (OS, libraries, compilers, etc.). It is a very effective way of interfacing with the CMS open data as it gives you the proper environment you need to analyze these data. To learn more about Docker in general, from a HEP perspective, you may want to check out this Introduction to Docker , from Matthew Feickert. You can also jump right in with a tutorial on running CMS analysis code using Docker .","title":"Docker"},{"location":"tools/git/","text":"Git \u00b6 Warning This page is under construction Here are some helpful links to learn how to use git.","title":"Git"},{"location":"tools/git/#git","text":"Warning This page is under construction Here are some helpful links to learn how to use git.","title":"Git"},{"location":"tools/root/","text":"ROOT \u00b6 Warning This page is under construction From ROOT's webpage A modular scientific software toolkit. It provides all the functionalities needed to deal with big data processing, statistical analysis, visualisation and storage. It is mainly written in C++ but integrated with other languages such as Python and R. It is the primary toolkit for many experimental analysis and while you are free to analyze these datasets however you like, some familiarity with ROOT will serve you well when accessing the data. Many ROOT examples can be found here . If you don't know where to start, we would recommend Example 1 Example 2 Example 3 Python has become the language of choice for many analysts and most of the examples you'll see make use of the PyROOT module, callable from python. You can go through a number of the examples here . If you don't know where to start, we would recommend Example 1 Example 2 Example 3","title":"ROOT"},{"location":"tools/root/#root","text":"Warning This page is under construction From ROOT's webpage A modular scientific software toolkit. It provides all the functionalities needed to deal with big data processing, statistical analysis, visualisation and storage. It is mainly written in C++ but integrated with other languages such as Python and R. It is the primary toolkit for many experimental analysis and while you are free to analyze these datasets however you like, some familiarity with ROOT will serve you well when accessing the data. Many ROOT examples can be found here . If you don't know where to start, we would recommend Example 1 Example 2 Example 3 Python has become the language of choice for many analysts and most of the examples you'll see make use of the PyROOT module, callable from python. You can go through a number of the examples here . If you don't know where to start, we would recommend Example 1 Example 2 Example 3","title":"ROOT"},{"location":"tools/unix/","text":"Unix \u00b6 Warning This page is under construction Useful tips on basic unix environments","title":"UNIX"},{"location":"tools/unix/#unix","text":"Warning This page is under construction Useful tips on basic unix environments","title":"Unix"},{"location":"tools/virtualmachines/","text":"Virtual machines \u00b6 CMS open data and legacy data, even though still exciting and full of potential, are already a few years old. Because of the rapidly evolving technolgies, the computing environments that were used to analyze these data are already ancient compared to the current, bleeding edge ones. Therefore, in order to mantain our ability to study these data, we have to rely on technologies that help us preserve adequate computer environments. One way of doing this is by using virtual machines. In simple words, a virtual machine is an emulation of a computer system that can run within another system. The latter is usually known as the host . Open data releases, CMSSW versions and operating systems \u00b6 CMS open data from our 2010 release can be studied using CMSSW_4_2_8, a version of the CMSSW software that used to run under Scientific Linux CERN 5 (slc5) operating system. Likewise, open data from our 2011/2012 release used CMSSW_5_3_32 under Scientific Linux CERN 6 (slc6). The virtual machines that are used to analyze these data, therefore, need to consider all these compatibility subtleties. Virtual machine images \u00b6 In practical terms, a virtual machine image is a computer file that has all the right ingredients to create a virtual computer inside a given host. This file, however, needs to be decoded by a virtual machine interpreter, usually known as hypervisor , which runs on the host machine. One of the most famous hypervisors is Oracle's VirtualBox . CMS virtual images \u00b6 The most current images for CMS open data usage are described separately in the CERN Open Portal site for 2010 and 2011/2012 . They come equiped with the ROOT framework, CMSSW and CVMFS access. Remember When installing a CMS virtual machine (following the instructions below), always use the latest image file available for 2010 or 2011/2012 data. Installation \u00b6 Detailed instructions on how to install the CERN virtual machines can be found in the 2010 and 2011/2012 virtual machine installation guides from the CERN Open Portal. Choose the one to follow depending on the data release you will be working on. In summary, the basic steps are as follows: Download and install the latest (or even better, the latest tested) version of VirtualBox . Note that it is available for an ample range of platforms. Download the latest CMS virtual image file. Choose between 2010 or 2011/2012 , depending on the data release of interest. Once downloaded, import the image file into VirtualBox. Remember Always use the latest image file available for 2010 or 2011/2012 . Older ones are usually deprecated. Test the environment; again, 2010 or 2011/2012 , depending on the release. Finally, check for any known issues or limitations ( 2010 , 2011/2012 .)","title":"Virtual Machines"},{"location":"tools/virtualmachines/#virtual-machines","text":"CMS open data and legacy data, even though still exciting and full of potential, are already a few years old. Because of the rapidly evolving technolgies, the computing environments that were used to analyze these data are already ancient compared to the current, bleeding edge ones. Therefore, in order to mantain our ability to study these data, we have to rely on technologies that help us preserve adequate computer environments. One way of doing this is by using virtual machines. In simple words, a virtual machine is an emulation of a computer system that can run within another system. The latter is usually known as the host .","title":"Virtual machines"},{"location":"tools/virtualmachines/#open-data-releases-cmssw-versions-and-operating-systems","text":"CMS open data from our 2010 release can be studied using CMSSW_4_2_8, a version of the CMSSW software that used to run under Scientific Linux CERN 5 (slc5) operating system. Likewise, open data from our 2011/2012 release used CMSSW_5_3_32 under Scientific Linux CERN 6 (slc6). The virtual machines that are used to analyze these data, therefore, need to consider all these compatibility subtleties.","title":"Open data releases, CMSSW versions and operating systems"},{"location":"tools/virtualmachines/#virtual-machine-images","text":"In practical terms, a virtual machine image is a computer file that has all the right ingredients to create a virtual computer inside a given host. This file, however, needs to be decoded by a virtual machine interpreter, usually known as hypervisor , which runs on the host machine. One of the most famous hypervisors is Oracle's VirtualBox .","title":"Virtual machine images"},{"location":"tools/virtualmachines/#cms-virtual-images","text":"The most current images for CMS open data usage are described separately in the CERN Open Portal site for 2010 and 2011/2012 . They come equiped with the ROOT framework, CMSSW and CVMFS access. Remember When installing a CMS virtual machine (following the instructions below), always use the latest image file available for 2010 or 2011/2012 data.","title":"CMS virtual images"},{"location":"tools/virtualmachines/#installation","text":"Detailed instructions on how to install the CERN virtual machines can be found in the 2010 and 2011/2012 virtual machine installation guides from the CERN Open Portal. Choose the one to follow depending on the data release you will be working on. In summary, the basic steps are as follows: Download and install the latest (or even better, the latest tested) version of VirtualBox . Note that it is available for an ample range of platforms. Download the latest CMS virtual image file. Choose between 2010 or 2011/2012 , depending on the data release of interest. Once downloaded, import the image file into VirtualBox. Remember Always use the latest image file available for 2010 or 2011/2012 . Older ones are usually deprecated. Test the environment; again, 2010 or 2011/2012 , depending on the release. Finally, check for any known issues or limitations ( 2010 , 2011/2012 .)","title":"Installation"}]}