{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"CMS Open Data Guide \u00b6 Warning This page is under construction Welcome to the official guide for CMS open data. This page is still under construction. We appreciate your feedback and/or your help building this guide. How to use this site \u00b6 There are three main tabs to help you navigate the site. It starts with the Computing Tools most likely needed to deal with CMS open data. Then, there is a little review of CMSSW , which is the software used by CMS. Finally the Analysis section guides you through the different steps (in the most general order) that you need to follow for performing a particle physics analysis with CMS open data. The site's philosophy \u00b6 This site is thought as a navigation aid. The CMS collaboration has built an extensive amount of documentation over the years. However, given the nature of our rapidly evolving research activities, this documentation is usually scattered around, which makes it difficult to navigate. The main goal of this guide, therefore, is to facilitate the usage of CMS open/legacy data by providing a structured set of instructions that agglutinate those pieces of information already available in other sites. In this sense, we do not pretend to copy every little piece of information and/or code, but to help you get to it and find your way around it. For CMS open data the three main sources of documentation/information are: The CMS public Twiki pages . Particularly the workbook and the software guide Note When accessing the CMS twiki pages we will usually point you to the most recent page. However, historical Twiki documentation, i.e., earlier revision of the pages, may provide more accurate information for open data that is already a few years old. One can access this historical archive by going to the bottom of any Twiki page, clicking on History and exploring the revisions closer to the open data release year. The CERN CMS Open Portal pages. This portal is not exactly meant to archive documentation. It is mainly a repository for our open data. However, it does host important information that is not so easy to find. This guide will point you to the right pages. The CMSSW code . Although less conventional, exploring the CMSSW code could be a really good source of information. For instance, having hundreds of trigger bits, if the information from a specific module used in a specific trigger (with which data was taken) was needed, it would be impossible to document that explicitly in some guide. Instead, one can explore the code and easily find out the needed information. We will try to show you how it is done. How to contribute or contact us \u00b6 Please follow these instructions if you would like to contribute. If you find bugs or have suggestions or recommendations to improve this guide, please fill out an issue or contact us .","title":"Home"},{"location":"#cms-open-data-guide","text":"Warning This page is under construction Welcome to the official guide for CMS open data. This page is still under construction. We appreciate your feedback and/or your help building this guide.","title":"CMS Open Data Guide"},{"location":"#how-to-use-this-site","text":"There are three main tabs to help you navigate the site. It starts with the Computing Tools most likely needed to deal with CMS open data. Then, there is a little review of CMSSW , which is the software used by CMS. Finally the Analysis section guides you through the different steps (in the most general order) that you need to follow for performing a particle physics analysis with CMS open data.","title":"How to use this site"},{"location":"#the-sites-philosophy","text":"This site is thought as a navigation aid. The CMS collaboration has built an extensive amount of documentation over the years. However, given the nature of our rapidly evolving research activities, this documentation is usually scattered around, which makes it difficult to navigate. The main goal of this guide, therefore, is to facilitate the usage of CMS open/legacy data by providing a structured set of instructions that agglutinate those pieces of information already available in other sites. In this sense, we do not pretend to copy every little piece of information and/or code, but to help you get to it and find your way around it. For CMS open data the three main sources of documentation/information are: The CMS public Twiki pages . Particularly the workbook and the software guide Note When accessing the CMS twiki pages we will usually point you to the most recent page. However, historical Twiki documentation, i.e., earlier revision of the pages, may provide more accurate information for open data that is already a few years old. One can access this historical archive by going to the bottom of any Twiki page, clicking on History and exploring the revisions closer to the open data release year. The CERN CMS Open Portal pages. This portal is not exactly meant to archive documentation. It is mainly a repository for our open data. However, it does host important information that is not so easy to find. This guide will point you to the right pages. The CMSSW code . Although less conventional, exploring the CMSSW code could be a really good source of information. For instance, having hundreds of trigger bits, if the information from a specific module used in a specific trigger (with which data was taken) was needed, it would be impossible to document that explicitly in some guide. Instead, one can explore the code and easily find out the needed information. We will try to show you how it is done.","title":"The site's philosophy"},{"location":"#how-to-contribute-or-contact-us","text":"Please follow these instructions if you would like to contribute. If you find bugs or have suggestions or recommendations to improve this guide, please fill out an issue or contact us .","title":"How to contribute or contact us"},{"location":"about/","text":"About \u00b6 This is the offcial guide for CMS open data. All CMS instructional material is made available under the Creative Commons Attribution license . Contributors \u00b6 Matt Bellis Edgar Carrera Kati Lassila-Perini Tibor \u0160imko Marco Vidal Garc\u00eda Audrius Mecionis Allan Jales Contact \u00b6 cms-data-preservation@[Eraseme]cern.ch","title":"About"},{"location":"about/#about","text":"This is the offcial guide for CMS open data. All CMS instructional material is made available under the Creative Commons Attribution license .","title":"About"},{"location":"about/#contributors","text":"Matt Bellis Edgar Carrera Kati Lassila-Perini Tibor \u0160imko Marco Vidal Garc\u00eda Audrius Mecionis Allan Jales","title":"Contributors"},{"location":"about/#contact","text":"cms-data-preservation@[Eraseme]cern.ch","title":"Contact"},{"location":"faq/","text":"FAQ \u00b6 Warning This page is under construction Frequently Asked Questions and other problems and issues that have come up. Possible subsections below High-level questions \u00b6 Why would I choose VirtualBox over docker? Why would I choose docker over VirtualBox? \u00b6 Great question! Anyone? Docker \u00b6 Docker downloads container but never launches environment \u00b6 This is an issue with newer OSs on your local laptop/desktop running older OSs in the container. For example, suppose you are following the Running CMS analysis code using Docker tutorial. If you run docker run --name opendata -it cmsopendata/cmssw_5_3_32 /bin/bash and the container downloads but you don't find yourself in the CMSSW_5_3_32 environment, then... Data \u00b6 CMSSW \u00b6","title":"FAQ"},{"location":"faq/#faq","text":"Warning This page is under construction Frequently Asked Questions and other problems and issues that have come up. Possible subsections below","title":"FAQ"},{"location":"faq/#high-level-questions","text":"","title":"High-level questions"},{"location":"faq/#why-would-i-choose-virtualbox-over-docker-why-would-i-choose-docker-over-virtualbox","text":"Great question! Anyone?","title":"Why would I choose VirtualBox over docker? Why would I choose docker over VirtualBox?"},{"location":"faq/#docker","text":"","title":"Docker"},{"location":"faq/#docker-downloads-container-but-never-launches-environment","text":"This is an issue with newer OSs on your local laptop/desktop running older OSs in the container. For example, suppose you are following the Running CMS analysis code using Docker tutorial. If you run docker run --name opendata -it cmsopendata/cmssw_5_3_32 /bin/bash and the container downloads but you don't find yourself in the CMSSW_5_3_32 environment, then...","title":"Docker downloads container but never launches environment"},{"location":"faq/#data","text":"","title":"Data"},{"location":"faq/#cmssw","text":"","title":"CMSSW"},{"location":"analysis/backgrounds/qcdestimation/","text":"QCD Estimation \u00b6 Warning This page is under construction","title":"QCD Estimation"},{"location":"analysis/backgrounds/qcdestimation/#qcd-estimation","text":"Warning This page is under construction","title":"QCD Estimation"},{"location":"analysis/backgrounds/techniques/","text":"Techniques \u00b6 Warning This page is under construction","title":"Techniques"},{"location":"analysis/backgrounds/techniques/#techniques","text":"Warning This page is under construction","title":"Techniques"},{"location":"analysis/datasim/collisiondata/","text":"Collision Data \u00b6 Warning This page is under construction The CMS collision data is organized in primary datasets (PD). All CMS open data primary datasets can be found with this search . The dataset name consists of three parts separated by \"/\", e.g.: /TauPlusX/Run2011A-12Oct2013-v1/AOD The first part indicates the primary dataset contents ( TauPlusX ), the second part is the data-taking era ( Run2011A ) and reprocessing ( 12Oct2013 ), and the last one indicates the data format ( AOD ). Dataset contents \u00b6 The primary dataset definition is centered around physics objects (SingleMu, Jet, Tau etc). Events triggered by High Level Triggers (HLT) with a similar physics contents or use are mostly directed in the same PD. This guide gives an overview of the CMS trigger system. Besides requirements on the physics content, the organisation of the primary datasets has to satisfy constraints related to the data processing and handling, such as the average event rate approximately uniform across the different PDs, and the event rate more than 10 Hz and less than 200 Hz. (relevant?) Each CMS collision dataset comes with a brief description of the contents, and the full listing of all possible HLT trigger streams included in the dataset. The instructions how to find the exact definitions and parameters of the HLT trigger definitions can be found in Guide to the CMS Trigger System under \" HLT Trigger Path definitions \". Since a given event can pass more than one HLT path, it can be included in more than one primary dataset. There's an overall overlap between the PDs of around 25-35% during Run1 and it must be taken into account when combining events from different datasets in an analysis. Data taking and reprocessing \u00b6 One year of data taking is divided in several \"eras\" indicated as RunA, RunB, etc. According to the CMS data policy, 50% of data is published after the embargo period, completed with the full release within 10 years. Currently available are Run2010A and Run2010B Run2011A Run2012B and Run2012C The data are reprocessed several times, and it is the last complete reprocessing available at the time of the release which is made public. Data format \u00b6 The data format in use for Run1 data is Analysis Object Data (AOD). A brief description of data formats can be found in the introductory About CMS under \" Primary and simulated datasets \". Else (FIXME) \u00b6 To consider: mention json files for validated runs/LS mention condition data and GT Integrated luminosity here or in a separate chapter? Refs G. Franzoni: Dataset definition for CMS operations and physics analyses CR2014_311.pdf","title":"Collision Data"},{"location":"analysis/datasim/collisiondata/#collision-data","text":"Warning This page is under construction The CMS collision data is organized in primary datasets (PD). All CMS open data primary datasets can be found with this search . The dataset name consists of three parts separated by \"/\", e.g.: /TauPlusX/Run2011A-12Oct2013-v1/AOD The first part indicates the primary dataset contents ( TauPlusX ), the second part is the data-taking era ( Run2011A ) and reprocessing ( 12Oct2013 ), and the last one indicates the data format ( AOD ).","title":"Collision Data"},{"location":"analysis/datasim/collisiondata/#dataset-contents","text":"The primary dataset definition is centered around physics objects (SingleMu, Jet, Tau etc). Events triggered by High Level Triggers (HLT) with a similar physics contents or use are mostly directed in the same PD. This guide gives an overview of the CMS trigger system. Besides requirements on the physics content, the organisation of the primary datasets has to satisfy constraints related to the data processing and handling, such as the average event rate approximately uniform across the different PDs, and the event rate more than 10 Hz and less than 200 Hz. (relevant?) Each CMS collision dataset comes with a brief description of the contents, and the full listing of all possible HLT trigger streams included in the dataset. The instructions how to find the exact definitions and parameters of the HLT trigger definitions can be found in Guide to the CMS Trigger System under \" HLT Trigger Path definitions \". Since a given event can pass more than one HLT path, it can be included in more than one primary dataset. There's an overall overlap between the PDs of around 25-35% during Run1 and it must be taken into account when combining events from different datasets in an analysis.","title":"Dataset contents"},{"location":"analysis/datasim/collisiondata/#data-taking-and-reprocessing","text":"One year of data taking is divided in several \"eras\" indicated as RunA, RunB, etc. According to the CMS data policy, 50% of data is published after the embargo period, completed with the full release within 10 years. Currently available are Run2010A and Run2010B Run2011A Run2012B and Run2012C The data are reprocessed several times, and it is the last complete reprocessing available at the time of the release which is made public.","title":"Data taking and reprocessing"},{"location":"analysis/datasim/collisiondata/#data-format","text":"The data format in use for Run1 data is Analysis Object Data (AOD). A brief description of data formats can be found in the introductory About CMS under \" Primary and simulated datasets \".","title":"Data format"},{"location":"analysis/datasim/collisiondata/#else-fixme","text":"To consider: mention json files for validated runs/LS mention condition data and GT Integrated luminosity here or in a separate chapter? Refs G. Franzoni: Dataset definition for CMS operations and physics analyses CR2014_311.pdf","title":"Else (FIXME)"},{"location":"analysis/datasim/eventgeneration/","text":"Event Generation \u00b6 Warning This page is under construction Physical event generation and detector simulation are the first steps in producing Monte Carlo samples suitable for physical analysis. Here we will teach you how to use the CMS datasets in the CERN Open Data Portal and the CMSSW machinery for the generation of events in simple steps: Generation and Simulation: To simulate beam collisions. Triggers: To simulate the effect of the detectors and electronics. Reconstruction: For the reconstruction of the events in the collisions. What you will find here: Virtual machines Dataset name System details Configuration files cmsDriver Generation from Matrix Element (ME) generators LHE Simulation High Level Trigger (HLT) Reconstruction Generation from general-purpose generators Generation and Simulation High Level Trigger (HLT) Reconstruction Example for event generation with 2011 CMSSW machinery Example for event generation with 2012 CMSSW machinery Virtual machines \u00b6 A specific CMS virtual machine includes the ROOT framework and CMSSW. Follow these instructions to configure a CERN virtual machine on your computer to be used with the 2011 and 2012 CMS open data. Dataset name \u00b6 When exploring a simulated dataset on the CERN Open Data Portal , the first thing you will see is the name of the dataset. CMS uses the following naming convention : PROCESS_RANGETYPE-RANGELOWtoRANGEHIGH_FILTER_TUNE_COMMENT_COMENERGY-GENERATOR Take as an example the name of record 12201 : QCD_Pt-15to3000_TuneZ2star_Flat_8TeV_pythia6 System details \u00b6 In the record of each dataset, you can find the recommended global tag and release for analysis (CMSSW is the data analysis library). A global tag stores additional data that is required by the reconstruction and analysis software. Take as an example section System details of record 12201 : Recommended global tag for analysis: START53_V27 Recommended release for analysis: CMSSW_5_3_32 Configuration files \u00b6 The CMS software framework uses a software bus model, where data is stored in the event which is passed to a series of modules. A single executable, cmsRun , is used, and the modules are loaded at runtime. A configuration file defines which modules are loaded, in which order they are run, and with which configurable parameters they are run. You can find the configuration files for the generation of events for each dataset in its respective record within the CERN Open Data Portal . Check, for example, the section How were these data generated? of record 12201 . cmsDriver \u00b6 The cmsDriver is a tool to create production-solid configuration files from minimal command line options. Its code implementation, the cmsDriver.py script, is part of the CMSSW software. A summary of the cmsDriver.py script's options with a detailed message about each one can be visualized by getting the help: cmsDriver.py --help Generation from Matrix Element (ME) generators \u00b6 Generator-level datasets can be produced using a Matrix Element (ME) generator (e.g., Powheg , MadGraph5_aMCatNLO , Alpgen ) to deliver the event at the parton level and then a general-purpose generator to hadronise the event. Here we will reproduce the steps in the generation of record 1352 . Guided by the system details specified in the dataset, you should start by setting up your run time environment: cmsrel CMSSW_5_3_32 cd CMSSW_5_3_32/src/ cmsenv We will create a package according to our dataset: mkdir MyPackage cd MyPackage mkedanlzr MySim LHE \u00b6 The Les Houches Event file format ( LHE ) is an agreement between Monte Carlo event generators and theorists to define Matrix Element level event listings in a common language. The LHE input file that store process and event information can be one generated by you or you can look for examples in /eos/cms/store/lhe/ . Here we will use a file with events generated for record 1352 : cmsDriver.py step1 --filein lhe:10270 --fileout file:LHE.root --mc --eventcontent LHE --datatier GEN --conditions START53_LV6A1::All --step NONE --python_filename LHE.py --no_exec --customise Configuration/DataProcessing/Utils.addMonitoring -n 3 Run the CMSSW executable: cmsRun LHE.py Simulation \u00b6 The next step is to generate fully hadronised events. We need to use the appropriate configuration file for this purpose. Take as an example the file in Step SIM for the simulation of record 1352 . The configuration file is in this link . We add this file to our local area: curl http://uaf-10.t2.ucsd.edu/~phchang/analysis/generator/genproductions/python/SevenTeV/Hadronizer_TuneZ2_7TeV_generic_LHE_pythia_tauola_cff.py -o MySim/python/mysim.py Compile everything: scram b Execute the cmsDriver command as: cmsDriver.py MyPackage/MySim/python/mysim.py --filein file:LHE.root --fileout file:sim.root --mc --eventcontent RAWSIM --customise SimG4Core/Application/reproc2011_2012_cff.customiseG4,Configuration/DataProcessing/Utils.addMonitoring --datatier GEN-SIM --conditions START53_LV6A1::All --beamspot Realistic7TeV2011CollisionV2 --step GEN,SIM --datamix NODATAMIXER --python_filename sim.py --no_exec -n 3 Run the CMSSW executable: cmsRun sim.py High Level Trigger (HLT) \u00b6 It is a crucial part of the CMS data flow since it is the HLT algorithms and filters which will decide whether an event should be kept for an offline analysis: any offline analysis depends on the outcome of HLT. Execute the cmsDriver command as: cmsDriver.py step1 --filein file:sim.root --fileout file:hlt.root --mc --eventcontent RAWSIM --runsScenarioForMC Run2012_AB_C_D_oneRunPerEra --datatier GEN-RAW --conditions START53_LV6A1::All --step DIGI,L1,DIGI2RAW,HLT:2011 --python_filename hlt.py --no_exec --customise Configuration/DataProcessing/Utils.addMonitoring -n 3 Now, run the CMSSW executable: cmsRun hlt.py Reconstruction \u00b6 The algorithms that make up the CMS event reconstruction software build physics objects (e.g., muons, electrons, jets) from the raw data recorded by the detector. All events collected by the CMS trigger system are reconstructed by the CMS prompt reconstruction system soon after being collected. Execute the cmsDriver command as: cmsDriver.py step2 --filein file:hlt.root --fileout file:reco.root --mc --eventcontent AODSIM,DQM --datatier AODSIM,DQM --conditions START53_LV6A1::All --step RAW2DIGI,L1Reco,RECO,VALIDATION:validation_prod,DQM:DQMOfflinePOGMC --python_filename reco.py --no_exec --customise Configuration/DataProcessing/Utils.addMonitoring -n 3 Now, run the CMSSW executable: cmsRun reco.py You can start ROOT and type TBrowser t to explore the files that were created. Generation from general-purpose generators \u00b6 Generator-level datasets can be produced using a general-purpose generator (e.g., Pythia , Herwig , Tauola ) to simulate the event and the hadronisation. Here we will reproduce the steps in the generation of record 12201 . Guided by the system details specified in the dataset, you should start by setting up your run time environment: cmsrel CMSSW_5_3_32 cd CMSSW_5_3_32/src/ cmsenv We will create a package according to our dataset: mkdir MyPackage cd MyPackage mkedanlzr MyGen Generation and Simulation \u00b6 We need to use the appropriate configuration file. Take as an example the file in Step SIM for the generation and simulation of record 12201 . The configuration file is in this link . We add this file to our local area: curl https://raw.githubusercontent.com/cms-sw/genproductions/master/python/EightTeV/QCD_Pt/QCD_Pt_15to3000_TuneZ2star_Flat_8TeV_pythia6_cff.py -o MyGen/python/mygen.py Compile everything: scram b Execute the cmsDriver command as: cmsDriver.py MyPackage/MyGen/python/mygen.py --fileout file:gen.root --mc --eventcontent RAWSIM --pileup NoPileUp --customise Configuration/StandardSequences/SimWithCastor_cff.customise,Configuration/DataProcessing/Utils.addMonitoring --datatier GEN-SIM --conditions START50_V13::All --beamspot Realistic8TeVCollision --step GEN,SIM --datamix NODATAMIXER --python_filename gen.py --no_exec -n 3 Run the CMSSW executable: cmsRun gen.py High Level Trigger (HLT) \u00b6 Execute the cmsDriver command as: cmsDriver.py step1 --filein file:gen.root --fileout file:hlt.root --pileup_input dbs:/MinBias_TuneZ2star_8TeV-pythia6/Summer12-START50_V13-v3/GEN-SIM --mc --eventcontent RAWSIM --runsScenarioForMC Run2012_AB_C_D_oneRunPerEra --pileup fromDB --datatier GEN-SIM-RAW --conditions START53_V7N::All --step DIGI,L1,DIGI2RAW,HLT:7E33v2 --python_filename hlt.py --no_exec --customise Configuration/DataProcessing/Utils.addMonitoring -n 3 In section How were these data generated? of the record, you can find the pile-up dataset. Additionally, you can manually add ROOT files to the hlt.py file for the pile-up configuration by looking at the list of ROOT files that were used in the Step HLT configuration file of the record you are studying. This involves, for instance, opening file hlt.py and replacing the line process.mix.input.fileNames = cms.untracked.vstring([]) with process.mix.input.fileNames = cms.untracked.vstring([ 'root://eospublic.cern.ch//eos/opendata/cms/MonteCarlo2012/Summer12/MinBias_TuneZ2star_8TeV-pythia6/GEN-SIM/START50_V13-v3/0000/005825F1-F260-E111-BD97-003048C692DA.root', 'root://eospublic.cern.ch//eos/opendata/cms/MonteCarlo2012/Summer12/MinBias_TuneZ2star_8TeV-pythia6/GEN-SIM/START50_V13-v3/0000/003EEBD4-8061-E111-9A23-003048D437F2.root', 'root://eospublic.cern.ch//eos/opendata/cms/MonteCarlo2012/Summer12/MinBias_TuneZ2star_8TeV-pythia6/GEN-SIM/START50_V13-v3/0000/0005E496-3661-E111-B31E-003048F0E426.root']) Now, run the CMSSW executable: cmsRun hlt.py Reconstruction \u00b6 Execute the cmsDriver command as: cmsDriver.py step2 --filein file:hlt.root --fileout file:reco.root --mc --eventcontent AODSIM,DQM --datatier AODSIM,DQM --conditions START53_V7N::All --step RAW2DIGI,L1Reco,RECO,VALIDATION:validation_prod,DQM:DQMOfflinePOGMC --python_filename reco.py --no_exec --customise Configuration/DataProcessing/Utils.addMonitoring -n 3 Now, run the CMSSW executable: cmsRun reco.py You can start ROOT and type TBrowser t to explore the files that were created. Example for event generation with 2011 CMSSW machinery \u00b6 In this example , you will learn how to generate 2011 MC Drell-Yan events from scratch. A Drell-Yan process occurs when a quark and an antiquark annihilate, creating a virtual photon or Z boson, which then decays into a pair of oppositely charged leptons. Example for event generation with 2012 CMSSW machinery \u00b6 In this example , you will learn how to generate 2012 MC QCD events, which involve the strong interaction between quarks and gluons. Additionally, you will know what are the steps to extract the tracking information of these events.","title":"Event Generation"},{"location":"analysis/datasim/eventgeneration/#event-generation","text":"Warning This page is under construction Physical event generation and detector simulation are the first steps in producing Monte Carlo samples suitable for physical analysis. Here we will teach you how to use the CMS datasets in the CERN Open Data Portal and the CMSSW machinery for the generation of events in simple steps: Generation and Simulation: To simulate beam collisions. Triggers: To simulate the effect of the detectors and electronics. Reconstruction: For the reconstruction of the events in the collisions. What you will find here: Virtual machines Dataset name System details Configuration files cmsDriver Generation from Matrix Element (ME) generators LHE Simulation High Level Trigger (HLT) Reconstruction Generation from general-purpose generators Generation and Simulation High Level Trigger (HLT) Reconstruction Example for event generation with 2011 CMSSW machinery Example for event generation with 2012 CMSSW machinery","title":"Event Generation"},{"location":"analysis/datasim/eventgeneration/#virtual-machines","text":"A specific CMS virtual machine includes the ROOT framework and CMSSW. Follow these instructions to configure a CERN virtual machine on your computer to be used with the 2011 and 2012 CMS open data.","title":"Virtual machines"},{"location":"analysis/datasim/eventgeneration/#dataset-name","text":"When exploring a simulated dataset on the CERN Open Data Portal , the first thing you will see is the name of the dataset. CMS uses the following naming convention : PROCESS_RANGETYPE-RANGELOWtoRANGEHIGH_FILTER_TUNE_COMMENT_COMENERGY-GENERATOR Take as an example the name of record 12201 : QCD_Pt-15to3000_TuneZ2star_Flat_8TeV_pythia6","title":"Dataset name"},{"location":"analysis/datasim/eventgeneration/#system-details","text":"In the record of each dataset, you can find the recommended global tag and release for analysis (CMSSW is the data analysis library). A global tag stores additional data that is required by the reconstruction and analysis software. Take as an example section System details of record 12201 : Recommended global tag for analysis: START53_V27 Recommended release for analysis: CMSSW_5_3_32","title":"System details"},{"location":"analysis/datasim/eventgeneration/#configuration-files","text":"The CMS software framework uses a software bus model, where data is stored in the event which is passed to a series of modules. A single executable, cmsRun , is used, and the modules are loaded at runtime. A configuration file defines which modules are loaded, in which order they are run, and with which configurable parameters they are run. You can find the configuration files for the generation of events for each dataset in its respective record within the CERN Open Data Portal . Check, for example, the section How were these data generated? of record 12201 .","title":"Configuration files"},{"location":"analysis/datasim/eventgeneration/#cmsdriver","text":"The cmsDriver is a tool to create production-solid configuration files from minimal command line options. Its code implementation, the cmsDriver.py script, is part of the CMSSW software. A summary of the cmsDriver.py script's options with a detailed message about each one can be visualized by getting the help: cmsDriver.py --help","title":"cmsDriver"},{"location":"analysis/datasim/eventgeneration/#generation-from-matrix-element-me-generators","text":"Generator-level datasets can be produced using a Matrix Element (ME) generator (e.g., Powheg , MadGraph5_aMCatNLO , Alpgen ) to deliver the event at the parton level and then a general-purpose generator to hadronise the event. Here we will reproduce the steps in the generation of record 1352 . Guided by the system details specified in the dataset, you should start by setting up your run time environment: cmsrel CMSSW_5_3_32 cd CMSSW_5_3_32/src/ cmsenv We will create a package according to our dataset: mkdir MyPackage cd MyPackage mkedanlzr MySim","title":"Generation from Matrix Element (ME) generators"},{"location":"analysis/datasim/eventgeneration/#lhe","text":"The Les Houches Event file format ( LHE ) is an agreement between Monte Carlo event generators and theorists to define Matrix Element level event listings in a common language. The LHE input file that store process and event information can be one generated by you or you can look for examples in /eos/cms/store/lhe/ . Here we will use a file with events generated for record 1352 : cmsDriver.py step1 --filein lhe:10270 --fileout file:LHE.root --mc --eventcontent LHE --datatier GEN --conditions START53_LV6A1::All --step NONE --python_filename LHE.py --no_exec --customise Configuration/DataProcessing/Utils.addMonitoring -n 3 Run the CMSSW executable: cmsRun LHE.py","title":"LHE"},{"location":"analysis/datasim/eventgeneration/#simulation","text":"The next step is to generate fully hadronised events. We need to use the appropriate configuration file for this purpose. Take as an example the file in Step SIM for the simulation of record 1352 . The configuration file is in this link . We add this file to our local area: curl http://uaf-10.t2.ucsd.edu/~phchang/analysis/generator/genproductions/python/SevenTeV/Hadronizer_TuneZ2_7TeV_generic_LHE_pythia_tauola_cff.py -o MySim/python/mysim.py Compile everything: scram b Execute the cmsDriver command as: cmsDriver.py MyPackage/MySim/python/mysim.py --filein file:LHE.root --fileout file:sim.root --mc --eventcontent RAWSIM --customise SimG4Core/Application/reproc2011_2012_cff.customiseG4,Configuration/DataProcessing/Utils.addMonitoring --datatier GEN-SIM --conditions START53_LV6A1::All --beamspot Realistic7TeV2011CollisionV2 --step GEN,SIM --datamix NODATAMIXER --python_filename sim.py --no_exec -n 3 Run the CMSSW executable: cmsRun sim.py","title":"Simulation"},{"location":"analysis/datasim/eventgeneration/#high-level-trigger-hlt","text":"It is a crucial part of the CMS data flow since it is the HLT algorithms and filters which will decide whether an event should be kept for an offline analysis: any offline analysis depends on the outcome of HLT. Execute the cmsDriver command as: cmsDriver.py step1 --filein file:sim.root --fileout file:hlt.root --mc --eventcontent RAWSIM --runsScenarioForMC Run2012_AB_C_D_oneRunPerEra --datatier GEN-RAW --conditions START53_LV6A1::All --step DIGI,L1,DIGI2RAW,HLT:2011 --python_filename hlt.py --no_exec --customise Configuration/DataProcessing/Utils.addMonitoring -n 3 Now, run the CMSSW executable: cmsRun hlt.py","title":"High Level Trigger (HLT)"},{"location":"analysis/datasim/eventgeneration/#reconstruction","text":"The algorithms that make up the CMS event reconstruction software build physics objects (e.g., muons, electrons, jets) from the raw data recorded by the detector. All events collected by the CMS trigger system are reconstructed by the CMS prompt reconstruction system soon after being collected. Execute the cmsDriver command as: cmsDriver.py step2 --filein file:hlt.root --fileout file:reco.root --mc --eventcontent AODSIM,DQM --datatier AODSIM,DQM --conditions START53_LV6A1::All --step RAW2DIGI,L1Reco,RECO,VALIDATION:validation_prod,DQM:DQMOfflinePOGMC --python_filename reco.py --no_exec --customise Configuration/DataProcessing/Utils.addMonitoring -n 3 Now, run the CMSSW executable: cmsRun reco.py You can start ROOT and type TBrowser t to explore the files that were created.","title":"Reconstruction"},{"location":"analysis/datasim/eventgeneration/#generation-from-general-purpose-generators","text":"Generator-level datasets can be produced using a general-purpose generator (e.g., Pythia , Herwig , Tauola ) to simulate the event and the hadronisation. Here we will reproduce the steps in the generation of record 12201 . Guided by the system details specified in the dataset, you should start by setting up your run time environment: cmsrel CMSSW_5_3_32 cd CMSSW_5_3_32/src/ cmsenv We will create a package according to our dataset: mkdir MyPackage cd MyPackage mkedanlzr MyGen","title":"Generation from general-purpose generators"},{"location":"analysis/datasim/eventgeneration/#generation-and-simulation","text":"We need to use the appropriate configuration file. Take as an example the file in Step SIM for the generation and simulation of record 12201 . The configuration file is in this link . We add this file to our local area: curl https://raw.githubusercontent.com/cms-sw/genproductions/master/python/EightTeV/QCD_Pt/QCD_Pt_15to3000_TuneZ2star_Flat_8TeV_pythia6_cff.py -o MyGen/python/mygen.py Compile everything: scram b Execute the cmsDriver command as: cmsDriver.py MyPackage/MyGen/python/mygen.py --fileout file:gen.root --mc --eventcontent RAWSIM --pileup NoPileUp --customise Configuration/StandardSequences/SimWithCastor_cff.customise,Configuration/DataProcessing/Utils.addMonitoring --datatier GEN-SIM --conditions START50_V13::All --beamspot Realistic8TeVCollision --step GEN,SIM --datamix NODATAMIXER --python_filename gen.py --no_exec -n 3 Run the CMSSW executable: cmsRun gen.py","title":"Generation and Simulation"},{"location":"analysis/datasim/eventgeneration/#high-level-trigger-hlt_1","text":"Execute the cmsDriver command as: cmsDriver.py step1 --filein file:gen.root --fileout file:hlt.root --pileup_input dbs:/MinBias_TuneZ2star_8TeV-pythia6/Summer12-START50_V13-v3/GEN-SIM --mc --eventcontent RAWSIM --runsScenarioForMC Run2012_AB_C_D_oneRunPerEra --pileup fromDB --datatier GEN-SIM-RAW --conditions START53_V7N::All --step DIGI,L1,DIGI2RAW,HLT:7E33v2 --python_filename hlt.py --no_exec --customise Configuration/DataProcessing/Utils.addMonitoring -n 3 In section How were these data generated? of the record, you can find the pile-up dataset. Additionally, you can manually add ROOT files to the hlt.py file for the pile-up configuration by looking at the list of ROOT files that were used in the Step HLT configuration file of the record you are studying. This involves, for instance, opening file hlt.py and replacing the line process.mix.input.fileNames = cms.untracked.vstring([]) with process.mix.input.fileNames = cms.untracked.vstring([ 'root://eospublic.cern.ch//eos/opendata/cms/MonteCarlo2012/Summer12/MinBias_TuneZ2star_8TeV-pythia6/GEN-SIM/START50_V13-v3/0000/005825F1-F260-E111-BD97-003048C692DA.root', 'root://eospublic.cern.ch//eos/opendata/cms/MonteCarlo2012/Summer12/MinBias_TuneZ2star_8TeV-pythia6/GEN-SIM/START50_V13-v3/0000/003EEBD4-8061-E111-9A23-003048D437F2.root', 'root://eospublic.cern.ch//eos/opendata/cms/MonteCarlo2012/Summer12/MinBias_TuneZ2star_8TeV-pythia6/GEN-SIM/START50_V13-v3/0000/0005E496-3661-E111-B31E-003048F0E426.root']) Now, run the CMSSW executable: cmsRun hlt.py","title":"High Level Trigger (HLT)"},{"location":"analysis/datasim/eventgeneration/#reconstruction_1","text":"Execute the cmsDriver command as: cmsDriver.py step2 --filein file:hlt.root --fileout file:reco.root --mc --eventcontent AODSIM,DQM --datatier AODSIM,DQM --conditions START53_V7N::All --step RAW2DIGI,L1Reco,RECO,VALIDATION:validation_prod,DQM:DQMOfflinePOGMC --python_filename reco.py --no_exec --customise Configuration/DataProcessing/Utils.addMonitoring -n 3 Now, run the CMSSW executable: cmsRun reco.py You can start ROOT and type TBrowser t to explore the files that were created.","title":"Reconstruction"},{"location":"analysis/datasim/eventgeneration/#example-for-event-generation-with-2011-cmssw-machinery","text":"In this example , you will learn how to generate 2011 MC Drell-Yan events from scratch. A Drell-Yan process occurs when a quark and an antiquark annihilate, creating a virtual photon or Z boson, which then decays into a pair of oppositely charged leptons.","title":"Example for event generation with 2011 CMSSW machinery"},{"location":"analysis/datasim/eventgeneration/#example-for-event-generation-with-2012-cmssw-machinery","text":"In this example , you will learn how to generate 2012 MC QCD events, which involve the strong interaction between quarks and gluons. Additionally, you will know what are the steps to extract the tracking information of these events.","title":"Example for event generation with 2012 CMSSW machinery"},{"location":"analysis/datasim/mcsimulations/","text":"Monte Carlo Simulations \u00b6 Warning This page is under construction A set of simulated data (Monte Carlo - MC) corresponding to the collision data is made available. All directly available MC datasets can be found with this search . Furthermore, large amount of MC, thought to be of less frequent use, is available on demand and included in search results if \" include on-demand datasets \" option is selected. MC dataset are searchable by categories , which can be found under \"Filter by category\" on the left bar of the search page. The dataset name consists of three parts separated by / e.g.: /DYToMuMu_M-15To50_Tune4C_8TeV-pythia8/Summer12_DR53X-PU_S10_START53_V19-v1/AODSIM The first part indicates the simulated physics process ( DYToMuMu ), some of the production parameters ( M-15To50_Tune4C ), collision energy ( 8TeV ), and the event generator used in the processing chain. CMS simulated datasets names gives more details in the naming. The second part is the production campaign ( Summer12_DR53X ), pile-up profile ( PU_S10 ) and processing conditions ( START53_V19 ), and the last one indicates the data format ( AODSIM ). Dataset contents \u00b6 The dataset naming reflects the contents of the dataset, and the actual generator parameters with which the dataset contents have been defined can be found as explained under \" Finding the generator parameters \" in the CMS Monte Carlo production overview . Processing \u00b6 CMS Monte Carlo production overview briefly describes the steps in the MC production chain. Data format \u00b6 The data format in use for Run1 MC data is Analysis Object Data (AODSIM). A brief description of data formats can be found in the introductory About CMS under \" Primary and simulated datasets \".","title":"MC Simulations"},{"location":"analysis/datasim/mcsimulations/#monte-carlo-simulations","text":"Warning This page is under construction A set of simulated data (Monte Carlo - MC) corresponding to the collision data is made available. All directly available MC datasets can be found with this search . Furthermore, large amount of MC, thought to be of less frequent use, is available on demand and included in search results if \" include on-demand datasets \" option is selected. MC dataset are searchable by categories , which can be found under \"Filter by category\" on the left bar of the search page. The dataset name consists of three parts separated by / e.g.: /DYToMuMu_M-15To50_Tune4C_8TeV-pythia8/Summer12_DR53X-PU_S10_START53_V19-v1/AODSIM The first part indicates the simulated physics process ( DYToMuMu ), some of the production parameters ( M-15To50_Tune4C ), collision energy ( 8TeV ), and the event generator used in the processing chain. CMS simulated datasets names gives more details in the naming. The second part is the production campaign ( Summer12_DR53X ), pile-up profile ( PU_S10 ) and processing conditions ( START53_V19 ), and the last one indicates the data format ( AODSIM ).","title":"Monte Carlo Simulations"},{"location":"analysis/datasim/mcsimulations/#dataset-contents","text":"The dataset naming reflects the contents of the dataset, and the actual generator parameters with which the dataset contents have been defined can be found as explained under \" Finding the generator parameters \" in the CMS Monte Carlo production overview .","title":"Dataset contents"},{"location":"analysis/datasim/mcsimulations/#processing","text":"CMS Monte Carlo production overview briefly describes the steps in the MC production chain.","title":"Processing"},{"location":"analysis/datasim/mcsimulations/#data-format","text":"The data format in use for Run1 MC data is Analysis Object Data (AODSIM). A brief description of data formats can be found in the introductory About CMS under \" Primary and simulated datasets \".","title":"Data format"},{"location":"analysis/interpretation/limits/","text":"Upper-limit calculations \u00b6 Warning This page is under construction","title":"Upper-limit Calculations"},{"location":"analysis/interpretation/limits/#upper-limit-calculations","text":"Warning This page is under construction","title":"Upper-limit calculations"},{"location":"analysis/interpretation/stats/","text":"Statistics \u00b6 Warning This page is under construction","title":"Statistics"},{"location":"analysis/interpretation/stats/#statistics","text":"Warning This page is under construction","title":"Statistics"},{"location":"analysis/luminosity/lumi/","text":"Luminosity \u00b6 Warning This page is under construction","title":"Luminosity"},{"location":"analysis/luminosity/lumi/#luminosity","text":"Warning This page is under construction","title":"Luminosity"},{"location":"analysis/selection/objectid/","text":"Object ID \u00b6 Warning This page is under construction","title":"Physics Objects ID"},{"location":"analysis/selection/objectid/#object-id","text":"Warning This page is under construction","title":"Object ID"},{"location":"analysis/selection/objects/","text":"Physics Objects \u00b6 Warning This page is under construction Description \u00b6 The CMS is a giant detector that acts like a camera that \"photographs\" particle collisions, allowing us to interpret their nature. Certainly we cannot directly observe all the particles created in the collisions because some of them decay very quickly or simply do not interact with our detector. However, we can infer their presence. If they decay to other stable particles and interact with the apparatus, they leave signals in the CMS subdetectors. These signals are used to reconstruct the decay products or infer their presence; we call these physics objects . These objects could be electrons, muons, jets, missing energy, etc., but also lower level objects like tracks. For the current releases of open data, we store them in ROOT files following the EDM data model in AOD format. In the CERN Open Portal site one can find a more detailed description of these physical objects and a list of them corresponding to 2010 and 2011/2012 releases of open data. DataFormats \u00b6 As one can see in those guides, these physical objects are usually stored in specific collections . For instance, muons are most commonly obtained from the reco::Muon collection. The AOD Data Format Table gives a good description of the different collections (or data formats) for the AOD tier. Unfortunately, the links for the containers column got broken after CMSSW was moved to Github. Those links would have pointed us to the corresponding CMSSW C++ classes associated with those containers. This is important because one needs to know which CMSSW class matches a given collection of objects to include the headers of those classes in the header of your analyzer code. But let that not let us down. Fortunately, the names of the collections containers actually match the name of its associated CMSSW classes. These classes (data format classes) live under the DataFormats directory in CMSSW. If we browse through, we find the MuonReco package. In its interface area we find the DataFormats/MuonReco/interface/Muon.h class header, which is the one we would need to incorporate in our analyzer. This is corroborated by this Muon Analysis Twiki section . Remember When accessing a specific piece of code in the CMSSW github repository, and want to explore its methods, variables, etc., make sure you select the right git branch. E.g., CMSSW_5_3_X for 2011/2012 open data. In addition to this base class, sometimes it is necessary to invoke other auxiliary classes. For instance, DataFormats/MuonReco/interface/MuonFwd.h , which can be found in the same interface area. So, in the context of this example, in order to support muons information, at the top of your EDAnalyzer you should include the following lines: //classes to extract Muon information #include \"DataFormats/MuonReco/interface/Muon.h\" #include \"DataFormats/MuonReco/interface/MuonFwd.h\" Access methods \u00b6 In the Event methods for data access section of the Getting Data From an Event Twiki page, one can find a complete description of the different methods available for Event data access. Remember When accessing the CMS twiki pages we will usually point you to the most recent page. However, historical Twiki documentation, i.e., earlier revision of the pages, may provide more accurate information for open data that is already a few years old. One can access this historical archive by going to the bottom of any Twiki page, clicking on History and exploring the revisions closer to the open data release year. As indicated in that page, all Event data access methods use the edm::Handle<T> , where T is the C++ type of the requested object, to hold the result of an access. As an example, during Run 1, the recommended method was the getByLabel one. This method needed an InputTag . This can also be extracted from the AOD Data Format Table . The first column indicate the InputTag: Therefore, in the context of this muon example, in the analyze method of your EDAnalyzer you should include the following lines: Handle < reco :: MuonCollection > mymuons ; iEvent . getByLabel ( \"muons\" , mymuons ); If you required cosmic muons, for some reason, you would need instead: Handle < reco :: MuonCollection > mymuons ; iEvent . getByLabel ( \"muonsFromCosmics\" , mymuons ); From configuration \u00b6 Alternatively, it would be also possible to retrieve the InputTag name from configuration . In that case, in your configuration file you would need something like: process . demo = cms . EDAnalyzer ( 'MuonAnalyzer' , InputCollection = cms . InputTag ( \"muons\" ) ) In this case, you would need to declare the appropriate input tag in your EDAnalyzer class: //declare the input tag for MuonCollection edm :: InputTag muonInput ; Extract it from the ParameterSet in the constructor MuonAnalyzer :: MuonAnalyzer ( const edm :: ParameterSet & iConfig ) { //now do what ever initialization is needed muonInput = iConfig . getParameter < edm :: InputTag > ( \"InputCollection\" ); } and use in the analyze routine: Handle < reco :: MuonCollection > mymuons ; iEvent . getByLabel ( muonInput , mymuons ); Additional information for accessing CMS physics objects \u00b6 In Chapter 7 of the CMS Workbook one can find Analysis pages that provide additional information, which can be useful to check on top of the general strategy for accessing objects that was discussed above.","title":"Physics Objects"},{"location":"analysis/selection/objects/#physics-objects","text":"Warning This page is under construction","title":"Physics Objects"},{"location":"analysis/selection/objects/#description","text":"The CMS is a giant detector that acts like a camera that \"photographs\" particle collisions, allowing us to interpret their nature. Certainly we cannot directly observe all the particles created in the collisions because some of them decay very quickly or simply do not interact with our detector. However, we can infer their presence. If they decay to other stable particles and interact with the apparatus, they leave signals in the CMS subdetectors. These signals are used to reconstruct the decay products or infer their presence; we call these physics objects . These objects could be electrons, muons, jets, missing energy, etc., but also lower level objects like tracks. For the current releases of open data, we store them in ROOT files following the EDM data model in AOD format. In the CERN Open Portal site one can find a more detailed description of these physical objects and a list of them corresponding to 2010 and 2011/2012 releases of open data.","title":"Description"},{"location":"analysis/selection/objects/#dataformats","text":"As one can see in those guides, these physical objects are usually stored in specific collections . For instance, muons are most commonly obtained from the reco::Muon collection. The AOD Data Format Table gives a good description of the different collections (or data formats) for the AOD tier. Unfortunately, the links for the containers column got broken after CMSSW was moved to Github. Those links would have pointed us to the corresponding CMSSW C++ classes associated with those containers. This is important because one needs to know which CMSSW class matches a given collection of objects to include the headers of those classes in the header of your analyzer code. But let that not let us down. Fortunately, the names of the collections containers actually match the name of its associated CMSSW classes. These classes (data format classes) live under the DataFormats directory in CMSSW. If we browse through, we find the MuonReco package. In its interface area we find the DataFormats/MuonReco/interface/Muon.h class header, which is the one we would need to incorporate in our analyzer. This is corroborated by this Muon Analysis Twiki section . Remember When accessing a specific piece of code in the CMSSW github repository, and want to explore its methods, variables, etc., make sure you select the right git branch. E.g., CMSSW_5_3_X for 2011/2012 open data. In addition to this base class, sometimes it is necessary to invoke other auxiliary classes. For instance, DataFormats/MuonReco/interface/MuonFwd.h , which can be found in the same interface area. So, in the context of this example, in order to support muons information, at the top of your EDAnalyzer you should include the following lines: //classes to extract Muon information #include \"DataFormats/MuonReco/interface/Muon.h\" #include \"DataFormats/MuonReco/interface/MuonFwd.h\"","title":"DataFormats"},{"location":"analysis/selection/objects/#access-methods","text":"In the Event methods for data access section of the Getting Data From an Event Twiki page, one can find a complete description of the different methods available for Event data access. Remember When accessing the CMS twiki pages we will usually point you to the most recent page. However, historical Twiki documentation, i.e., earlier revision of the pages, may provide more accurate information for open data that is already a few years old. One can access this historical archive by going to the bottom of any Twiki page, clicking on History and exploring the revisions closer to the open data release year. As indicated in that page, all Event data access methods use the edm::Handle<T> , where T is the C++ type of the requested object, to hold the result of an access. As an example, during Run 1, the recommended method was the getByLabel one. This method needed an InputTag . This can also be extracted from the AOD Data Format Table . The first column indicate the InputTag: Therefore, in the context of this muon example, in the analyze method of your EDAnalyzer you should include the following lines: Handle < reco :: MuonCollection > mymuons ; iEvent . getByLabel ( \"muons\" , mymuons ); If you required cosmic muons, for some reason, you would need instead: Handle < reco :: MuonCollection > mymuons ; iEvent . getByLabel ( \"muonsFromCosmics\" , mymuons );","title":"Access methods"},{"location":"analysis/selection/objects/#from-configuration","text":"Alternatively, it would be also possible to retrieve the InputTag name from configuration . In that case, in your configuration file you would need something like: process . demo = cms . EDAnalyzer ( 'MuonAnalyzer' , InputCollection = cms . InputTag ( \"muons\" ) ) In this case, you would need to declare the appropriate input tag in your EDAnalyzer class: //declare the input tag for MuonCollection edm :: InputTag muonInput ; Extract it from the ParameterSet in the constructor MuonAnalyzer :: MuonAnalyzer ( const edm :: ParameterSet & iConfig ) { //now do what ever initialization is needed muonInput = iConfig . getParameter < edm :: InputTag > ( \"InputCollection\" ); } and use in the analyze routine: Handle < reco :: MuonCollection > mymuons ; iEvent . getByLabel ( muonInput , mymuons );","title":"From configuration"},{"location":"analysis/selection/objects/#additional-information-for-accessing-cms-physics-objects","text":"In Chapter 7 of the CMS Workbook one can find Analysis pages that provide additional information, which can be useful to check on top of the general strategy for accessing objects that was discussed above.","title":"Additional information for accessing CMS physics objects"},{"location":"analysis/selection/triggers/","text":"Triggers \u00b6 Warning This page is under construction","title":"Triggers"},{"location":"analysis/selection/triggers/#triggers","text":"Warning This page is under construction","title":"Triggers"},{"location":"analysis/selection/idefficiencystudy/signalextraction/","text":"Signal Extraction \u00b6 Warning This page is under construction Detector reconstruction efficiencies are calculated using signal muons, that is, only true candidates decaying to dimuons. This is achieved in this study by extracting signal from the data by the usage of some methods. Here it is presented two: sideband subtraction and fitting. Sideband subtraction method \u00b6 The sideband subtraction method involves choosing sideband and signal regions in invariant mass distribution for each tag+probe pair. The signal region is selected by finding the ressonance position and defining a region around it. While the signal region contains both signal and background, the sideband region is chosen such as to have only background, with a distance from signal region. A example of those regions selection can be seen below for the J/psi ressonance. For each event category (i.e. Pass and All), and for a given variable of interest (e.g., the probe pT), two distributions are obtained, one for each region (Signal and Sideband). In order to obtain the variable distribution for the signal only, we proceed by subtracting the Background distribution (Sideband region) from the Signal+Background one (Signal region): Where the normalization \u03b1 factor quantifies the quantity of background present in the signal region: And for the uncertainty: Applying those equations we get histograms like this: Solid blue line (Total) = particles in signal region; Dashed blue line (Background) = particles in sideband regions; Solid magenta line (signal) = signal histogram subtracted. Fitting method \u00b6 In this method, the signal is extracted not by histogram manipulation but by likelihood fitting. The procedure is applied after splitting the data in sub-samples, corresponding to bins of the kinematic variable of interest of the probe objects. As such, the efficiency will be measured as a function of that variable. Each sub-sample contains signal and background events; the signal is accessed by fitting the invariant mass spectra The fit for each bin allows to statistically discriminate between signal and background. In particular, the fit yields the number of signal events. The efficiency is finally obtained by simply forming the ratio of the signal yield from the fit to the passing category by the signal yield from the fit of the inclusive all category. This approach is illustrated below.","title":"Signal extraction"},{"location":"analysis/selection/idefficiencystudy/signalextraction/#signal-extraction","text":"Warning This page is under construction Detector reconstruction efficiencies are calculated using signal muons, that is, only true candidates decaying to dimuons. This is achieved in this study by extracting signal from the data by the usage of some methods. Here it is presented two: sideband subtraction and fitting.","title":"Signal Extraction"},{"location":"analysis/selection/idefficiencystudy/signalextraction/#sideband-subtraction-method","text":"The sideband subtraction method involves choosing sideband and signal regions in invariant mass distribution for each tag+probe pair. The signal region is selected by finding the ressonance position and defining a region around it. While the signal region contains both signal and background, the sideband region is chosen such as to have only background, with a distance from signal region. A example of those regions selection can be seen below for the J/psi ressonance. For each event category (i.e. Pass and All), and for a given variable of interest (e.g., the probe pT), two distributions are obtained, one for each region (Signal and Sideband). In order to obtain the variable distribution for the signal only, we proceed by subtracting the Background distribution (Sideband region) from the Signal+Background one (Signal region): Where the normalization \u03b1 factor quantifies the quantity of background present in the signal region: And for the uncertainty: Applying those equations we get histograms like this: Solid blue line (Total) = particles in signal region; Dashed blue line (Background) = particles in sideband regions; Solid magenta line (signal) = signal histogram subtracted.","title":"Sideband subtraction method"},{"location":"analysis/selection/idefficiencystudy/signalextraction/#fitting-method","text":"In this method, the signal is extracted not by histogram manipulation but by likelihood fitting. The procedure is applied after splitting the data in sub-samples, corresponding to bins of the kinematic variable of interest of the probe objects. As such, the efficiency will be measured as a function of that variable. Each sub-sample contains signal and background events; the signal is accessed by fitting the invariant mass spectra The fit for each bin allows to statistically discriminate between signal and background. In particular, the fit yields the number of signal events. The efficiency is finally obtained by simply forming the ratio of the signal yield from the fit to the passing category by the signal yield from the fit of the inclusive all category. This approach is illustrated below.","title":"Fitting method"},{"location":"analysis/selection/idefficiencystudy/tagandprobe/","text":"Tag and Probe \u00b6 Warning This page is under construction The Tag and Probe method is an experimental procedure commonly used in particle physics that allows to measure a process\u2019 efficiency directly from data. The procedure provides an unbiased sample of probe objects that can be then used to measure the efficiency of a particular selection criteria. Tag and Probe method \u00b6 This method is a data-driven technique and it is based on decays of known ressonances in pair of particles. The decaying muons are labeled according to the following criteria: Tag muon : well identified, triggered muon (tight selection criteria). Probe muon : unbiased set of muon candidates (very loose selection criteria), either passing or failing the criteria for which the eciency is to be measured. Tag muon are employed to trigger the presence of a resonance decay while probe muons, paired to tag muons, will be used for getting efficiency due its' unbiased characteristic. CMS Efficiency \u00b6 The efficiency will be given by the fraction of probe muons that pass a given criteria (in this case, the Muon ID which is explained below): The denominator corresponds to the number of resonance candidates (tag+probe pairs) reconstructed in the dataset. The numerator corresponds to the subset for which the probe passes the criteria. CMS Muon identification and reconstruction \u00b6 In the standard CMS reconstruction for proton-proton collisions, tracks are first reconstructed independently in the inner tracker and in the muon system. Based on these objects, three reconstruction approaches are used: Tracker Muon reconstruction: all tracker tracks with pT > 0.5 GeV/c and total momentum p > 2.5 GeV/c are considered as possible muon candidates, and are extrapolated to the muon system taking into account the magnetic field; Standalone Muon reconstruction: all tracks of the segments reconstructed in the muon chambers (performed using segments and hits from Drift Tubes in the barrel region, Cathode Strip Chambers and Resistive Plates Chambers in the endcaps) are used to generate \u201cseeds\u201d consisting of position and direction vectors and an estimate of the muon transverse momentum; Global Muon reconstruction: starts from a Standalone reconstructed muon track and extrapolates its trajectory from the innermost muon station through the coil and both calorimeters to the outer tracker surface. These are illustrated below: Note You can find more details concerning CMS Muon Identification and reconstruction in this paper JINST 7 (2012) P10002 .","title":"Tag and Probe"},{"location":"analysis/selection/idefficiencystudy/tagandprobe/#tag-and-probe","text":"Warning This page is under construction The Tag and Probe method is an experimental procedure commonly used in particle physics that allows to measure a process\u2019 efficiency directly from data. The procedure provides an unbiased sample of probe objects that can be then used to measure the efficiency of a particular selection criteria.","title":"Tag and Probe"},{"location":"analysis/selection/idefficiencystudy/tagandprobe/#tag-and-probe-method","text":"This method is a data-driven technique and it is based on decays of known ressonances in pair of particles. The decaying muons are labeled according to the following criteria: Tag muon : well identified, triggered muon (tight selection criteria). Probe muon : unbiased set of muon candidates (very loose selection criteria), either passing or failing the criteria for which the eciency is to be measured. Tag muon are employed to trigger the presence of a resonance decay while probe muons, paired to tag muons, will be used for getting efficiency due its' unbiased characteristic.","title":"Tag and Probe method"},{"location":"analysis/selection/idefficiencystudy/tagandprobe/#cms-efficiency","text":"The efficiency will be given by the fraction of probe muons that pass a given criteria (in this case, the Muon ID which is explained below): The denominator corresponds to the number of resonance candidates (tag+probe pairs) reconstructed in the dataset. The numerator corresponds to the subset for which the probe passes the criteria.","title":"CMS Efficiency"},{"location":"analysis/selection/idefficiencystudy/tagandprobe/#cms-muon-identification-and-reconstruction","text":"In the standard CMS reconstruction for proton-proton collisions, tracks are first reconstructed independently in the inner tracker and in the muon system. Based on these objects, three reconstruction approaches are used: Tracker Muon reconstruction: all tracker tracks with pT > 0.5 GeV/c and total momentum p > 2.5 GeV/c are considered as possible muon candidates, and are extrapolated to the muon system taking into account the magnetic field; Standalone Muon reconstruction: all tracks of the segments reconstructed in the muon chambers (performed using segments and hits from Drift Tubes in the barrel region, Cathode Strip Chambers and Resistive Plates Chambers in the endcaps) are used to generate \u201cseeds\u201d consisting of position and direction vectors and an estimate of the muon transverse momentum; Global Muon reconstruction: starts from a Standalone reconstructed muon track and extrapolates its trajectory from the innermost muon station through the coil and both calorimeters to the outer tracker surface. These are illustrated below: Note You can find more details concerning CMS Muon Identification and reconstruction in this paper JINST 7 (2012) P10002 .","title":"CMS Muon identification and reconstruction"},{"location":"analysis/selection/idefficiencystudy/referenceguide/FitFunctions/","text":"class FitFunctions \u00b6 This class hold all fit functions for histograms. class FitFunctions::Primary \u00b6 This class is holding primary fit functions for histograms. Content list \u00b6 double Gaus(...) double Pol1(...) double Exp(...) double CrystalBall(...) Functions details \u00b6 Gaus(...) \u00b6 static double Gaus ( double * x , double * par ) Parameters: par = [ height , position , sigma ] Pol1(...) \u00b6 static double Pol1 ( double * x , double * par ) Parameters: par = [ b , a ] Pol3(...) \u00b6 static double Pol3 ( double * x , double * par ) Parameters: par = [ d , c , b , a ] Exp(...) \u00b6 static double Exp ( double * x , double * par ) Parameters: par = [ height , width ] CrystalBall(...) \u00b6 static double CrystalBall ( double * x , double * par ) Parameters: par = [ alpha , n , mean , sigma , yield ] class FitFunctions::Merged \u00b6 This class holds merged fit functions for histograms. Content list \u00b6 double Jpsi::Signal_InvariantMass() double Jpsi::Background_InvariantMass() double Jpsi::InvariantMass() double Upsilon::Signal_InvariantMass() double Upsilon::Background_InvariantMass() double Upsilon::InvariantMass() Functions details \u00b6 Jpsi::Signal_InvariantMass(...) \u00b6 static double Signal_InvariantMass ( double * x , double * par ) Form: Gaus + CrystalBall Parameters: par = [ height , position , sigma , alpha , n , mean , sigma , yield ] Jpsi::Background_InvariantMass(...) \u00b6 static double Background_InvariantMass ( double * x , double * par ) Form: Exp Parameters: par = [ b , a ] Jpsi::InvariantMass(...) \u00b6 static double Signal_InvariantMass ( double * x , double * par ) + Background_InvariantMass ( double * x , double * par ) Form: Gaus + CrystalBall + Exp Parameters: par = [ height1 , position1 , sigma1 , alpha2 , n2 , mean2 , sigma2 , yield2 , b , a ] Upsilon::Signal_InvariantMass(...) \u00b6 static double Signal_InvariantMass ( double * x , double * par ) Form: CrystalBall + Gaus + Gaus Parameters: par = [ alpha1 , n1 , mean1 , sigma1 , yield1 , height2 , position2 , sigma2 , height3 , position3 , sigma3 ] Upsilon::Background_InvariantMass(...) \u00b6 static double Background_InvariantMass ( double * x , double * par ) Form: Pol3 Parameters: par = [ d , c , b , a ] Upsilon::InvariantMass(...) \u00b6 static double Signal_InvariantMass ( double * x , double * par ) + Background_InvariantMass ( double * x , double * par ) Form: CrystalBall + Gaus + Gaus + Pol3 Parameters: par = [ alpha1 , n1 , mean1 , sigma1 , yield1 , height2 , position2 , sigma2 , height3 , position3 , sigma3 , d , c , b , a ]","title":"FitFunction class"},{"location":"analysis/selection/idefficiencystudy/referenceguide/FitFunctions/#class-fitfunctions","text":"This class hold all fit functions for histograms.","title":"class FitFunctions"},{"location":"analysis/selection/idefficiencystudy/referenceguide/FitFunctions/#class-fitfunctionsprimary","text":"This class is holding primary fit functions for histograms.","title":"class FitFunctions::Primary"},{"location":"analysis/selection/idefficiencystudy/referenceguide/FitFunctions/#content-list","text":"double Gaus(...) double Pol1(...) double Exp(...) double CrystalBall(...)","title":"Content list"},{"location":"analysis/selection/idefficiencystudy/referenceguide/FitFunctions/#functions-details","text":"","title":"Functions details"},{"location":"analysis/selection/idefficiencystudy/referenceguide/FitFunctions/#gaus","text":"static double Gaus ( double * x , double * par ) Parameters: par = [ height , position , sigma ]","title":"Gaus(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/FitFunctions/#pol1","text":"static double Pol1 ( double * x , double * par ) Parameters: par = [ b , a ]","title":"Pol1(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/FitFunctions/#pol3","text":"static double Pol3 ( double * x , double * par ) Parameters: par = [ d , c , b , a ]","title":"Pol3(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/FitFunctions/#exp","text":"static double Exp ( double * x , double * par ) Parameters: par = [ height , width ]","title":"Exp(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/FitFunctions/#crystalball","text":"static double CrystalBall ( double * x , double * par ) Parameters: par = [ alpha , n , mean , sigma , yield ]","title":"CrystalBall(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/FitFunctions/#class-fitfunctionsmerged","text":"This class holds merged fit functions for histograms.","title":"class FitFunctions::Merged"},{"location":"analysis/selection/idefficiencystudy/referenceguide/FitFunctions/#content-list_1","text":"double Jpsi::Signal_InvariantMass() double Jpsi::Background_InvariantMass() double Jpsi::InvariantMass() double Upsilon::Signal_InvariantMass() double Upsilon::Background_InvariantMass() double Upsilon::InvariantMass()","title":"Content list"},{"location":"analysis/selection/idefficiencystudy/referenceguide/FitFunctions/#functions-details_1","text":"","title":"Functions details"},{"location":"analysis/selection/idefficiencystudy/referenceguide/FitFunctions/#jpsisignal_invariantmass","text":"static double Signal_InvariantMass ( double * x , double * par ) Form: Gaus + CrystalBall Parameters: par = [ height , position , sigma , alpha , n , mean , sigma , yield ]","title":"Jpsi::Signal_InvariantMass(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/FitFunctions/#jpsibackground_invariantmass","text":"static double Background_InvariantMass ( double * x , double * par ) Form: Exp Parameters: par = [ b , a ]","title":"Jpsi::Background_InvariantMass(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/FitFunctions/#jpsiinvariantmass","text":"static double Signal_InvariantMass ( double * x , double * par ) + Background_InvariantMass ( double * x , double * par ) Form: Gaus + CrystalBall + Exp Parameters: par = [ height1 , position1 , sigma1 , alpha2 , n2 , mean2 , sigma2 , yield2 , b , a ]","title":"Jpsi::InvariantMass(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/FitFunctions/#upsilonsignal_invariantmass","text":"static double Signal_InvariantMass ( double * x , double * par ) Form: CrystalBall + Gaus + Gaus Parameters: par = [ alpha1 , n1 , mean1 , sigma1 , yield1 , height2 , position2 , sigma2 , height3 , position3 , sigma3 ]","title":"Upsilon::Signal_InvariantMass(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/FitFunctions/#upsilonbackground_invariantmass","text":"static double Background_InvariantMass ( double * x , double * par ) Form: Pol3 Parameters: par = [ d , c , b , a ]","title":"Upsilon::Background_InvariantMass(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/FitFunctions/#upsiloninvariantmass","text":"static double Signal_InvariantMass ( double * x , double * par ) + Background_InvariantMass ( double * x , double * par ) Form: CrystalBall + Gaus + Gaus + Pol3 Parameters: par = [ alpha1 , n1 , mean1 , sigma1 , yield1 , height2 , position2 , sigma2 , height3 , position3 , sigma3 , d , c , b , a ]","title":"Upsilon::InvariantMass(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/InvariantMass/","text":"class InvariantMass \u00b6 Holds MassValues struct . Constructor details \u00b6 InvariantMass ( const char *& resonance , const char *& particleName , const char *& canvasWatermark , const char *& directoryToSave , const char *& particleType ) : resonance ( resonance ), particleName ( particleName ), canvasWatermark ( canvasWatermark ), directoryToSave ( directoryToSave ), particleType ( particleType ) { if ( strcmp ( resonance , \"Jpsi\" ) == 0 ) { xMin = 2.9 ; xMax = 3.3 ; nBins = 160 ; } if ( strcmp ( resonance , \"Upsilon\" ) == 0 ) { xMin = 8.7 ; xMax = 11. ; nBins = 60 ; } if ( strcmp ( resonance , \"Upsilon1S\" ) == 0 ) { xMin = 8.7 ; xMax = 11. ; nBins = 60 ; } createMassHistogram ( Pass . hMass , \"Passing\" ); createMassHistogram ( All . hMass , \"All\" ); } Private variable details \u00b6 Summary Type Name const char*& resonance const char*& particleName const char*& canvasWatermark const char*& directoryToSave const char*& particleType All variables here are reference for public variables in mother class: Type class Private Functions details \u00b6 createMassHistogram(...) \u00b6 void createMassHistogram ( TH1D * & hMass , const char * PassingOrFailing ) Create invariant mass histogram with a specific title. The argument hMass is a pointer where the histogram shall be stored. drawCanvasQuarter(...) \u00b6 void drawCanvasQuarter ( TCanvas * & canvas , bool drawRegions , int quarter , MassValues * ObjMassValues , int color = kBlue ) Draw a quarter of whole canvas with invariant mass histogram pointed. Public variable details \u00b6 Summary Type Name Default value double xMin 0. double xMax 0. int nBins 0 int decimals 3 Constructed objects MassValues Pass Stores information about passing mass histograms. MassValues All Stores information about passing mass histograms. Public Functions details \u00b6 createMassCanvas(...) \u00b6 TCanvas * createMassCanvas ( bool drawRegions = false , bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for invariant mass (passing and all muons). defineMassHistogramNumbers() \u00b6 void defineMassHistogramNumbers ( int nBins , double xMin , double xMax , int decimals = 3 ) Redefine number parameters of mass histograms in Mass object. doFit() \u00b6 void doFit () Apply a fit over invariant mass in MassValues objects. fillMassHistograms(...) \u00b6 void fillMassHistograms ( double ** quantities , int ** types ) Automatically fill masses histograms. Needs to be called in a loop over all dataset. updateMassValuesAll() \u00b6 void updateMassValuesAll () After fill invariant mass histogram, you need to set signal regions and sideband regions. This function will set it for you. updateMassValuesAll(...) \u00b6 void updateMassValuesFor ( MassValues * ObjMassValues , bool isAll = false ) After fill invariant mass histograms, you need to set signal regions and sideband regions. This function will set it for you. writeMassHistogramsOnFile(...) \u00b6 void writeMassHistogramsOnFile ( bool writehPass , bool writehAll ) Write all mass canvas histograms in a root file. Just need to call this function and all mass histograms will be written.","title":"InvariantMass class"},{"location":"analysis/selection/idefficiencystudy/referenceguide/InvariantMass/#class-invariantmass","text":"Holds MassValues struct .","title":"class InvariantMass"},{"location":"analysis/selection/idefficiencystudy/referenceguide/InvariantMass/#constructor-details","text":"InvariantMass ( const char *& resonance , const char *& particleName , const char *& canvasWatermark , const char *& directoryToSave , const char *& particleType ) : resonance ( resonance ), particleName ( particleName ), canvasWatermark ( canvasWatermark ), directoryToSave ( directoryToSave ), particleType ( particleType ) { if ( strcmp ( resonance , \"Jpsi\" ) == 0 ) { xMin = 2.9 ; xMax = 3.3 ; nBins = 160 ; } if ( strcmp ( resonance , \"Upsilon\" ) == 0 ) { xMin = 8.7 ; xMax = 11. ; nBins = 60 ; } if ( strcmp ( resonance , \"Upsilon1S\" ) == 0 ) { xMin = 8.7 ; xMax = 11. ; nBins = 60 ; } createMassHistogram ( Pass . hMass , \"Passing\" ); createMassHistogram ( All . hMass , \"All\" ); }","title":"Constructor details"},{"location":"analysis/selection/idefficiencystudy/referenceguide/InvariantMass/#private-variable-details","text":"Summary Type Name const char*& resonance const char*& particleName const char*& canvasWatermark const char*& directoryToSave const char*& particleType All variables here are reference for public variables in mother class: Type class","title":"Private variable details"},{"location":"analysis/selection/idefficiencystudy/referenceguide/InvariantMass/#private-functions-details","text":"","title":"Private Functions details"},{"location":"analysis/selection/idefficiencystudy/referenceguide/InvariantMass/#createmasshistogram","text":"void createMassHistogram ( TH1D * & hMass , const char * PassingOrFailing ) Create invariant mass histogram with a specific title. The argument hMass is a pointer where the histogram shall be stored.","title":"createMassHistogram(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/InvariantMass/#drawcanvasquarter","text":"void drawCanvasQuarter ( TCanvas * & canvas , bool drawRegions , int quarter , MassValues * ObjMassValues , int color = kBlue ) Draw a quarter of whole canvas with invariant mass histogram pointed.","title":"drawCanvasQuarter(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/InvariantMass/#public-variable-details","text":"Summary Type Name Default value double xMin 0. double xMax 0. int nBins 0 int decimals 3 Constructed objects MassValues Pass Stores information about passing mass histograms. MassValues All Stores information about passing mass histograms.","title":"Public variable details"},{"location":"analysis/selection/idefficiencystudy/referenceguide/InvariantMass/#public-functions-details","text":"","title":"Public Functions details"},{"location":"analysis/selection/idefficiencystudy/referenceguide/InvariantMass/#createmasscanvas","text":"TCanvas * createMassCanvas ( bool drawRegions = false , bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for invariant mass (passing and all muons).","title":"createMassCanvas(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/InvariantMass/#definemasshistogramnumbers","text":"void defineMassHistogramNumbers ( int nBins , double xMin , double xMax , int decimals = 3 ) Redefine number parameters of mass histograms in Mass object.","title":"defineMassHistogramNumbers()"},{"location":"analysis/selection/idefficiencystudy/referenceguide/InvariantMass/#dofit","text":"void doFit () Apply a fit over invariant mass in MassValues objects.","title":"doFit()"},{"location":"analysis/selection/idefficiencystudy/referenceguide/InvariantMass/#fillmasshistograms","text":"void fillMassHistograms ( double ** quantities , int ** types ) Automatically fill masses histograms. Needs to be called in a loop over all dataset.","title":"fillMassHistograms(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/InvariantMass/#updatemassvaluesall","text":"void updateMassValuesAll () After fill invariant mass histogram, you need to set signal regions and sideband regions. This function will set it for you.","title":"updateMassValuesAll()"},{"location":"analysis/selection/idefficiencystudy/referenceguide/InvariantMass/#updatemassvaluesall_1","text":"void updateMassValuesFor ( MassValues * ObjMassValues , bool isAll = false ) After fill invariant mass histograms, you need to set signal regions and sideband regions. This function will set it for you.","title":"updateMassValuesAll(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/InvariantMass/#writemasshistogramsonfile","text":"void writeMassHistogramsOnFile ( bool writehPass , bool writehAll ) Write all mass canvas histograms in a root file. Just need to call this function and all mass histograms will be written.","title":"writeMassHistogramsOnFile(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/MassValues/","text":"struct MassValues \u00b6 Holds informations about passing or all particles fit. Public variable details \u00b6 Summary Type Name Default value TH1D* hMass NULL TF1* fitFunction NULL TF1* fitSignal NULL TF1* fitBackground NULL double sidebandRegion1_x1 0. double sidebandRegion1_x2 0. double signalRegion_x1 0. double signalRegion_x2 0. double sidebandRegion2_x1 0. double sidebandRegion2_x2 0. TFitResultPtr fitResult 0 Public Functions details \u00b6 createTBox(...) \u00b6 TBox * createTBox ( double Ymax , int index = 0 , double Ymin = 0. ) Return TBox of sideband or signal region. if index = -1 return TBox representing left sideband region. if index = 0 return TBox representing signal region. if index = 1 return TBox representing right sideband region. doFitJpsi() \u00b6 void doFitJpsi () Do fit for J/psi resonance. doFitUpsilon() \u00b6 void doFitUpsilon () Do fit for Upsilon resonance with 3 resonances peaks (1S, 2S, 3S). doFitUpsilon1S() \u00b6 void doFitUpsilon1S () Do fit for Upsilon (1S) resonance. isInSidebandRegion(...) \u00b6 bool isInSidebandRegion ( double InvariantMass ) Check if InvariantMass is in sideband region. isInSignalRegion(...) \u00b6 bool isInSignalRegion ( double InvariantMass ) Check if InvariantMass is in signal region. subtractionFactor() \u00b6 double subtractionFactor () Get the subtraction factor calculated by the ratio between yield of background particles in signal region by yield of background particles in sideband region. This yield is get by the integral of function stored in fitBackground variable.","title":"MassValues struct"},{"location":"analysis/selection/idefficiencystudy/referenceguide/MassValues/#struct-massvalues","text":"Holds informations about passing or all particles fit.","title":"struct MassValues"},{"location":"analysis/selection/idefficiencystudy/referenceguide/MassValues/#public-variable-details","text":"Summary Type Name Default value TH1D* hMass NULL TF1* fitFunction NULL TF1* fitSignal NULL TF1* fitBackground NULL double sidebandRegion1_x1 0. double sidebandRegion1_x2 0. double signalRegion_x1 0. double signalRegion_x2 0. double sidebandRegion2_x1 0. double sidebandRegion2_x2 0. TFitResultPtr fitResult 0","title":"Public variable details"},{"location":"analysis/selection/idefficiencystudy/referenceguide/MassValues/#public-functions-details","text":"","title":"Public Functions details"},{"location":"analysis/selection/idefficiencystudy/referenceguide/MassValues/#createtbox","text":"TBox * createTBox ( double Ymax , int index = 0 , double Ymin = 0. ) Return TBox of sideband or signal region. if index = -1 return TBox representing left sideband region. if index = 0 return TBox representing signal region. if index = 1 return TBox representing right sideband region.","title":"createTBox(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/MassValues/#dofitjpsi","text":"void doFitJpsi () Do fit for J/psi resonance.","title":"doFitJpsi()"},{"location":"analysis/selection/idefficiencystudy/referenceguide/MassValues/#dofitupsilon","text":"void doFitUpsilon () Do fit for Upsilon resonance with 3 resonances peaks (1S, 2S, 3S).","title":"doFitUpsilon()"},{"location":"analysis/selection/idefficiencystudy/referenceguide/MassValues/#dofitupsilon1s","text":"void doFitUpsilon1S () Do fit for Upsilon (1S) resonance.","title":"doFitUpsilon1S()"},{"location":"analysis/selection/idefficiencystudy/referenceguide/MassValues/#isinsidebandregion","text":"bool isInSidebandRegion ( double InvariantMass ) Check if InvariantMass is in sideband region.","title":"isInSidebandRegion(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/MassValues/#isinsignalregion","text":"bool isInSignalRegion ( double InvariantMass ) Check if InvariantMass is in signal region.","title":"isInSignalRegion(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/MassValues/#subtractionfactor","text":"double subtractionFactor () Get the subtraction factor calculated by the ratio between yield of background particles in signal region by yield of background particles in sideband region. This yield is get by the integral of function stored in fitBackground variable.","title":"subtractionFactor()"},{"location":"analysis/selection/idefficiencystudy/referenceguide/PassingFailing/","text":"class PassingFailing \u00b6 Holds histograms of passing and all particle quantities. Constructor details \u00b6 PassingFailing ( const char *& resonance , const char *& particleName , const char *& canvasWatermark , const char *& directoryToSave , const char *& particleType , InvariantMass & ObjMass , const char *& tagOrProbe , const char * passingOrFailing , const char *& quantityName , const char *& xAxisName , const char *& quantityUnit , const char *& extendedQuantityName , double & xMin , double & xMax , int & nBins , int & decimals ) : resonance ( resonance ), particleName ( particleName ), canvasWatermark ( canvasWatermark ), directoryToSave ( directoryToSave ), particleType ( particleType ), ObjMass ( ObjMass ), tagOrProbe ( tagOrProbe ), passingOrFailing ( passingOrFailing ), quantityName ( quantityName ), xAxisName ( xAxisName ), quantityUnit ( quantityUnit ), extendedQuantityName ( extendedQuantityName ), nBins ( nBins ), xMin ( xMin ), xMax ( xMax ), decimals ( decimals ) { createHistogram ( hSigBack , \"SigBack\" ); createHistogram ( hSig , \"Sig\" ); createHistogram ( hBack , \"Back\" ); } Private variable details \u00b6 Summary Type Name const char*& resonance const char*& particleName const char*& canvasWatermark const char*& directoryToSave const char*& particleType const char*& tagOrProbe InvariantMass& ObjMass const char*& tagOrProbe const char*& xAxisName const char*& quantityUnit const char*& extendedQuantityName double& xMin double& xMax int& nBins int& decimals All variables here are reference for public variables in mother class: PtEtaPhi class . Private Functions details \u00b6 createHistogram() \u00b6 void createHistogram () Create quantity histogram. fillAfter() \u00b6 string fillAfter ( string text , char fillWith , int targetLength ) Fill blank space of a string. It is used in consistencyDebugCout(). Public variable details \u00b6 Summary Type Name Default value const char* passingOrFailing NULL TH1D* hSigBack NULL TH1D* hSig NULL TH1D* hBack NULL Details const char* passingOrFailing Set if it is \"Passing\" or \"All\" object. TH1D* hSigBack Stores the histogram for particles in signal region. TH1D* hSig Stores the subtracted histogram. TH1D* hBack Stores the histogram for particles in sideband region. Public Functions details \u00b6 consistencyDebugCout() \u00b6 void consistencyDebugCout () Print on terminal the consistency check after subtractSigHistogram(). It is result for this equation: N total - (alpha * N background + N signal ) Where: alpha = yield of background particles signal region / yield of background particles sideband region createQuantitiesCanvas(...) \u00b6 TCanvas * createQuantitiesCanvas ( bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all quantities after subtractSigHistograms(). fillQuantitiesHistograms(...) \u00b6 void fillQuantitiesHistograms ( double & InvariantMass , int & isPassing ) Automatically fill all quantities histograms. Needs to be called in a loop over all dataset. normalizeHistograms() \u00b6 void normalizeHistograms () Normalize quantities histograms of variable bin after filling it. PassFailObj() \u00b6 MassValues * PassFailObj () Get the MassValue object of corresponding MassValue object. subtractSigHistogram() \u00b6 void subtractSigHistogram () Apply sideband subtraction over histograms. writeQuantitiesHistogramsOnFile(...) \u00b6 void writeQuantitiesHistogramsOnFile ( bool hSigBack , bool hSig , bool hBack ) Write quantity histograms in a root file. Just need to call this function and all quantities histograms will be written. It needs to be called after subtractSigHistograms().","title":"PassingFailing class"},{"location":"analysis/selection/idefficiencystudy/referenceguide/PassingFailing/#class-passingfailing","text":"Holds histograms of passing and all particle quantities.","title":"class PassingFailing"},{"location":"analysis/selection/idefficiencystudy/referenceguide/PassingFailing/#constructor-details","text":"PassingFailing ( const char *& resonance , const char *& particleName , const char *& canvasWatermark , const char *& directoryToSave , const char *& particleType , InvariantMass & ObjMass , const char *& tagOrProbe , const char * passingOrFailing , const char *& quantityName , const char *& xAxisName , const char *& quantityUnit , const char *& extendedQuantityName , double & xMin , double & xMax , int & nBins , int & decimals ) : resonance ( resonance ), particleName ( particleName ), canvasWatermark ( canvasWatermark ), directoryToSave ( directoryToSave ), particleType ( particleType ), ObjMass ( ObjMass ), tagOrProbe ( tagOrProbe ), passingOrFailing ( passingOrFailing ), quantityName ( quantityName ), xAxisName ( xAxisName ), quantityUnit ( quantityUnit ), extendedQuantityName ( extendedQuantityName ), nBins ( nBins ), xMin ( xMin ), xMax ( xMax ), decimals ( decimals ) { createHistogram ( hSigBack , \"SigBack\" ); createHistogram ( hSig , \"Sig\" ); createHistogram ( hBack , \"Back\" ); }","title":"Constructor details"},{"location":"analysis/selection/idefficiencystudy/referenceguide/PassingFailing/#private-variable-details","text":"Summary Type Name const char*& resonance const char*& particleName const char*& canvasWatermark const char*& directoryToSave const char*& particleType const char*& tagOrProbe InvariantMass& ObjMass const char*& tagOrProbe const char*& xAxisName const char*& quantityUnit const char*& extendedQuantityName double& xMin double& xMax int& nBins int& decimals All variables here are reference for public variables in mother class: PtEtaPhi class .","title":"Private variable details"},{"location":"analysis/selection/idefficiencystudy/referenceguide/PassingFailing/#private-functions-details","text":"","title":"Private Functions details"},{"location":"analysis/selection/idefficiencystudy/referenceguide/PassingFailing/#createhistogram","text":"void createHistogram () Create quantity histogram.","title":"createHistogram()"},{"location":"analysis/selection/idefficiencystudy/referenceguide/PassingFailing/#fillafter","text":"string fillAfter ( string text , char fillWith , int targetLength ) Fill blank space of a string. It is used in consistencyDebugCout().","title":"fillAfter()"},{"location":"analysis/selection/idefficiencystudy/referenceguide/PassingFailing/#public-variable-details","text":"Summary Type Name Default value const char* passingOrFailing NULL TH1D* hSigBack NULL TH1D* hSig NULL TH1D* hBack NULL Details const char* passingOrFailing Set if it is \"Passing\" or \"All\" object. TH1D* hSigBack Stores the histogram for particles in signal region. TH1D* hSig Stores the subtracted histogram. TH1D* hBack Stores the histogram for particles in sideband region.","title":"Public variable details"},{"location":"analysis/selection/idefficiencystudy/referenceguide/PassingFailing/#public-functions-details","text":"","title":"Public Functions details"},{"location":"analysis/selection/idefficiencystudy/referenceguide/PassingFailing/#consistencydebugcout","text":"void consistencyDebugCout () Print on terminal the consistency check after subtractSigHistogram(). It is result for this equation: N total - (alpha * N background + N signal ) Where: alpha = yield of background particles signal region / yield of background particles sideband region","title":"consistencyDebugCout()"},{"location":"analysis/selection/idefficiencystudy/referenceguide/PassingFailing/#createquantitiescanvas","text":"TCanvas * createQuantitiesCanvas ( bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all quantities after subtractSigHistograms().","title":"createQuantitiesCanvas(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/PassingFailing/#fillquantitieshistograms","text":"void fillQuantitiesHistograms ( double & InvariantMass , int & isPassing ) Automatically fill all quantities histograms. Needs to be called in a loop over all dataset.","title":"fillQuantitiesHistograms(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/PassingFailing/#normalizehistograms","text":"void normalizeHistograms () Normalize quantities histograms of variable bin after filling it.","title":"normalizeHistograms()"},{"location":"analysis/selection/idefficiencystudy/referenceguide/PassingFailing/#passfailobj","text":"MassValues * PassFailObj () Get the MassValue object of corresponding MassValue object.","title":"PassFailObj()"},{"location":"analysis/selection/idefficiencystudy/referenceguide/PassingFailing/#subtractsighistogram","text":"void subtractSigHistogram () Apply sideband subtraction over histograms.","title":"subtractSigHistogram()"},{"location":"analysis/selection/idefficiencystudy/referenceguide/PassingFailing/#writequantitieshistogramsonfile","text":"void writeQuantitiesHistogramsOnFile ( bool hSigBack , bool hSig , bool hBack ) Write quantity histograms in a root file. Just need to call this function and all quantities histograms will be written. It needs to be called after subtractSigHistograms().","title":"writeQuantitiesHistogramsOnFile(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/PtEtaPhi/","text":"class PtEtaPhi \u00b6 Holds PassingFailing class . Constructor details \u00b6 PtEtaPhi ( const char *& resonance , const char *& particleName , const char *& canvasWatermark , const char *& directoryToSave , const char *& particleType , InvariantMass & ObjMass , const char *& tagOrProbe , const char * quantityName , const char * xAxisName , const char * quantityUnit , const char * extendedQuantityName , int nBins , double xMin , double xMax , int decimals = 3 ) : resonance ( resonance ), particleName ( particleName ), canvasWatermark ( canvasWatermark ), directoryToSave ( directoryToSave ), particleType ( particleType ), ObjMass ( ObjMass ), tagOrProbe ( tagOrProbe ), quantityName ( quantityName ), xAxisName ( xAxisName ), quantityUnit ( quantityUnit ), extendedQuantityName ( extendedQuantityName ), nBins ( nBins ), xMin ( xMin ), xMax ( xMax ), decimals ( decimals ) {} Private variable details \u00b6 Summary Type Name const char*& resonance const char*& particleName const char*& canvasWatermark const char*& directoryToSave const char*& particleType const char*& tagOrProbe InvariantMass& ObjMass All variables here are reference for public variables in mother class: TagProbe class . Public variable details \u00b6 Summary Type Name Default value const char* tagOrProbe NULL const char* xAxisName NULL const char* quantityUnit NULL const char* extendedQuantityName NULL double xMin 0. double xMax 0. int nBins 0 int decimals 3 TEfficiency* pEff NULL Details const char* quantityName Stores the quantity name. E.g.: \"pT\". const char* extendedQuantityName Stores the extended quantity name. E.g.: \"Transversal Momentum\". const char* quantityUnit Stores the quantity unit. E.g.: \"GeV/c\". const char* xAxisName Stores the quantity name for histogram horizontal axis in LaTeX form. E.g.: \"p_{t}\". int nBins Stores the number of bins in histograms. int decimals = 3 Number of decimals showed in bin width on histogram vertical axis. double xMin Lower horizontal value of histogram. double xMax Higher horizontal value of histogram. TEfficiency* pEff Stores the efficiency plot. Constructed objects PassingFailing Pass Stores all informations about invariant masses, including fit and histograms. PassingFailing All Stores all informations about tag muons, incuding quantities histograms and efficiencies. Public Functions details \u00b6 consistencyDebugCout() \u00b6 void consistencyDebugCout () Print on terminal the consistency check after subtractSigHistograms(). createEfficiencyCanvas(...) \u00b6 void createEfficiencyCanvas ( bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all efficiencies calculated. It need to be called after createEfficiencyPlot(...). createEfficiencyPlot(...) \u00b6 TEfficiency * createEfficiencyPlot ( bool shouldWrite = false ) Create a TEfficiency object with calculated efficiency. It needs do be called after subtractSigHistograms(). createQuantitiesCanvas(...) \u00b6 TCanvas * createQuantitiesCanvas ( bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all quantities after subtractSigHistograms(). fillQuantitiesHistograms(...) \u00b6 void fillQuantitiesHistograms ( double & quantity , double & InvariantMass , int & isPassing ) Automatically fill all quantities histograms. Needs to be called in a loop over all dataset. normalizeHistograms() \u00b6 void normalizeHistograms () Normalize quantities histograms of variable bin after filling it. subtractSigHistograms() \u00b6 void subtractSigHistograms () Apply sideband subtraction over all histograms. writeQuantitiesHistogramsOnFile(...) \u00b6 void writeQuantitiesHistogramsOnFile ( bool hSigBack , bool hSig , bool hBack ) Write all quantities histograms in a root file. Just need to call this function and all quantities histograms will be written. It needs to be called after subtractSigHistograms().","title":"PtEtaPhi class"},{"location":"analysis/selection/idefficiencystudy/referenceguide/PtEtaPhi/#class-ptetaphi","text":"Holds PassingFailing class .","title":"class PtEtaPhi"},{"location":"analysis/selection/idefficiencystudy/referenceguide/PtEtaPhi/#constructor-details","text":"PtEtaPhi ( const char *& resonance , const char *& particleName , const char *& canvasWatermark , const char *& directoryToSave , const char *& particleType , InvariantMass & ObjMass , const char *& tagOrProbe , const char * quantityName , const char * xAxisName , const char * quantityUnit , const char * extendedQuantityName , int nBins , double xMin , double xMax , int decimals = 3 ) : resonance ( resonance ), particleName ( particleName ), canvasWatermark ( canvasWatermark ), directoryToSave ( directoryToSave ), particleType ( particleType ), ObjMass ( ObjMass ), tagOrProbe ( tagOrProbe ), quantityName ( quantityName ), xAxisName ( xAxisName ), quantityUnit ( quantityUnit ), extendedQuantityName ( extendedQuantityName ), nBins ( nBins ), xMin ( xMin ), xMax ( xMax ), decimals ( decimals ) {}","title":"Constructor details"},{"location":"analysis/selection/idefficiencystudy/referenceguide/PtEtaPhi/#private-variable-details","text":"Summary Type Name const char*& resonance const char*& particleName const char*& canvasWatermark const char*& directoryToSave const char*& particleType const char*& tagOrProbe InvariantMass& ObjMass All variables here are reference for public variables in mother class: TagProbe class .","title":"Private variable details"},{"location":"analysis/selection/idefficiencystudy/referenceguide/PtEtaPhi/#public-variable-details","text":"Summary Type Name Default value const char* tagOrProbe NULL const char* xAxisName NULL const char* quantityUnit NULL const char* extendedQuantityName NULL double xMin 0. double xMax 0. int nBins 0 int decimals 3 TEfficiency* pEff NULL Details const char* quantityName Stores the quantity name. E.g.: \"pT\". const char* extendedQuantityName Stores the extended quantity name. E.g.: \"Transversal Momentum\". const char* quantityUnit Stores the quantity unit. E.g.: \"GeV/c\". const char* xAxisName Stores the quantity name for histogram horizontal axis in LaTeX form. E.g.: \"p_{t}\". int nBins Stores the number of bins in histograms. int decimals = 3 Number of decimals showed in bin width on histogram vertical axis. double xMin Lower horizontal value of histogram. double xMax Higher horizontal value of histogram. TEfficiency* pEff Stores the efficiency plot. Constructed objects PassingFailing Pass Stores all informations about invariant masses, including fit and histograms. PassingFailing All Stores all informations about tag muons, incuding quantities histograms and efficiencies.","title":"Public variable details"},{"location":"analysis/selection/idefficiencystudy/referenceguide/PtEtaPhi/#public-functions-details","text":"","title":"Public Functions details"},{"location":"analysis/selection/idefficiencystudy/referenceguide/PtEtaPhi/#consistencydebugcout","text":"void consistencyDebugCout () Print on terminal the consistency check after subtractSigHistograms().","title":"consistencyDebugCout()"},{"location":"analysis/selection/idefficiencystudy/referenceguide/PtEtaPhi/#createefficiencycanvas","text":"void createEfficiencyCanvas ( bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all efficiencies calculated. It need to be called after createEfficiencyPlot(...).","title":"createEfficiencyCanvas(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/PtEtaPhi/#createefficiencyplot","text":"TEfficiency * createEfficiencyPlot ( bool shouldWrite = false ) Create a TEfficiency object with calculated efficiency. It needs do be called after subtractSigHistograms().","title":"createEfficiencyPlot(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/PtEtaPhi/#createquantitiescanvas","text":"TCanvas * createQuantitiesCanvas ( bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all quantities after subtractSigHistograms().","title":"createQuantitiesCanvas(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/PtEtaPhi/#fillquantitieshistograms","text":"void fillQuantitiesHistograms ( double & quantity , double & InvariantMass , int & isPassing ) Automatically fill all quantities histograms. Needs to be called in a loop over all dataset.","title":"fillQuantitiesHistograms(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/PtEtaPhi/#normalizehistograms","text":"void normalizeHistograms () Normalize quantities histograms of variable bin after filling it.","title":"normalizeHistograms()"},{"location":"analysis/selection/idefficiencystudy/referenceguide/PtEtaPhi/#subtractsighistograms","text":"void subtractSigHistograms () Apply sideband subtraction over all histograms.","title":"subtractSigHistograms()"},{"location":"analysis/selection/idefficiencystudy/referenceguide/PtEtaPhi/#writequantitieshistogramsonfile","text":"void writeQuantitiesHistogramsOnFile ( bool hSigBack , bool hSig , bool hBack ) Write all quantities histograms in a root file. Just need to call this function and all quantities histograms will be written. It needs to be called after subtractSigHistograms().","title":"writeQuantitiesHistogramsOnFile(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/SidebandSubtraction/","text":"class SidebandSubtraction \u00b6 Holds Type class . This is the mother class. Constructor details \u00b6 SidebandSubtraction () {} SidebandSubtraction ( const char * resonance ) : resonance ( resonance ) {} Public variable details \u00b6 Summary Type Name Default value const char* resonance \"Jpsi\" const char* particleName \"Muon\" const char* canvasWatermark \"#bf{CMS Open Data}\" const char* directoryToSave \"../result/\" bool doTracker true bool doStandalone true bool doGlobal true bool doTagMuon true bool doProbeMuon true Details const char* resonance = \"Jpsi\" Supports values \"Jpsi\" , \"Upsilon\" or \"Upsilon(1S)\" . const char* particleName = \"Muon\" Stores the particle name for titles. const char* canvasWatermark = \"#bf{CMS Open Data}\" Stores what watermark will be showed in plots. const char* directoryToSave = \"../result/\" Where all canvas will be stored. bool doTracker = true If it will compute Tracker muons efficiency. bool doStandalone = true If it will compute Standalone muons efficiency. bool doGlobal = true If it will compute Global muons efficiency. Constructed objects Type Tracker Stores all informations about Tracker muons. Type Standalone Stores all informations about Standalone muons. Type Global Stores all informations about Global muons. Public Functions details \u00b6 consistencyDebugCout() \u00b6 void consistencyDebugCout () Print on terminal the consistency check after subtractSigHistograms(). createEfficiencyCanvas(...) \u00b6 void createEfficiencyCanvas ( bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all efficiencies calculated. It need to be called after createEfficiencyPlot(...). createEfficiencyPlot(...) \u00b6 void createEfficiencyPlot ( bool shouldWrite = false ) Create a TEfficiency object with calculated efficiency. It needs do be called after subtractSigHistograms(). createMassCanvas(...) \u00b6 void createMassCanvas ( bool drawRegions = false , bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all invariant mass (passing and all muons). createQuantitiesCanvas(...) \u00b6 void createQuantitiesCanvas ( bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all quantities after subtractSigHistograms(). defineMassHistogramNumbers() \u00b6 void defineMassHistogramNumbers ( int nBins , double xMin , double xMax , int decimals = 3 ) Redefine number parameters of all mass histograms. doFit() \u00b6 void doFit () Apply a fit over all invariant mass stored. fillMassHistograms(...) \u00b6 void fillMassHistograms ( double ** quantities , int ** types ) Automatically fill all masses histograms. Needs to be called in a loop over all dataset. fillQuantitiesHistograms(...) \u00b6 void fillQuantitiesHistograms ( double ** quantities , int ** types ) Automatically fill all quantities histograms. Needs to be called in a loop over all dataset. normalizeHistograms() \u00b6 void normalizeHistograms () Normalize quantities histograms of variable bin after filling it. subtractSigHistograms() \u00b6 void subtractSigHistograms () Apply sideband subtraction over all histograms. updateMassValuesAll() \u00b6 void updateMassValuesAll () After fill invariant mass histograms, you need to set signal regions and sideband regions. This function will set it for you. writeMassHistogramsOnFile(...) \u00b6 void writeMassHistogramsOnFile ( bool writehPass , bool writehAll ) Write all mass canvas histograms in a root file. Just need to call this function and all mass histograms will be written. writeQuantitiesHistogramsOnFile(...) \u00b6 void writeQuantitiesHistogramsOnFile ( bool hSigBack , bool hSig , bool hBack ) Write all quantities histograms in a root file. Just need to call this function and all quantities histograms will be written. It needs to be called after subtractSigHistograms().","title":"SidebandSubtraction class"},{"location":"analysis/selection/idefficiencystudy/referenceguide/SidebandSubtraction/#class-sidebandsubtraction","text":"Holds Type class . This is the mother class.","title":"class SidebandSubtraction"},{"location":"analysis/selection/idefficiencystudy/referenceguide/SidebandSubtraction/#constructor-details","text":"SidebandSubtraction () {} SidebandSubtraction ( const char * resonance ) : resonance ( resonance ) {}","title":"Constructor details"},{"location":"analysis/selection/idefficiencystudy/referenceguide/SidebandSubtraction/#public-variable-details","text":"Summary Type Name Default value const char* resonance \"Jpsi\" const char* particleName \"Muon\" const char* canvasWatermark \"#bf{CMS Open Data}\" const char* directoryToSave \"../result/\" bool doTracker true bool doStandalone true bool doGlobal true bool doTagMuon true bool doProbeMuon true Details const char* resonance = \"Jpsi\" Supports values \"Jpsi\" , \"Upsilon\" or \"Upsilon(1S)\" . const char* particleName = \"Muon\" Stores the particle name for titles. const char* canvasWatermark = \"#bf{CMS Open Data}\" Stores what watermark will be showed in plots. const char* directoryToSave = \"../result/\" Where all canvas will be stored. bool doTracker = true If it will compute Tracker muons efficiency. bool doStandalone = true If it will compute Standalone muons efficiency. bool doGlobal = true If it will compute Global muons efficiency. Constructed objects Type Tracker Stores all informations about Tracker muons. Type Standalone Stores all informations about Standalone muons. Type Global Stores all informations about Global muons.","title":"Public variable details"},{"location":"analysis/selection/idefficiencystudy/referenceguide/SidebandSubtraction/#public-functions-details","text":"","title":"Public Functions details"},{"location":"analysis/selection/idefficiencystudy/referenceguide/SidebandSubtraction/#consistencydebugcout","text":"void consistencyDebugCout () Print on terminal the consistency check after subtractSigHistograms().","title":"consistencyDebugCout()"},{"location":"analysis/selection/idefficiencystudy/referenceguide/SidebandSubtraction/#createefficiencycanvas","text":"void createEfficiencyCanvas ( bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all efficiencies calculated. It need to be called after createEfficiencyPlot(...).","title":"createEfficiencyCanvas(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/SidebandSubtraction/#createefficiencyplot","text":"void createEfficiencyPlot ( bool shouldWrite = false ) Create a TEfficiency object with calculated efficiency. It needs do be called after subtractSigHistograms().","title":"createEfficiencyPlot(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/SidebandSubtraction/#createmasscanvas","text":"void createMassCanvas ( bool drawRegions = false , bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all invariant mass (passing and all muons).","title":"createMassCanvas(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/SidebandSubtraction/#createquantitiescanvas","text":"void createQuantitiesCanvas ( bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all quantities after subtractSigHistograms().","title":"createQuantitiesCanvas(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/SidebandSubtraction/#definemasshistogramnumbers","text":"void defineMassHistogramNumbers ( int nBins , double xMin , double xMax , int decimals = 3 ) Redefine number parameters of all mass histograms.","title":"defineMassHistogramNumbers()"},{"location":"analysis/selection/idefficiencystudy/referenceguide/SidebandSubtraction/#dofit","text":"void doFit () Apply a fit over all invariant mass stored.","title":"doFit()"},{"location":"analysis/selection/idefficiencystudy/referenceguide/SidebandSubtraction/#fillmasshistograms","text":"void fillMassHistograms ( double ** quantities , int ** types ) Automatically fill all masses histograms. Needs to be called in a loop over all dataset.","title":"fillMassHistograms(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/SidebandSubtraction/#fillquantitieshistograms","text":"void fillQuantitiesHistograms ( double ** quantities , int ** types ) Automatically fill all quantities histograms. Needs to be called in a loop over all dataset.","title":"fillQuantitiesHistograms(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/SidebandSubtraction/#normalizehistograms","text":"void normalizeHistograms () Normalize quantities histograms of variable bin after filling it.","title":"normalizeHistograms()"},{"location":"analysis/selection/idefficiencystudy/referenceguide/SidebandSubtraction/#subtractsighistograms","text":"void subtractSigHistograms () Apply sideband subtraction over all histograms.","title":"subtractSigHistograms()"},{"location":"analysis/selection/idefficiencystudy/referenceguide/SidebandSubtraction/#updatemassvaluesall","text":"void updateMassValuesAll () After fill invariant mass histograms, you need to set signal regions and sideband regions. This function will set it for you.","title":"updateMassValuesAll()"},{"location":"analysis/selection/idefficiencystudy/referenceguide/SidebandSubtraction/#writemasshistogramsonfile","text":"void writeMassHistogramsOnFile ( bool writehPass , bool writehAll ) Write all mass canvas histograms in a root file. Just need to call this function and all mass histograms will be written.","title":"writeMassHistogramsOnFile(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/SidebandSubtraction/#writequantitieshistogramsonfile","text":"void writeQuantitiesHistogramsOnFile ( bool hSigBack , bool hSig , bool hBack ) Write all quantities histograms in a root file. Just need to call this function and all quantities histograms will be written. It needs to be called after subtractSigHistograms().","title":"writeQuantitiesHistogramsOnFile(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/TagProbe/","text":"class TagProbe \u00b6 Holds TagProbe class and InvariantMass class . Constructor details \u00b6 TagProbe ( const char *& resonance , const char *& particleName , const char *& canvasWatermark , const char *& directoryToSave , const char *& particleType , InvariantMass & ObjMass , const char * tagOrProbe ) : resonance ( resonance ), particleName ( particleName ), canvasWatermark ( canvasWatermark ), directoryToSave ( directoryToSave ), particleType ( particleType ), ObjMass ( ObjMass ), tagOrProbe ( tagOrProbe ) {} Private variable details \u00b6 Summary Type Name const char*& resonance const char*& particleName const char*& canvasWatermark const char*& directoryToSave const char*& particleType InvariantMass& ObjMass All variables here are reference for public variables in mother class: Type class Public variable details \u00b6 Summary Type Name Default value const char* tagOrProbe NULL Details const char* tagOrProbe = NULL Set if it is \"Tag\" or \"Probe\" object Constructed objects PtEtaPhi Pt Transversal momentum histograms. PtEtaPhi Eta Pseudorapidity histograms. PtEtaPhi Phi Azimutal angle histograms. Public Functions details \u00b6 consistencyDebugCout() \u00b6 void consistencyDebugCout () Print on terminal the consistency check after subtractSigHistograms(). createEfficiencyCanvas(...) \u00b6 void createEfficiencyCanvas ( bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all efficiencies calculated. It need to be called after createEfficiencyPlot(...). createEfficiencyPlot(...) \u00b6 void createEfficiencyPlot ( bool shouldWrite = false ) Create a TEfficiency object with calculated efficiency. It needs do be called after subtractSigHistograms(). createQuantitiesCanvas(...) \u00b6 void createQuantitiesCanvas ( bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all quantities after subtractSigHistograms(). fillQuantitiesHistograms(...) \u00b6 void fillQuantitiesHistograms ( double ** quantities , double & InvariantMass , int & isPassing ) Automatically fill all quantities histograms. Needs to be called in a loop over all dataset. normalizeHistograms() \u00b6 void normalizeHistograms () Normalize quantities histograms of variable bin after filling it. subtractSigHistograms() \u00b6 void subtractSigHistograms () Apply sideband subtraction over all histograms. writeQuantitiesHistogramsOnFile(...) \u00b6 void writeQuantitiesHistogramsOnFile ( bool hSigBack , bool hSig , bool hBack ) Write all quantities histograms in a root file. Just need to call this function and all quantities histograms will be written. It needs to be called after subtractSigHistograms().","title":"TagProbe class"},{"location":"analysis/selection/idefficiencystudy/referenceguide/TagProbe/#class-tagprobe","text":"Holds TagProbe class and InvariantMass class .","title":"class TagProbe"},{"location":"analysis/selection/idefficiencystudy/referenceguide/TagProbe/#constructor-details","text":"TagProbe ( const char *& resonance , const char *& particleName , const char *& canvasWatermark , const char *& directoryToSave , const char *& particleType , InvariantMass & ObjMass , const char * tagOrProbe ) : resonance ( resonance ), particleName ( particleName ), canvasWatermark ( canvasWatermark ), directoryToSave ( directoryToSave ), particleType ( particleType ), ObjMass ( ObjMass ), tagOrProbe ( tagOrProbe ) {}","title":"Constructor details"},{"location":"analysis/selection/idefficiencystudy/referenceguide/TagProbe/#private-variable-details","text":"Summary Type Name const char*& resonance const char*& particleName const char*& canvasWatermark const char*& directoryToSave const char*& particleType InvariantMass& ObjMass All variables here are reference for public variables in mother class: Type class","title":"Private variable details"},{"location":"analysis/selection/idefficiencystudy/referenceguide/TagProbe/#public-variable-details","text":"Summary Type Name Default value const char* tagOrProbe NULL Details const char* tagOrProbe = NULL Set if it is \"Tag\" or \"Probe\" object Constructed objects PtEtaPhi Pt Transversal momentum histograms. PtEtaPhi Eta Pseudorapidity histograms. PtEtaPhi Phi Azimutal angle histograms.","title":"Public variable details"},{"location":"analysis/selection/idefficiencystudy/referenceguide/TagProbe/#public-functions-details","text":"","title":"Public Functions details"},{"location":"analysis/selection/idefficiencystudy/referenceguide/TagProbe/#consistencydebugcout","text":"void consistencyDebugCout () Print on terminal the consistency check after subtractSigHistograms().","title":"consistencyDebugCout()"},{"location":"analysis/selection/idefficiencystudy/referenceguide/TagProbe/#createefficiencycanvas","text":"void createEfficiencyCanvas ( bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all efficiencies calculated. It need to be called after createEfficiencyPlot(...).","title":"createEfficiencyCanvas(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/TagProbe/#createefficiencyplot","text":"void createEfficiencyPlot ( bool shouldWrite = false ) Create a TEfficiency object with calculated efficiency. It needs do be called after subtractSigHistograms().","title":"createEfficiencyPlot(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/TagProbe/#createquantitiescanvas","text":"void createQuantitiesCanvas ( bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all quantities after subtractSigHistograms().","title":"createQuantitiesCanvas(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/TagProbe/#fillquantitieshistograms","text":"void fillQuantitiesHistograms ( double ** quantities , double & InvariantMass , int & isPassing ) Automatically fill all quantities histograms. Needs to be called in a loop over all dataset.","title":"fillQuantitiesHistograms(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/TagProbe/#normalizehistograms","text":"void normalizeHistograms () Normalize quantities histograms of variable bin after filling it.","title":"normalizeHistograms()"},{"location":"analysis/selection/idefficiencystudy/referenceguide/TagProbe/#subtractsighistograms","text":"void subtractSigHistograms () Apply sideband subtraction over all histograms.","title":"subtractSigHistograms()"},{"location":"analysis/selection/idefficiencystudy/referenceguide/TagProbe/#writequantitieshistogramsonfile","text":"void writeQuantitiesHistogramsOnFile ( bool hSigBack , bool hSig , bool hBack ) Write all quantities histograms in a root file. Just need to call this function and all quantities histograms will be written. It needs to be called after subtractSigHistograms().","title":"writeQuantitiesHistogramsOnFile(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/Type/","text":"class Type \u00b6 Holds TagProbe class and InvariantMass class . Constructor details \u00b6 Type ( const char *& resonance , const char *& particleName , bool & doTagMuon , bool & doProbeMuon , const char *& canvasWatermark , const char *& directoryToSave , const char * particleType ) : resonance ( resonance ), particleName ( particleName ), doTagMuon ( doTagMuon ), doProbeMuon ( doProbeMuon ), canvasWatermark ( canvasWatermark ), directoryToSave ( directoryToSave ), particleType ( particleType ) {} Private variable details \u00b6 Summary Type Name const char*& resonance const char*& particleName bool& doTagMuon bool& doProbeMuon const char*& canvasWatermark const char*& directoryToSave All variables here are reference for public variables in mother class: SidebandSubtraction class . Public variable details \u00b6 Summary Type Name Default value const char* particleType NULL Details const char* particleType = NULL Set the name of particle type. Constructed objects InvariantMass Mass Stores all informations about invariant masses, including fit and histograms. TagProbe Tag Stores all informations about tag muons, incuding quantities histograms and efficiencies. TagProbe Probe Stores all informations about probe muons, incuding quantities histograms and efficiencies. Public Functions details \u00b6 consistencyDebugCout() \u00b6 void consistencyDebugCout () Print on terminal the consistency check after subtractSigHistograms(). createEfficiencyCanvas(...) \u00b6 void createEfficiencyCanvas ( bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all efficiencies calculated. It need to be called after createEfficiencyPlot(...). createEfficiencyPlot(...) \u00b6 void createEfficiencyPlot ( bool shouldWrite = false ) Create a TEfficiency object with calculated efficiency. It needs do be called after subtractSigHistograms(). createMassCanvas(...) \u00b6 void createMassCanvas ( bool drawRegions = false , bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all invariant mass (passing and all muons). createQuantitiesCanvas(...) \u00b6 void createQuantitiesCanvas ( bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all quantities after subtractSigHistograms(). defineMassHistogramNumbers() \u00b6 void defineMassHistogramNumbers ( int nBins , double xMin , double xMax , int decimals = 3 ) Redefine number parameters of mass histograms in Mass object. doFit() \u00b6 void doFit () Apply a fit over invariant mass in Mass object. fillMassHistograms(...) \u00b6 void fillMassHistograms ( double & InvariantMass , int & isPassing ) Automatically fill all masses histograms. Needs to be called in a loop over all dataset. fillQuantitiesHistograms(...) \u00b6 void fillQuantitiesHistograms ( double ** quantities , int & isPassing ) Automatically fill all quantities histograms. Needs to be called in a loop over all dataset. normalizeHistograms() \u00b6 void normalizeHistograms () Normalize quantities histograms of variable bin after filling it. subtractSigHistograms() \u00b6 void subtractSigHistograms () Apply sideband subtraction over all histograms. updateMassValuesAll() \u00b6 void updateMassValuesAll () After fill invariant mass histograms, you need to set signal regions and sideband regions. This function will set it for you. writeMassHistogramsOnFile(...) \u00b6 void writeMassHistogramsOnFile ( bool writehPass , bool writehAll ) Write all mass canvas histograms in a root file. Just need to call this function and all mass histograms will be written. writeQuantitiesHistogramsOnFile(...) \u00b6 void writeQuantitiesHistogramsOnFile ( bool hSigBack , bool hSig , bool hBack ) Write all quantities histograms in a root file. Just need to call this function and all quantities histograms will be written. It needs to be called after subtractSigHistograms().","title":"Type class"},{"location":"analysis/selection/idefficiencystudy/referenceguide/Type/#class-type","text":"Holds TagProbe class and InvariantMass class .","title":"class Type"},{"location":"analysis/selection/idefficiencystudy/referenceguide/Type/#constructor-details","text":"Type ( const char *& resonance , const char *& particleName , bool & doTagMuon , bool & doProbeMuon , const char *& canvasWatermark , const char *& directoryToSave , const char * particleType ) : resonance ( resonance ), particleName ( particleName ), doTagMuon ( doTagMuon ), doProbeMuon ( doProbeMuon ), canvasWatermark ( canvasWatermark ), directoryToSave ( directoryToSave ), particleType ( particleType ) {}","title":"Constructor details"},{"location":"analysis/selection/idefficiencystudy/referenceguide/Type/#private-variable-details","text":"Summary Type Name const char*& resonance const char*& particleName bool& doTagMuon bool& doProbeMuon const char*& canvasWatermark const char*& directoryToSave All variables here are reference for public variables in mother class: SidebandSubtraction class .","title":"Private variable details"},{"location":"analysis/selection/idefficiencystudy/referenceguide/Type/#public-variable-details","text":"Summary Type Name Default value const char* particleType NULL Details const char* particleType = NULL Set the name of particle type. Constructed objects InvariantMass Mass Stores all informations about invariant masses, including fit and histograms. TagProbe Tag Stores all informations about tag muons, incuding quantities histograms and efficiencies. TagProbe Probe Stores all informations about probe muons, incuding quantities histograms and efficiencies.","title":"Public variable details"},{"location":"analysis/selection/idefficiencystudy/referenceguide/Type/#public-functions-details","text":"","title":"Public Functions details"},{"location":"analysis/selection/idefficiencystudy/referenceguide/Type/#consistencydebugcout","text":"void consistencyDebugCout () Print on terminal the consistency check after subtractSigHistograms().","title":"consistencyDebugCout()"},{"location":"analysis/selection/idefficiencystudy/referenceguide/Type/#createefficiencycanvas","text":"void createEfficiencyCanvas ( bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all efficiencies calculated. It need to be called after createEfficiencyPlot(...).","title":"createEfficiencyCanvas(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/Type/#createefficiencyplot","text":"void createEfficiencyPlot ( bool shouldWrite = false ) Create a TEfficiency object with calculated efficiency. It needs do be called after subtractSigHistograms().","title":"createEfficiencyPlot(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/Type/#createmasscanvas","text":"void createMassCanvas ( bool drawRegions = false , bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all invariant mass (passing and all muons).","title":"createMassCanvas(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/Type/#createquantitiescanvas","text":"void createQuantitiesCanvas ( bool shouldWrite = false , bool shouldSavePNG = false ) Create canvas for all quantities after subtractSigHistograms().","title":"createQuantitiesCanvas(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/Type/#definemasshistogramnumbers","text":"void defineMassHistogramNumbers ( int nBins , double xMin , double xMax , int decimals = 3 ) Redefine number parameters of mass histograms in Mass object.","title":"defineMassHistogramNumbers()"},{"location":"analysis/selection/idefficiencystudy/referenceguide/Type/#dofit","text":"void doFit () Apply a fit over invariant mass in Mass object.","title":"doFit()"},{"location":"analysis/selection/idefficiencystudy/referenceguide/Type/#fillmasshistograms","text":"void fillMassHistograms ( double & InvariantMass , int & isPassing ) Automatically fill all masses histograms. Needs to be called in a loop over all dataset.","title":"fillMassHistograms(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/Type/#fillquantitieshistograms","text":"void fillQuantitiesHistograms ( double ** quantities , int & isPassing ) Automatically fill all quantities histograms. Needs to be called in a loop over all dataset.","title":"fillQuantitiesHistograms(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/Type/#normalizehistograms","text":"void normalizeHistograms () Normalize quantities histograms of variable bin after filling it.","title":"normalizeHistograms()"},{"location":"analysis/selection/idefficiencystudy/referenceguide/Type/#subtractsighistograms","text":"void subtractSigHistograms () Apply sideband subtraction over all histograms.","title":"subtractSigHistograms()"},{"location":"analysis/selection/idefficiencystudy/referenceguide/Type/#updatemassvaluesall","text":"void updateMassValuesAll () After fill invariant mass histograms, you need to set signal regions and sideband regions. This function will set it for you.","title":"updateMassValuesAll()"},{"location":"analysis/selection/idefficiencystudy/referenceguide/Type/#writemasshistogramsonfile","text":"void writeMassHistogramsOnFile ( bool writehPass , bool writehAll ) Write all mass canvas histograms in a root file. Just need to call this function and all mass histograms will be written.","title":"writeMassHistogramsOnFile(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/Type/#writequantitieshistogramsonfile","text":"void writeQuantitiesHistogramsOnFile ( bool hSigBack , bool hSig , bool hBack ) Write all quantities histograms in a root file. Just need to call this function and all quantities histograms will be written. It needs to be called after subtractSigHistograms().","title":"writeQuantitiesHistogramsOnFile(...)"},{"location":"analysis/selection/idefficiencystudy/referenceguide/macro/","text":"macro.cpp \u00b6 A macro is a code file create to be interpreted by a program. In this case, ROOT will interpret it. About the code \u00b6 macro.cpp is a example how to use Sideband Subtraction to get reconstruction efficiencies for a Tag & Probe ntupple. It analyzes J/psi and Upsilon reconstruction efficiency for tracker , standalone and global muons. The file is encountered in folder main . Now, I going to talk about what this function do and how it does in the texto below. Before macro.cpp \u00b6 There are some files in folder config aside of macro.ccp . The sections below explain about them. cuts.h \u00b6 This is it content: //This files holds some functions used in macro.cpp for particle selection //Return if is a accepted particle or no bool applyCuts ( double ** quantities , int ** types ) { //Assign variables for easy visualization double & ProbeMuon_Pt = * quantities [ 0 ]; double & ProbeMuon_Eta = * quantities [ 1 ]; double & ProbeMuon_Phi = * quantities [ 2 ]; double & TagMuon_Pt = * quantities [ 3 ]; double & TagMuon_Eta = * quantities [ 4 ]; double & TagMuon_Phi = * quantities [ 5 ]; double & InvariantMass = * quantities [ 6 ]; int & PassingProbeTrackingMuon = * types [ 0 ]; int & PassingProbeStandAloneMuon = * types [ 1 ]; int & PassingProbeGlobalMuon = * types [ 2 ]; //Apply cuts if ( TagMuon_Pt >= 7.0 && fabs ( TagMuon_Eta ) <= 2.4 ) return true ; return false ; } It stores the function applyCuts(), where return true for allowed pair of particles and false for not allowed. createHistogram.h \u00b6 This file is called in PassingFailing.cpp and set quantity histograms bins and create the hitogram. Its default content is shwon bellow: void createHistogram ( TH1D * & histo , const char * histoName ) { //Set parameters string hName = string ( particleType ) + string ( passingOrFailing ) + string ( tagOrProbe ) + string ( particleName ) + \"_\" + string ( quantityName ) + string ( histoName ); string hTitle = string ( passingOrFailing ) + \" in \" + string ( particleType ) + \" \" + string ( tagOrProbe ); string xAxisTitle = string ( xAxisName ); string yAxisTitleForm = \"Events\" ; //Add unit if has if ( strcmp ( quantityUnit , \"\" ) != 0 ) xAxisTitle += \" [\" + string ( quantityUnit ) + \"]\" ; //Change title is passing if ( strcmp ( passingOrFailing , \"Passing\" ) == 0 ) hTitle = string ( particleType ) + \" \" + string ( particleName ) + \" \" + string ( tagOrProbe ); if ( strcmp ( passingOrFailing , \"All\" ) == 0 ) hTitle = \"All \" + string ( particleName ) + \" \" + string ( tagOrProbe ); //Variable bin for pT if ( strcmp ( quantityName , \"Pt\" ) == 0 ) { double xbins [] = { 0. , 2.0 , 3.4 , 4.0 , 4.4 , 4.7 , 5.0 , 5.6 , 5.8 , 6.0 , 6.2 , 6.4 , 6.6 , 6.8 , 7.3 , 9.5 , 13.0 , 17.0 , 40. }; int nbins = sizeof ( xbins ) / sizeof ( * xbins ) - 1 ; histo = new TH1D ( hName . data (), hTitle . data (), nbins , xbins ); } //Variable bin for eta else if ( strcmp ( quantityName , \"Eta\" ) == 0 ) { double xbins [] = { -2.4 , -1.8 , -1.4 , -1.2 , -1.0 , -0.8 , -0.5 , -0.2 , 0 , 0.2 , 0.5 , 0.8 , 1.0 , 1.2 , 1.4 , 1.8 , 2.4 }; int nbins = sizeof ( xbins ) / sizeof ( * xbins ) - 1 ; histo = new TH1D ( hName . data (), hTitle . data (), nbins , xbins ); } //Bins for phi else { double xbins [] = { -3.0 , -1.8 , -1.6 , -1.2 , -1.0 , -0.7 , -0.4 , -0.2 , 0 , 0.2 , 0.4 , 0.7 , 1.0 , 1.2 , 1.6 , 1.8 , 3.0 }; int nbins = sizeof ( xbins ) / sizeof ( * xbins ) - 1 ; histo = new TH1D ( hName . data (), hTitle . data (), nbins , xbins ); } //Edit histogram axis histo -> GetYaxis () -> SetTitle ( Form ( yAxisTitleForm . data (), histo -> GetBinWidth ( 0 ))); histo -> GetXaxis () -> SetTitle ( xAxisTitle . data ()); } settings.cpp \u00b6 It stores many configurations used in macro.cpp : //List of files const char * files [] = { \"../data_histoall.root\" , \"../Run2011AMuOnia_mergeNtuple.root\" , \"../JPsiToMuMu_mergeMCNtuple.root\" , \"../Run2011A_MuOnia_Upsilon.root\" , \"../Upsilon1SToMuMu_MC_full.root\" }; const char * directoriesToSave [] = { \"../results/result/\" , \"../results/Jpsi_Run_2011/\" , \"../results/Jpsi_MC_2020_sbs/\" , \"../results/Upsilon_Run_2011/\" , \"../results/Upsilon_MC_2020_sbs/\" }; //MAIN OPTIONS //Which file of files (variable above) should use int useFile = 4 ; //Set the canvasW wtermark const char * canvasWatermark = \"#bf{CMS Open Data}\" ; //Path where is going to save results const char * directoryToSave = directoriesToSave [ useFile ]; //directoryToSave = \"../result/\"; //Should limit data? long long limitData = 0 ; //0 -> do not limit //Canvas drawing bool shouldDrawInvariantMassCanvas = true ; bool shouldDrawInvariantMassCanvasRegion = true ; bool shouldDrawQuantitiesCanvas = true ; bool shouldDrawEfficiencyCanvas = true ; //Muon id anlyse bool doTracker = true ; bool doStandalone = false ; bool doGlobal = false ; //Muon label anlyse bool doTagMuon = false ; bool doProbeMuon = true ; //ENDED MAIN OPTIONS And then there are more automatically set options: //Auto detect resonance due file index const char * resonance = \"Jpsi\" ; if ( useFile > 2 ) resonance = \"Upsilon\" ; if ( useFile == 4 ) resonance = \"Upsilon1S\" ; //Auto detect limit of data if ( limitData > 0 ) directoryToSave = \"../partial_result/\" ; //Compatibility adjusts on file read (for data_histoall ntupples) bool needsRetroCompatibility = false ; if ( useFile == 0 ) needsRetroCompatibility = true ; Code explained in parts \u00b6 macro.cpp is the main file of this program. Its the main code. It is explained in parts below: //Input files, options are set here! #include \"config/settings.cpp\" It imports configurations about macro.cpp //Check if the name of dir is ok if ( string ( directoryToSave ). back () != string ( \"/\" )) { cerr << \"To avoid errors, please end the result directory with a \\\" / \\\" \" << endl ; abort (); } //Check if dir exists and create if ( gSystem -> AccessPathName ( directoryToSave )) { if ( gSystem -> mkdir ( directoryToSave , true )) { cerr << \" \\\" \" << directoryToSave << \" \\\" path could not be found and could not be created ERROR\" << endl ; cerr << \"Try to create manually this folder path\" << endl ; abort (); } else { cout << \" \\\" \" << directoryToSave << \" \\\" directory created OK\" << endl ; } } else { cout << \" \\\" \" << directoryToSave << \" \\\" directory OK\" << endl ; } Check if the directoryToSave (setted in settings.cpp) has a valid name and if exists. If not, the code creates the folder. //Compatibility adjusts on file read (for data_histoall ntupples) string folderName = \"tagandprobe/\" ; if ( needsRetroCompatibility ) folderName = \"demo/\" ; //Open and read files TFile * file0 = TFile :: Open ( files [ useFile ]); TTree * TreePC = ( TTree * ) file0 -> Get (( folderName + \"PlotControl\" ). data ()); TTree * TreeAT = ( TTree * ) file0 -> Get (( folderName + \"AnalysisTree\" ). data ()); cout << \"Using \\\" \" << files [ useFile ] << \" \\\" ntupple\" << endl ; This part is responsible to open the file and do conversions. The first one file is a bit different of the other ones, so it needs compatibiliy besides its not important anymore and is a obsolete file. //Create variables double ProbeMuon_Pt ; double ProbeMuon_Eta ; double ProbeMuon_Phi ; double TagMuon_Pt ; double TagMuon_Eta ; double TagMuon_Phi ; double InvariantMass ; int PassingProbeTrackingMuon ; int PassingProbeStandAloneMuon ; int PassingProbeGlobalMuon ; //Assign variables TreePC -> SetBranchAddress ( \"ProbeMuon_Pt\" , & ProbeMuon_Pt ); TreePC -> SetBranchAddress ( \"ProbeMuon_Eta\" , & ProbeMuon_Eta ); TreePC -> SetBranchAddress ( \"ProbeMuon_Phi\" , & ProbeMuon_Phi ); TreePC -> SetBranchAddress ( \"TagMuon_Pt\" , & TagMuon_Pt ); TreePC -> SetBranchAddress ( \"TagMuon_Eta\" , & TagMuon_Eta ); TreePC -> SetBranchAddress ( \"TagMuon_Phi\" , & TagMuon_Phi ); if ( needsRetroCompatibility ) TreePC -> SetBranchAddress ( \"InvariantMass\" , & InvariantMass ); else TreeAT -> SetBranchAddress ( \"InvariantMass\" , & InvariantMass ); TreeAT -> SetBranchAddress ( \"PassingProbeTrackingMuon\" , & PassingProbeTrackingMuon ); TreeAT -> SetBranchAddress ( \"PassingProbeStandAloneMuon\" , & PassingProbeStandAloneMuon ); TreeAT -> SetBranchAddress ( \"PassingProbeGlobalMuon\" , & PassingProbeGlobalMuon ); double * quantities [] = { & ProbeMuon_Pt , & ProbeMuon_Eta , & ProbeMuon_Phi , & TagMuon_Pt , & TagMuon_Eta , & TagMuon_Phi , & InvariantMass , }; int * types [] = { & PassingProbeTrackingMuon , & PassingProbeStandAloneMuon , & PassingProbeGlobalMuon }; Now variables are created and linked to branches in ntupple. Then a array of these variables are set. //Create a object and set configs SidebandSubtraction SdS { resonance }; SdS . canvasWatermark = canvasWatermark ; SdS . directoryToSave = directoryToSave ; SdS . doTracker = doTracker ; SdS . doStandalone = doStandalone ; SdS . doGlobal = doGlobal ; SdS . doTagMuon = doTagMuon ; SdS . doProbeMuon = doProbeMuon ; cout << \"resonance: \" << SdS . resonance << \" \\n \" ; cout << \"Using subtraction factor as integral of background fit \\n \" ; The macro.cpp now creates the SdS object and assign variables setted in settings.cpp. At this point, it creates all histograms that you will need such as invariant mass histograms and pT, eta, phi histograms. //Get data size and set data limit if has long long numberEntries = TreePC -> GetEntries (); if ( limitData > 0 && limitData < numberEntries ) numberEntries = limitData ; printf ( \"Data analysed = %lld of %lld \\n \" , numberEntries , TreePC -> GetEntries ()); //Prepare for showing progress string progressFormat = \"Progress: %05.2f%% %0\" + to_string ( strlen ( to_string ( numberEntries ). data ())) + \"lld/%lld \\r \" ; auto lastTime = std :: chrono :: steady_clock :: now (); auto start = std :: chrono :: steady_clock :: now (); Now the code are limiting data if you setted and setting a string for progress information while filling histograms. cout << \" \\n Filling Invariant Mass Histograms..... (1/2) \\n \" ; //Loop between the components for ( long long i = 0 ; i < numberEntries ; i ++ ) { //Select particle pair TreePC -> GetEntry ( i ); TreeAT -> GetEntry ( i ); //Show progress on screen if ( chrono :: duration_cast < chrono :: milliseconds > ( chrono :: steady_clock :: now () - lastTime ). count () >= 1000 || i == numberEntries - 1 ) { printf ( progressFormat . data (), ( float )( i + 1 ) / ( float ) numberEntries * 100 , i + 1 , numberEntries ); lastTime = chrono :: steady_clock :: now (); } //Fill histograms if ( applyCuts ( quantities , types )) { SdS . fillMassHistograms ( quantities , types ); } } cout << \" \\n Took \" << chrono :: duration_cast < chrono :: milliseconds > ( chrono :: steady_clock :: now () - start ). count () << \" ms \\n \" ; This part of the code fill invariant mass histograms. Cuts are applyied in cuts.h. At this point, macro.cpp separes in passing and all muons. //Do function fit over the histogram SdS . doFit (); //Get values for invariant mass and sigma from plot SdS . updateMassValuesAll (); After filling mass histograms, it is necessary to apply the fit function. After doing fit, updateMassValuesAll() get regions for sideband subtraction mostly based in fitting. //------------------------------------- // Generate and save files //------------------------------------- //Create file root to store generated files TFile * generatedFile = TFile :: Open (( string ( directoryToSave ) + \"generated_hist.root\" ). data (), \"RECREATE\" ); generatedFile -> mkdir ( \"canvas/\" ); generatedFile -> cd ( \"canvas/\" ); if ( shouldDrawInvariantMassCanvas ) { bool drawRegions = false ; bool shouldWrite = true ; bool shouldSavePNG = true ; SdS . createMassCanvas ( drawRegions , shouldWrite , shouldSavePNG ); } if ( shouldDrawInvariantMassCanvasRegion && ! isMC ) { bool drawRegions = true ; bool shouldWrite = true ; bool shouldSavePNG = true ; SdS . createMassCanvas ( drawRegions , shouldWrite , shouldSavePNG ); } Canvas are drawn and saved in the generated_hist.root file and in the folder as .png . //Prepare for showing progress lastTime = std :: chrono :: steady_clock :: now (); start = std :: chrono :: steady_clock :: now (); cout << \" \\n Filling Quantities Histograms..... (2/2) \\n \" ; //Loop between the components again for ( long long i = 0 ; i < numberEntries ; i ++ ) { //Select particle pair TreePC -> GetEntry ( i ); TreeAT -> GetEntry ( i ); //Show progress on screen if ( chrono :: duration_cast < chrono :: milliseconds > ( chrono :: steady_clock :: now () - lastTime ). count () >= 1000 || i == numberEntries - 1 ) { printf ( progressFormat . data (), ( float )( i + 1 ) / ( float ) numberEntries * 100 , i + 1 , numberEntries ); lastTime = chrono :: steady_clock :: now (); } //Fill histograms if ( applyCuts ( quantities , types )) { SdS . fillQuantitiesHistograms ( quantities , types ); } } cout << \" \\n Took \" << chrono :: duration_cast < chrono :: milliseconds > ( chrono :: steady_clock :: now () - start ). count () << \" ms \\n \" ; At this point of the code, this will separate all histogram in signal + background (signal region) and background (sideband region) due the regions for sideband choosen before. //Normalize Histograms for variable binning cout << \" \\n \" ; SdS . normalizeHistograms (); After folling histograms, as some of them has variable bins, it needs to be normalized. This function does this. //For sideband subtraction SdS . subtractSigHistograms (); Subtract background from signal + background histogram to create signal histogram. This method is what is called sideband subtraction . if ( shouldDrawQuantitiesCanvas ) { bool shouldWrite = true ; bool shouldSavePNG = true ; cout << endl ; SdS . createQuantitiesCanvas ( shouldWrite , shouldSavePNG ); } The code here draw the canvas for all pT, eta and phi quantities it has. Including background , signal and signal + background . //Debug consistency for histograms SdS . consistencyDebugCout (); This is a checker of how consistent is our result values and print on terminal results. For all histograms this calculations should result 0. For more details about how exactly it works, see consistencyDebugCout() . //Save histograms generatedFile -> mkdir ( \"histograms/\" ); generatedFile -> cd ( \"histograms/\" ); //Write quantities histograms on file { bool writehSigBack = true ; bool writehSig = true ; bool writehBack = true ; SdS . writeQuantitiesHistogramsOnFile ( writehSigBack , writehSig , writehBack ); } //Write mass histograms on file { bool writehPass = true ; bool writehAll = true ; SdS . writeMassHistogramsOnFile ( writehPass , writehAll ); } At this point, the code will write all histograms in a folder in the .root generated file. Including mass histograms and quantities histograms. //Save plots generatedFile -> mkdir ( \"efficiency/plots/\" ); generatedFile -> cd ( \"efficiency/plots/\" ); //Creates efficiency plots { bool shouldWrite = true ; SdS . createEfficiencyPlot ( shouldWrite ); } It calculates the efficiency of the quantities by using TEfficiency class of ROOT. Then saves the plots in another folder inside the .root file. //Saves new histograms and canvas in file generatedFile -> mkdir ( \"efficiency/canvas/\" ); generatedFile -> cd ( \"efficiency/canvas/\" ); if ( shouldDrawEfficiencyCanvas ) { bool shouldWrite = true ; bool shouldSavePNG = true ; cout << \" \\n \" ; SdS . createEfficiencyCanvas ( shouldWrite , shouldSavePNG ); } //Close files generatedFile -> Close (); cout << \" \\n Done. All result files can be found at \\\" \" << SdS . directoryToSave << \" \\\"\\n\\n \" ; The end point of this function. It creates a canvas for every efficiency plot calculated above and also saves in the generated file. After this, the task is done. Results \u00b6 All results are saved in a folder setted in directoryToSave variable. The result contains a file .root with all canvas, histograms and plots aside of .png images of all canvas created.","title":"macro"},{"location":"analysis/selection/idefficiencystudy/referenceguide/macro/#macrocpp","text":"A macro is a code file create to be interpreted by a program. In this case, ROOT will interpret it.","title":"macro.cpp"},{"location":"analysis/selection/idefficiencystudy/referenceguide/macro/#about-the-code","text":"macro.cpp is a example how to use Sideband Subtraction to get reconstruction efficiencies for a Tag & Probe ntupple. It analyzes J/psi and Upsilon reconstruction efficiency for tracker , standalone and global muons. The file is encountered in folder main . Now, I going to talk about what this function do and how it does in the texto below.","title":"About the code"},{"location":"analysis/selection/idefficiencystudy/referenceguide/macro/#before-macrocpp","text":"There are some files in folder config aside of macro.ccp . The sections below explain about them.","title":"Before macro.cpp"},{"location":"analysis/selection/idefficiencystudy/referenceguide/macro/#cutsh","text":"This is it content: //This files holds some functions used in macro.cpp for particle selection //Return if is a accepted particle or no bool applyCuts ( double ** quantities , int ** types ) { //Assign variables for easy visualization double & ProbeMuon_Pt = * quantities [ 0 ]; double & ProbeMuon_Eta = * quantities [ 1 ]; double & ProbeMuon_Phi = * quantities [ 2 ]; double & TagMuon_Pt = * quantities [ 3 ]; double & TagMuon_Eta = * quantities [ 4 ]; double & TagMuon_Phi = * quantities [ 5 ]; double & InvariantMass = * quantities [ 6 ]; int & PassingProbeTrackingMuon = * types [ 0 ]; int & PassingProbeStandAloneMuon = * types [ 1 ]; int & PassingProbeGlobalMuon = * types [ 2 ]; //Apply cuts if ( TagMuon_Pt >= 7.0 && fabs ( TagMuon_Eta ) <= 2.4 ) return true ; return false ; } It stores the function applyCuts(), where return true for allowed pair of particles and false for not allowed.","title":"cuts.h"},{"location":"analysis/selection/idefficiencystudy/referenceguide/macro/#createhistogramh","text":"This file is called in PassingFailing.cpp and set quantity histograms bins and create the hitogram. Its default content is shwon bellow: void createHistogram ( TH1D * & histo , const char * histoName ) { //Set parameters string hName = string ( particleType ) + string ( passingOrFailing ) + string ( tagOrProbe ) + string ( particleName ) + \"_\" + string ( quantityName ) + string ( histoName ); string hTitle = string ( passingOrFailing ) + \" in \" + string ( particleType ) + \" \" + string ( tagOrProbe ); string xAxisTitle = string ( xAxisName ); string yAxisTitleForm = \"Events\" ; //Add unit if has if ( strcmp ( quantityUnit , \"\" ) != 0 ) xAxisTitle += \" [\" + string ( quantityUnit ) + \"]\" ; //Change title is passing if ( strcmp ( passingOrFailing , \"Passing\" ) == 0 ) hTitle = string ( particleType ) + \" \" + string ( particleName ) + \" \" + string ( tagOrProbe ); if ( strcmp ( passingOrFailing , \"All\" ) == 0 ) hTitle = \"All \" + string ( particleName ) + \" \" + string ( tagOrProbe ); //Variable bin for pT if ( strcmp ( quantityName , \"Pt\" ) == 0 ) { double xbins [] = { 0. , 2.0 , 3.4 , 4.0 , 4.4 , 4.7 , 5.0 , 5.6 , 5.8 , 6.0 , 6.2 , 6.4 , 6.6 , 6.8 , 7.3 , 9.5 , 13.0 , 17.0 , 40. }; int nbins = sizeof ( xbins ) / sizeof ( * xbins ) - 1 ; histo = new TH1D ( hName . data (), hTitle . data (), nbins , xbins ); } //Variable bin for eta else if ( strcmp ( quantityName , \"Eta\" ) == 0 ) { double xbins [] = { -2.4 , -1.8 , -1.4 , -1.2 , -1.0 , -0.8 , -0.5 , -0.2 , 0 , 0.2 , 0.5 , 0.8 , 1.0 , 1.2 , 1.4 , 1.8 , 2.4 }; int nbins = sizeof ( xbins ) / sizeof ( * xbins ) - 1 ; histo = new TH1D ( hName . data (), hTitle . data (), nbins , xbins ); } //Bins for phi else { double xbins [] = { -3.0 , -1.8 , -1.6 , -1.2 , -1.0 , -0.7 , -0.4 , -0.2 , 0 , 0.2 , 0.4 , 0.7 , 1.0 , 1.2 , 1.6 , 1.8 , 3.0 }; int nbins = sizeof ( xbins ) / sizeof ( * xbins ) - 1 ; histo = new TH1D ( hName . data (), hTitle . data (), nbins , xbins ); } //Edit histogram axis histo -> GetYaxis () -> SetTitle ( Form ( yAxisTitleForm . data (), histo -> GetBinWidth ( 0 ))); histo -> GetXaxis () -> SetTitle ( xAxisTitle . data ()); }","title":"createHistogram.h"},{"location":"analysis/selection/idefficiencystudy/referenceguide/macro/#settingscpp","text":"It stores many configurations used in macro.cpp : //List of files const char * files [] = { \"../data_histoall.root\" , \"../Run2011AMuOnia_mergeNtuple.root\" , \"../JPsiToMuMu_mergeMCNtuple.root\" , \"../Run2011A_MuOnia_Upsilon.root\" , \"../Upsilon1SToMuMu_MC_full.root\" }; const char * directoriesToSave [] = { \"../results/result/\" , \"../results/Jpsi_Run_2011/\" , \"../results/Jpsi_MC_2020_sbs/\" , \"../results/Upsilon_Run_2011/\" , \"../results/Upsilon_MC_2020_sbs/\" }; //MAIN OPTIONS //Which file of files (variable above) should use int useFile = 4 ; //Set the canvasW wtermark const char * canvasWatermark = \"#bf{CMS Open Data}\" ; //Path where is going to save results const char * directoryToSave = directoriesToSave [ useFile ]; //directoryToSave = \"../result/\"; //Should limit data? long long limitData = 0 ; //0 -> do not limit //Canvas drawing bool shouldDrawInvariantMassCanvas = true ; bool shouldDrawInvariantMassCanvasRegion = true ; bool shouldDrawQuantitiesCanvas = true ; bool shouldDrawEfficiencyCanvas = true ; //Muon id anlyse bool doTracker = true ; bool doStandalone = false ; bool doGlobal = false ; //Muon label anlyse bool doTagMuon = false ; bool doProbeMuon = true ; //ENDED MAIN OPTIONS And then there are more automatically set options: //Auto detect resonance due file index const char * resonance = \"Jpsi\" ; if ( useFile > 2 ) resonance = \"Upsilon\" ; if ( useFile == 4 ) resonance = \"Upsilon1S\" ; //Auto detect limit of data if ( limitData > 0 ) directoryToSave = \"../partial_result/\" ; //Compatibility adjusts on file read (for data_histoall ntupples) bool needsRetroCompatibility = false ; if ( useFile == 0 ) needsRetroCompatibility = true ;","title":"settings.cpp"},{"location":"analysis/selection/idefficiencystudy/referenceguide/macro/#code-explained-in-parts","text":"macro.cpp is the main file of this program. Its the main code. It is explained in parts below: //Input files, options are set here! #include \"config/settings.cpp\" It imports configurations about macro.cpp //Check if the name of dir is ok if ( string ( directoryToSave ). back () != string ( \"/\" )) { cerr << \"To avoid errors, please end the result directory with a \\\" / \\\" \" << endl ; abort (); } //Check if dir exists and create if ( gSystem -> AccessPathName ( directoryToSave )) { if ( gSystem -> mkdir ( directoryToSave , true )) { cerr << \" \\\" \" << directoryToSave << \" \\\" path could not be found and could not be created ERROR\" << endl ; cerr << \"Try to create manually this folder path\" << endl ; abort (); } else { cout << \" \\\" \" << directoryToSave << \" \\\" directory created OK\" << endl ; } } else { cout << \" \\\" \" << directoryToSave << \" \\\" directory OK\" << endl ; } Check if the directoryToSave (setted in settings.cpp) has a valid name and if exists. If not, the code creates the folder. //Compatibility adjusts on file read (for data_histoall ntupples) string folderName = \"tagandprobe/\" ; if ( needsRetroCompatibility ) folderName = \"demo/\" ; //Open and read files TFile * file0 = TFile :: Open ( files [ useFile ]); TTree * TreePC = ( TTree * ) file0 -> Get (( folderName + \"PlotControl\" ). data ()); TTree * TreeAT = ( TTree * ) file0 -> Get (( folderName + \"AnalysisTree\" ). data ()); cout << \"Using \\\" \" << files [ useFile ] << \" \\\" ntupple\" << endl ; This part is responsible to open the file and do conversions. The first one file is a bit different of the other ones, so it needs compatibiliy besides its not important anymore and is a obsolete file. //Create variables double ProbeMuon_Pt ; double ProbeMuon_Eta ; double ProbeMuon_Phi ; double TagMuon_Pt ; double TagMuon_Eta ; double TagMuon_Phi ; double InvariantMass ; int PassingProbeTrackingMuon ; int PassingProbeStandAloneMuon ; int PassingProbeGlobalMuon ; //Assign variables TreePC -> SetBranchAddress ( \"ProbeMuon_Pt\" , & ProbeMuon_Pt ); TreePC -> SetBranchAddress ( \"ProbeMuon_Eta\" , & ProbeMuon_Eta ); TreePC -> SetBranchAddress ( \"ProbeMuon_Phi\" , & ProbeMuon_Phi ); TreePC -> SetBranchAddress ( \"TagMuon_Pt\" , & TagMuon_Pt ); TreePC -> SetBranchAddress ( \"TagMuon_Eta\" , & TagMuon_Eta ); TreePC -> SetBranchAddress ( \"TagMuon_Phi\" , & TagMuon_Phi ); if ( needsRetroCompatibility ) TreePC -> SetBranchAddress ( \"InvariantMass\" , & InvariantMass ); else TreeAT -> SetBranchAddress ( \"InvariantMass\" , & InvariantMass ); TreeAT -> SetBranchAddress ( \"PassingProbeTrackingMuon\" , & PassingProbeTrackingMuon ); TreeAT -> SetBranchAddress ( \"PassingProbeStandAloneMuon\" , & PassingProbeStandAloneMuon ); TreeAT -> SetBranchAddress ( \"PassingProbeGlobalMuon\" , & PassingProbeGlobalMuon ); double * quantities [] = { & ProbeMuon_Pt , & ProbeMuon_Eta , & ProbeMuon_Phi , & TagMuon_Pt , & TagMuon_Eta , & TagMuon_Phi , & InvariantMass , }; int * types [] = { & PassingProbeTrackingMuon , & PassingProbeStandAloneMuon , & PassingProbeGlobalMuon }; Now variables are created and linked to branches in ntupple. Then a array of these variables are set. //Create a object and set configs SidebandSubtraction SdS { resonance }; SdS . canvasWatermark = canvasWatermark ; SdS . directoryToSave = directoryToSave ; SdS . doTracker = doTracker ; SdS . doStandalone = doStandalone ; SdS . doGlobal = doGlobal ; SdS . doTagMuon = doTagMuon ; SdS . doProbeMuon = doProbeMuon ; cout << \"resonance: \" << SdS . resonance << \" \\n \" ; cout << \"Using subtraction factor as integral of background fit \\n \" ; The macro.cpp now creates the SdS object and assign variables setted in settings.cpp. At this point, it creates all histograms that you will need such as invariant mass histograms and pT, eta, phi histograms. //Get data size and set data limit if has long long numberEntries = TreePC -> GetEntries (); if ( limitData > 0 && limitData < numberEntries ) numberEntries = limitData ; printf ( \"Data analysed = %lld of %lld \\n \" , numberEntries , TreePC -> GetEntries ()); //Prepare for showing progress string progressFormat = \"Progress: %05.2f%% %0\" + to_string ( strlen ( to_string ( numberEntries ). data ())) + \"lld/%lld \\r \" ; auto lastTime = std :: chrono :: steady_clock :: now (); auto start = std :: chrono :: steady_clock :: now (); Now the code are limiting data if you setted and setting a string for progress information while filling histograms. cout << \" \\n Filling Invariant Mass Histograms..... (1/2) \\n \" ; //Loop between the components for ( long long i = 0 ; i < numberEntries ; i ++ ) { //Select particle pair TreePC -> GetEntry ( i ); TreeAT -> GetEntry ( i ); //Show progress on screen if ( chrono :: duration_cast < chrono :: milliseconds > ( chrono :: steady_clock :: now () - lastTime ). count () >= 1000 || i == numberEntries - 1 ) { printf ( progressFormat . data (), ( float )( i + 1 ) / ( float ) numberEntries * 100 , i + 1 , numberEntries ); lastTime = chrono :: steady_clock :: now (); } //Fill histograms if ( applyCuts ( quantities , types )) { SdS . fillMassHistograms ( quantities , types ); } } cout << \" \\n Took \" << chrono :: duration_cast < chrono :: milliseconds > ( chrono :: steady_clock :: now () - start ). count () << \" ms \\n \" ; This part of the code fill invariant mass histograms. Cuts are applyied in cuts.h. At this point, macro.cpp separes in passing and all muons. //Do function fit over the histogram SdS . doFit (); //Get values for invariant mass and sigma from plot SdS . updateMassValuesAll (); After filling mass histograms, it is necessary to apply the fit function. After doing fit, updateMassValuesAll() get regions for sideband subtraction mostly based in fitting. //------------------------------------- // Generate and save files //------------------------------------- //Create file root to store generated files TFile * generatedFile = TFile :: Open (( string ( directoryToSave ) + \"generated_hist.root\" ). data (), \"RECREATE\" ); generatedFile -> mkdir ( \"canvas/\" ); generatedFile -> cd ( \"canvas/\" ); if ( shouldDrawInvariantMassCanvas ) { bool drawRegions = false ; bool shouldWrite = true ; bool shouldSavePNG = true ; SdS . createMassCanvas ( drawRegions , shouldWrite , shouldSavePNG ); } if ( shouldDrawInvariantMassCanvasRegion && ! isMC ) { bool drawRegions = true ; bool shouldWrite = true ; bool shouldSavePNG = true ; SdS . createMassCanvas ( drawRegions , shouldWrite , shouldSavePNG ); } Canvas are drawn and saved in the generated_hist.root file and in the folder as .png . //Prepare for showing progress lastTime = std :: chrono :: steady_clock :: now (); start = std :: chrono :: steady_clock :: now (); cout << \" \\n Filling Quantities Histograms..... (2/2) \\n \" ; //Loop between the components again for ( long long i = 0 ; i < numberEntries ; i ++ ) { //Select particle pair TreePC -> GetEntry ( i ); TreeAT -> GetEntry ( i ); //Show progress on screen if ( chrono :: duration_cast < chrono :: milliseconds > ( chrono :: steady_clock :: now () - lastTime ). count () >= 1000 || i == numberEntries - 1 ) { printf ( progressFormat . data (), ( float )( i + 1 ) / ( float ) numberEntries * 100 , i + 1 , numberEntries ); lastTime = chrono :: steady_clock :: now (); } //Fill histograms if ( applyCuts ( quantities , types )) { SdS . fillQuantitiesHistograms ( quantities , types ); } } cout << \" \\n Took \" << chrono :: duration_cast < chrono :: milliseconds > ( chrono :: steady_clock :: now () - start ). count () << \" ms \\n \" ; At this point of the code, this will separate all histogram in signal + background (signal region) and background (sideband region) due the regions for sideband choosen before. //Normalize Histograms for variable binning cout << \" \\n \" ; SdS . normalizeHistograms (); After folling histograms, as some of them has variable bins, it needs to be normalized. This function does this. //For sideband subtraction SdS . subtractSigHistograms (); Subtract background from signal + background histogram to create signal histogram. This method is what is called sideband subtraction . if ( shouldDrawQuantitiesCanvas ) { bool shouldWrite = true ; bool shouldSavePNG = true ; cout << endl ; SdS . createQuantitiesCanvas ( shouldWrite , shouldSavePNG ); } The code here draw the canvas for all pT, eta and phi quantities it has. Including background , signal and signal + background . //Debug consistency for histograms SdS . consistencyDebugCout (); This is a checker of how consistent is our result values and print on terminal results. For all histograms this calculations should result 0. For more details about how exactly it works, see consistencyDebugCout() . //Save histograms generatedFile -> mkdir ( \"histograms/\" ); generatedFile -> cd ( \"histograms/\" ); //Write quantities histograms on file { bool writehSigBack = true ; bool writehSig = true ; bool writehBack = true ; SdS . writeQuantitiesHistogramsOnFile ( writehSigBack , writehSig , writehBack ); } //Write mass histograms on file { bool writehPass = true ; bool writehAll = true ; SdS . writeMassHistogramsOnFile ( writehPass , writehAll ); } At this point, the code will write all histograms in a folder in the .root generated file. Including mass histograms and quantities histograms. //Save plots generatedFile -> mkdir ( \"efficiency/plots/\" ); generatedFile -> cd ( \"efficiency/plots/\" ); //Creates efficiency plots { bool shouldWrite = true ; SdS . createEfficiencyPlot ( shouldWrite ); } It calculates the efficiency of the quantities by using TEfficiency class of ROOT. Then saves the plots in another folder inside the .root file. //Saves new histograms and canvas in file generatedFile -> mkdir ( \"efficiency/canvas/\" ); generatedFile -> cd ( \"efficiency/canvas/\" ); if ( shouldDrawEfficiencyCanvas ) { bool shouldWrite = true ; bool shouldSavePNG = true ; cout << \" \\n \" ; SdS . createEfficiencyCanvas ( shouldWrite , shouldSavePNG ); } //Close files generatedFile -> Close (); cout << \" \\n Done. All result files can be found at \\\" \" << SdS . directoryToSave << \" \\\"\\n\\n \" ; The end point of this function. It creates a canvas for every efficiency plot calculated above and also saves in the generated file. After this, the task is done.","title":"Code explained in parts"},{"location":"analysis/selection/idefficiencystudy/referenceguide/macro/#results","text":"All results are saved in a folder setted in directoryToSave variable. The result contains a file .root with all canvas, histograms and plots aside of .png images of all canvas created.","title":"Results"},{"location":"analysis/systematics/lumiuncertain/","text":"Luminosity Uncertainty \u00b6 Warning This page is under construction","title":"Luminosity Uncertainties"},{"location":"analysis/systematics/lumiuncertain/#luminosity-uncertainty","text":"Warning This page is under construction","title":"Luminosity Uncertainty"},{"location":"analysis/systematics/mcuncertain/","text":"MC Uncertainty \u00b6 Warning This page is under construction","title":"MC Uncertainty"},{"location":"analysis/systematics/mcuncertain/#mc-uncertainty","text":"Warning This page is under construction","title":"MC Uncertainty"},{"location":"analysis/systematics/objectsuncertain/","text":"Object Uncertainty \u00b6 Warning This page is under construction","title":"Object Uncertainty"},{"location":"analysis/systematics/objectsuncertain/#object-uncertainty","text":"Warning This page is under construction","title":"Object Uncertainty"},{"location":"analysis/systematics/pileupuncertain/","text":"Pileup Uncertainty \u00b6 Warning This page is under construction","title":"Pileup Uncertainty"},{"location":"analysis/systematics/pileupuncertain/#pileup-uncertainty","text":"Warning This page is under construction","title":"Pileup Uncertainty"},{"location":"cmssw/cmsswanalyzers/","text":"Analyzers \u00b6 First, a few general words about analysis in the CMSSW framework. Physics analysis proceeds via a series of subsequent steps. Building blocks are identified and more complex objects are built on top of them. How to write a Framework Module and run the job with the cmsRun can be found here . When setting up code for the new EDM (such as creating a new EDProducer) there is a fair amount of 'boiler plate' code that you must write. To make writing such code easier CMS provides a series of scripts that will generate the necessary directory structure and files needed so that all you need to do is write your actual algorithms. CMSSW distiguishes the following module types : EDAnalyzer: takes input from the event and processes the input without writing information back to the event EDProducer: takes input from the event and produces new output which is saved in the event EDFilter: decides if processing the event can be stopped and continued EventSetup: external service not bound to the event structure which provides information useable by all modules (e.g. Geometry, Magnetic Field, etc.) In order to generate above modules: mkedanlzr : makes a skeleton of a package containing an EDAnalyzer mkedprod : makes a skeleton of a package containing an EDProducer mkedfltr : makes a skeleton of a package containing an EDFilter mkrecord : makes a complete implementation of a Record used by the EventSetup More generators are available and you can find them here Warning This page is under construction","title":"Analyzers"},{"location":"cmssw/cmsswanalyzers/#analyzers","text":"First, a few general words about analysis in the CMSSW framework. Physics analysis proceeds via a series of subsequent steps. Building blocks are identified and more complex objects are built on top of them. How to write a Framework Module and run the job with the cmsRun can be found here . When setting up code for the new EDM (such as creating a new EDProducer) there is a fair amount of 'boiler plate' code that you must write. To make writing such code easier CMS provides a series of scripts that will generate the necessary directory structure and files needed so that all you need to do is write your actual algorithms. CMSSW distiguishes the following module types : EDAnalyzer: takes input from the event and processes the input without writing information back to the event EDProducer: takes input from the event and produces new output which is saved in the event EDFilter: decides if processing the event can be stopped and continued EventSetup: external service not bound to the event structure which provides information useable by all modules (e.g. Geometry, Magnetic Field, etc.) In order to generate above modules: mkedanlzr : makes a skeleton of a package containing an EDAnalyzer mkedprod : makes a skeleton of a package containing an EDProducer mkedfltr : makes a skeleton of a package containing an EDFilter mkrecord : makes a complete implementation of a Record used by the EventSetup More generators are available and you can find them here Warning This page is under construction","title":"Analyzers"},{"location":"cmssw/cmsswconditions/","text":"Conditions \u00b6 This page explains the use of global tags and the condition database with the CMS Open Data. All information was taken from here . A Global Tag is a coherent collection of records of additional data needed by the reconstruction and analysis software. The Global Tag is defined for each data-taking period, separately for collision and simulated data. These records are stored in the condition database. Condition data include non-event-related information (Alignment, Calibration, Temperature, etc.) and parameters for the simulation/reconstruction/analysis software. For CMS Open Data, the condition data are provided as sqlite files in the /cvmfs/cms-opendata-conddb.cern.ch/ directory, which is accessible through the CMS Open Data VM. Most physics objects such as electrons , muons , photons in the CMS Open Data are already calibrated and ready-to-use, and no additional corrections are needed other than selection and identification criteria, which will be applied in the analysis code. Therefore, simple analyses do not need to access the condition database. For example you can check the Higgs analysis example . However, access to the condition database is necessary, for example, for jet energy corrections and trigger configuration information. Examples of such analyses are for the PAT object production or the top quark pair production . Note that when you need to access the condition database, the first time you run the job on the CMS Open Data VM, it will download the condition data from the /cvmfs area. It will take time (an example run of a 10 Mbps line took 45 mins), but it will only happen once as the files will be cached on your VM. The job will not produce any output during this time, but you can check the ongoing processes with the command 'top' and you can monitor the progress of reading the condition data to the local cache with the command 'df'. Collision data and Monte Carlo data sets can be found at http://opendata.cern.ch/docs/cms-guide-for-condition-database for years 2010, 2011 and 2012. Warning This page is under construction","title":"Conditions Data"},{"location":"cmssw/cmsswconditions/#conditions","text":"This page explains the use of global tags and the condition database with the CMS Open Data. All information was taken from here . A Global Tag is a coherent collection of records of additional data needed by the reconstruction and analysis software. The Global Tag is defined for each data-taking period, separately for collision and simulated data. These records are stored in the condition database. Condition data include non-event-related information (Alignment, Calibration, Temperature, etc.) and parameters for the simulation/reconstruction/analysis software. For CMS Open Data, the condition data are provided as sqlite files in the /cvmfs/cms-opendata-conddb.cern.ch/ directory, which is accessible through the CMS Open Data VM. Most physics objects such as electrons , muons , photons in the CMS Open Data are already calibrated and ready-to-use, and no additional corrections are needed other than selection and identification criteria, which will be applied in the analysis code. Therefore, simple analyses do not need to access the condition database. For example you can check the Higgs analysis example . However, access to the condition database is necessary, for example, for jet energy corrections and trigger configuration information. Examples of such analyses are for the PAT object production or the top quark pair production . Note that when you need to access the condition database, the first time you run the job on the CMS Open Data VM, it will download the condition data from the /cvmfs area. It will take time (an example run of a 10 Mbps line took 45 mins), but it will only happen once as the files will be cached on your VM. The job will not produce any output during this time, but you can check the ongoing processes with the command 'top' and you can monitor the progress of reading the condition data to the local cache with the command 'df'. Collision data and Monte Carlo data sets can be found at http://opendata.cern.ch/docs/cms-guide-for-condition-database for years 2010, 2011 and 2012. Warning This page is under construction","title":"Conditions"},{"location":"cmssw/cmsswconfigure/","text":"Configuration \u00b6 A configuration document, written using the Python language, is used to configure the cmsRun executable. A Python configuration program specifies which modules, inputs, outputs and services are to be loaded during execution, how to configure these modules and services, and in what order to execute them. All information can be found at twiki.cern.ch/twiki/bin/view/CMSPublic/SWGuideAboutPythonConfigFile .","title":"Configuration"},{"location":"cmssw/cmsswconfigure/#configuration","text":"A configuration document, written using the Python language, is used to configure the cmsRun executable. A Python configuration program specifies which modules, inputs, outputs and services are to be loaded during execution, how to configure these modules and services, and in what order to execute them. All information can be found at twiki.cern.ch/twiki/bin/view/CMSPublic/SWGuideAboutPythonConfigFile .","title":"Configuration"},{"location":"cmssw/cmsswdatamodel/","text":"Data Model \u00b6 The CMS Event Data Model (EDM) is centered around the concept of an Event . Physically, an event is the result of a single readout of the detector electronics and the signals that will (in general) have been generated by particles, tracks, energy deposits, present in a number of bunch crossings. In software terms, an Event starts as a collection of the RAW data from a detector or MC event, stored as a single entity in memory, a C++ type-safe container called edm::Event . An Event is a C++ object container for all RAW and reconstructed data related to a particular collision. During processing, data are passed from one module to the next via the Event, and are accessed only through the Event. All objects in the Event may be individually or collectively stored in ROOT files, and are thus directly browsable in ROOT. More and detailed information can be found here . The CMS Data Hierarchy \u00b6 CMS Data is arranged into a hierarchy of data tiers. Each physics event is written into each data tier, where the tiers each contain different levels of information about the event. The different tiers each have different uses. The three main data tiers written in CMS are: RAW: full event information from the Tier-0 (i.e. from CERN), containing 'raw' detector information (detector element hits, etc) RAW is not used directly for analysis RECO (\"RECOnstructed data\"): the output from first-pass processing by the Tier-0. This layer contains reconstructed physics objects, but it's still very detailed. RECO can be used for analysis, but is too big for frequent or heavy use when CMS has collected a substantial data sample. RECO Data Format Table AOD (\"Analysis Object Data\"): this is a \"distilled\" version of the RECO event information, and is expected to be used for most analyses. AOD provides a trade-off between event size and complexity of the available information to optimize flexibility and speed for analyses. AOD Data Format Table The data tiers are described in more detail in a dedicated WorkBook chapter on Data Formats and Tiers .","title":"Data Model"},{"location":"cmssw/cmsswdatamodel/#data-model","text":"The CMS Event Data Model (EDM) is centered around the concept of an Event . Physically, an event is the result of a single readout of the detector electronics and the signals that will (in general) have been generated by particles, tracks, energy deposits, present in a number of bunch crossings. In software terms, an Event starts as a collection of the RAW data from a detector or MC event, stored as a single entity in memory, a C++ type-safe container called edm::Event . An Event is a C++ object container for all RAW and reconstructed data related to a particular collision. During processing, data are passed from one module to the next via the Event, and are accessed only through the Event. All objects in the Event may be individually or collectively stored in ROOT files, and are thus directly browsable in ROOT. More and detailed information can be found here .","title":"Data Model"},{"location":"cmssw/cmsswdatamodel/#the-cms-data-hierarchy","text":"CMS Data is arranged into a hierarchy of data tiers. Each physics event is written into each data tier, where the tiers each contain different levels of information about the event. The different tiers each have different uses. The three main data tiers written in CMS are: RAW: full event information from the Tier-0 (i.e. from CERN), containing 'raw' detector information (detector element hits, etc) RAW is not used directly for analysis RECO (\"RECOnstructed data\"): the output from first-pass processing by the Tier-0. This layer contains reconstructed physics objects, but it's still very detailed. RECO can be used for analysis, but is too big for frequent or heavy use when CMS has collected a substantial data sample. RECO Data Format Table AOD (\"Analysis Object Data\"): this is a \"distilled\" version of the RECO event information, and is expected to be used for most analyses. AOD provides a trade-off between event size and complexity of the available information to optimize flexibility and speed for analyses. AOD Data Format Table The data tiers are described in more detail in a dedicated WorkBook chapter on Data Formats and Tiers .","title":"The CMS Data Hierarchy"},{"location":"cmssw/cmsswoverview/","text":"Overview \u00b6 The overall collection of software, referred to as CMS Software (CMSSW), is built around a Framework, an Event Data Model (EDM), and Services needed by the simulation, calibration and alignment, and reconstruction modules that process event data so that physicists can perform analysis. The primary goal of the Framework and EDM is to facilitate the development and deployment of reconstruction and analysis software. The CMSSW event processing model consists of one executable, called cmsRun , and many plug-in modules which are managed by the Framework. All the code needed in the event processing (calibration, reconstruction algorithms, etc.) is contained in the modules. The same executable is used for both detector and Monte Carlo data. More and detailed information can be found here .","title":"Overview"},{"location":"cmssw/cmsswoverview/#overview","text":"The overall collection of software, referred to as CMS Software (CMSSW), is built around a Framework, an Event Data Model (EDM), and Services needed by the simulation, calibration and alignment, and reconstruction modules that process event data so that physicists can perform analysis. The primary goal of the Framework and EDM is to facilitate the development and deployment of reconstruction and analysis software. The CMSSW event processing model consists of one executable, called cmsRun , and many plug-in modules which are managed by the Framework. All the code needed in the event processing (calibration, reconstruction algorithms, etc.) is contained in the modules. The same executable is used for both detector and Monte Carlo data. More and detailed information can be found here .","title":"Overview"},{"location":"tools/cernportal/","text":"The CERN Open Data Portal \u00b6 Warning This page is under construction","title":"CERN Open Data Portal"},{"location":"tools/cernportal/#the-cern-open-data-portal","text":"Warning This page is under construction","title":"The CERN Open Data Portal"},{"location":"tools/cmsopendata/","text":"CMS Open Data \u00b6 Warning This page is under construction","title":"CMS Open Data"},{"location":"tools/cmsopendata/#cms-open-data","text":"Warning This page is under construction","title":"CMS Open Data"},{"location":"tools/cmstwiki/","text":"The CMS Twiki \u00b6 Warning This page is under construction","title":"CMS Twiki"},{"location":"tools/cmstwiki/#the-cms-twiki","text":"Warning This page is under construction","title":"The CMS Twiki"},{"location":"tools/cppandpython/","text":"C++ and python \u00b6 Warning This page is under construction","title":"C++ and Python"},{"location":"tools/cppandpython/#c-and-python","text":"Warning This page is under construction","title":"C++ and python"},{"location":"tools/docker/","text":"Docker \u00b6 Warning This page is under construction Docker is a commercial implementation of a container , a way to package up a snapshot of everything needed to run some particular version of software (OS, libraries, compilers, etc.). It is a very effective way of interfacing with the CMS open data as it gives you the proper environment you need to analyze these data. To learn more about Docker in general, from a HEP perspective, you may want to check out this Introduction to Docker , from Matthew Feickert. You can also jump right in with a tutorial on running CMS analysis code using Docker .","title":"Docker"},{"location":"tools/docker/#docker","text":"Warning This page is under construction Docker is a commercial implementation of a container , a way to package up a snapshot of everything needed to run some particular version of software (OS, libraries, compilers, etc.). It is a very effective way of interfacing with the CMS open data as it gives you the proper environment you need to analyze these data. To learn more about Docker in general, from a HEP perspective, you may want to check out this Introduction to Docker , from Matthew Feickert. You can also jump right in with a tutorial on running CMS analysis code using Docker .","title":"Docker"},{"location":"tools/git/","text":"Git \u00b6 Warning This page is under construction Here are some helpful links to learn how to use git.","title":"Git"},{"location":"tools/git/#git","text":"Warning This page is under construction Here are some helpful links to learn how to use git.","title":"Git"},{"location":"tools/root/","text":"ROOT \u00b6 Warning This page is under construction From ROOT's webpage A modular scientific software toolkit. It provides all the functionalities needed to deal with big data processing, statistical analysis, visualisation and storage. It is mainly written in C++ but integrated with other languages such as Python and R. It is the primary toolkit for many experimental analysis and while you are free to analyze these datasets however you like, some familiarity with ROOT will serve you well when accessing the data. Many ROOT examples can be found here . If you don't know where to start, we would recommend Example 1 Example 2 Example 3 Python has become the language of choice for many analysts and most of the examples you'll see make use of the PyROOT module, callable from python. You can go through a number of the examples here . If you don't know where to start, we would recommend Example 1 Example 2 Example 3","title":"ROOT"},{"location":"tools/root/#root","text":"Warning This page is under construction From ROOT's webpage A modular scientific software toolkit. It provides all the functionalities needed to deal with big data processing, statistical analysis, visualisation and storage. It is mainly written in C++ but integrated with other languages such as Python and R. It is the primary toolkit for many experimental analysis and while you are free to analyze these datasets however you like, some familiarity with ROOT will serve you well when accessing the data. Many ROOT examples can be found here . If you don't know where to start, we would recommend Example 1 Example 2 Example 3 Python has become the language of choice for many analysts and most of the examples you'll see make use of the PyROOT module, callable from python. You can go through a number of the examples here . If you don't know where to start, we would recommend Example 1 Example 2 Example 3","title":"ROOT"},{"location":"tools/unix/","text":"Unix \u00b6 Warning This page is under construction Useful tips on basic unix environments","title":"UNIX"},{"location":"tools/unix/#unix","text":"Warning This page is under construction Useful tips on basic unix environments","title":"Unix"},{"location":"tools/virtualmachines/","text":"Virtual machines \u00b6 CMS open data and legacy data, even though still exciting and full of potential, are already a few years old. Because of the rapidly evolving technolgies, the computing environments that were used to analyze these data are already ancient compared to the current, bleeding edge ones. Therefore, in order to mantain our ability to study these data, we have to rely on technologies that help us preserve adequate computer environments. One way of doing this is by using virtual machines. In simple words, a virtual machine is an emulation of a computer system that can run within another system. The latter is usually known as the host . Open data releases, CMSSW versions and operating systems \u00b6 CMS open data from our 2010 release can be studied using CMSSW_4_2_8, a version of the CMSSW software that used to run under Scientific Linux CERN 5 (slc5) operating system. Likewise, open data from our 2011/2012 release used CMSSW_5_3_32 under Scientific Linux CERN 6 (slc6). The virtual machines that are used to analyze these data, therefore, need to consider all these compatibility subtleties. Virtual machine images \u00b6 In practical terms, a virtual machine image is a computer file that has all the right ingredients to create a virtual computer inside a given host. This file, however, needs to be decoded by a virtual machine interpreter, usually known as hypervisor , which runs on the host machine. One of the most famous hypervisors is Oracle's VirtualBox . CMS virtual images \u00b6 The most current images for CMS open data usage are described separately in the CERN Open Portal site for 2010 and 2011/2012 . They come equiped with the ROOT framework, CMSSW and CVMFS access. Remember When installing a CMS virtual machine (following the instructions below), always use the latest image file available for 2010 or 2011/2012 data. Installation \u00b6 Detailed instructions on how to install the CERN virtual machines can be found in the 2010 and 2011/2012 virtual machine installation guides from the CERN Open Portal. Choose the one to follow depending on the data release you will be working on. In summary, the basic steps are as follows: Download and install the latest (or even better, the latest tested) version of VirtualBox . Note that it is available for an ample range of platforms. Download the latest CMS virtual image file. Choose between 2010 or 2011/2012 , depending on the data release of interest. Once downloaded, import the image file into VirtualBox. Remember Always use the latest image file available for 2010 or 2011/2012 . Older ones are usually deprecated. Test the environment; again, 2010 or 2011/2012 , depending on the release. Finally, check for any known issues or limitations ( 2010 , 2011/2012 .)","title":"Virtual Machines"},{"location":"tools/virtualmachines/#virtual-machines","text":"CMS open data and legacy data, even though still exciting and full of potential, are already a few years old. Because of the rapidly evolving technolgies, the computing environments that were used to analyze these data are already ancient compared to the current, bleeding edge ones. Therefore, in order to mantain our ability to study these data, we have to rely on technologies that help us preserve adequate computer environments. One way of doing this is by using virtual machines. In simple words, a virtual machine is an emulation of a computer system that can run within another system. The latter is usually known as the host .","title":"Virtual machines"},{"location":"tools/virtualmachines/#open-data-releases-cmssw-versions-and-operating-systems","text":"CMS open data from our 2010 release can be studied using CMSSW_4_2_8, a version of the CMSSW software that used to run under Scientific Linux CERN 5 (slc5) operating system. Likewise, open data from our 2011/2012 release used CMSSW_5_3_32 under Scientific Linux CERN 6 (slc6). The virtual machines that are used to analyze these data, therefore, need to consider all these compatibility subtleties.","title":"Open data releases, CMSSW versions and operating systems"},{"location":"tools/virtualmachines/#virtual-machine-images","text":"In practical terms, a virtual machine image is a computer file that has all the right ingredients to create a virtual computer inside a given host. This file, however, needs to be decoded by a virtual machine interpreter, usually known as hypervisor , which runs on the host machine. One of the most famous hypervisors is Oracle's VirtualBox .","title":"Virtual machine images"},{"location":"tools/virtualmachines/#cms-virtual-images","text":"The most current images for CMS open data usage are described separately in the CERN Open Portal site for 2010 and 2011/2012 . They come equiped with the ROOT framework, CMSSW and CVMFS access. Remember When installing a CMS virtual machine (following the instructions below), always use the latest image file available for 2010 or 2011/2012 data.","title":"CMS virtual images"},{"location":"tools/virtualmachines/#installation","text":"Detailed instructions on how to install the CERN virtual machines can be found in the 2010 and 2011/2012 virtual machine installation guides from the CERN Open Portal. Choose the one to follow depending on the data release you will be working on. In summary, the basic steps are as follows: Download and install the latest (or even better, the latest tested) version of VirtualBox . Note that it is available for an ample range of platforms. Download the latest CMS virtual image file. Choose between 2010 or 2011/2012 , depending on the data release of interest. Once downloaded, import the image file into VirtualBox. Remember Always use the latest image file available for 2010 or 2011/2012 . Older ones are usually deprecated. Test the environment; again, 2010 or 2011/2012 , depending on the release. Finally, check for any known issues or limitations ( 2010 , 2011/2012 .)","title":"Installation"}]}